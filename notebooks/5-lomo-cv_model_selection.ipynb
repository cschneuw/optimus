{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.serialization.safe_globals at 0x7327f8567a10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from itertools import product\n",
    "import warnings\n",
    "\n",
    "# System path modification\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning imports\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, MultiTaskLasso, MultiTaskElasticNet\n",
    ")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "# Custom modules\n",
    "from src.train import *\n",
    "from src.functions import *\n",
    "from src.plots import *\n",
    "from src.dataset import *\n",
    "from src.multixgboost import *\n",
    "from src.wrapper import *\n",
    "\n",
    "# Deep learning and machine learning specific \n",
    "import torch\n",
    "\n",
    "from pytorch_tabular.config import DataConfig, TrainerConfig, OptimizerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.models import (\n",
    "    GatedAdditiveTreeEnsembleConfig,\n",
    "    DANetConfig,\n",
    "    TabTransformerConfig,\n",
    "    TabNetModelConfig,\n",
    ")\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Print CUDA availability for PyTorch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "from omegaconf import DictConfig\n",
    "torch.serialization.safe_globals([DictConfig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-One-Missing-Out (LOMO) Cross-Validation\n",
    "\n",
    "This notebook explores predictive model performance in a leave-one-missing-out cross-validation (LOMO-CV) framework using multimodal Alzheimer’s disease biomarker data. This setting evaluates the models’ robustness when both training and testing data contain missing values.\n",
    "\n",
    "The analysis includes Linear Regression, Lasso, ElasticNet, PLS, Random Forest, XGBoost, TabNet, TabTransformer, and DANet models across four cognitive domains: Memory, Executive Function, Visuospatial Function, and Language.\n",
    "\n",
    "In LOMO-CV, we randomly select 20 subjects with missing data as test cases. For each, imputers are trained on the remaining training data (1,185 subjects) and applied to impute the test subject. Predictive models trained on the imputed training data are then used to predict outcomes for the test subject. Both imputation and prediction are performed without any retraining on the test data to avoid leakage. Model performance is measured using mean absolute error (MAE), mean square error (MSE) and Pearson correlation, with results summarized for each cognitive domain.\n",
    "\n",
    "--- \n",
    "\n",
    "### Notebook structure\n",
    "1. Leave-One-Missing-Out (LOMO-CV)\n",
    "2. MRI-Only Model Evaluation\n",
    "3. Results Summary and Reporting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_pickle_data_palettes()\n",
    "\n",
    "results_pickle_folder = \"../pickle/\"\n",
    "\n",
    "# Unpack data\n",
    "df_X, df_y, df_all, df_FinalCombination = data[\"df_X\"], data[\"df_y\"], data[\"df_all\"], data[\"df_FinalCombination\"]\n",
    "dict_select = data[\"dict_select\"]\n",
    "\n",
    "# Unpack colormaps\n",
    "full_palette, gender_palette, dx_palette = data[\"colormaps\"].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "idx_na = list(df_X.isna().any(axis=1))\n",
    "idx_nona = list(~df_X.isna().any(axis=1))\n",
    "\n",
    "# Identify unique RIDs for rows with and without missing data\n",
    "rid_na = df_all.loc[idx_na, \"RID\"].unique()\n",
    "rid_nona = df_all.loc[idx_nona, \"RID\"].unique()\n",
    "\n",
    "# Identify RIDs eligible for test set (not in train set)\n",
    "eligible_rid_na = np.setdiff1d(rid_na, rid_nona)\n",
    "\n",
    "df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]] = df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]].astype(\"int\", errors='ignore')\n",
    "\n",
    "\n",
    "single_measurement_rids = (\n",
    "    df_all[df_all[\"RID\"].isin(eligible_rid_na)]\n",
    "    .groupby(\"RID\")\n",
    "    .filter(lambda x: len(x) == 1)\n",
    "    .RID.unique()\n",
    ")\n",
    "\n",
    "test_rids = np.random.choice(single_measurement_rids, size=20, replace=False)\n",
    "\n",
    "# Create boolean mask for the test set\n",
    "idx_test = df_all[\"RID\"].isin(test_rids)\n",
    "\n",
    "# Create boolean mask for the train set (all not in test)\n",
    "idx_train = ~idx_test\n",
    "\n",
    "print(idx_test.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-One-Missing-Out (LOMO-CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42\n",
    "\n",
    "# Continuous Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "continuous_imputer_list = [\n",
    "    (\"KNNImputer_5\", KNNImputer(n_neighbors=5)),\n",
    "   # (\"IterativeImputer\", IterativeImputer(max_iter=100, random_state=42)),\n",
    "]\n",
    "\n",
    "# Ordinal Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "ordinal_imputer_list = [\n",
    "    (\"KNNImputer1\", KNNImputer(n_neighbors=1)),\n",
    "]\n",
    "\n",
    "# Predictive Models List (list of tuples with unique strings and corresponding instances)\n",
    "predictive_models_list = [\n",
    "    (\"LinearRegression\", LinearRegression()),\n",
    "    (\"MultiTaskElasticNet\", MultiTaskElasticNet()),\n",
    "    (\"MultiTaskElasticNet_tuned\", MultiTaskElasticNet(**{'alpha': 0.1, 'l1_ratio': 0.1})),\n",
    "    (\"MultiTaskLasso\", MultiTaskLasso()),\n",
    "    (\"MultiTaskLasso_tuned\", MultiTaskLasso(**{'alpha': 0.001})),\n",
    "    (\"RandomForestRegressor\", RandomForestRegressor()),\n",
    "    (\"XGBoostRegressor\", XGBoostRegressor()),\n",
    "    (\"XGBoostRegressor_tuned\", XGBoostRegressor(**{'colsample_bytree': 0.8776807051588262, 'learning_rate': 0.13329520360246094, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.5924272277627636})),\n",
    "    (\"TabNetRegressor_default\", TabNetModelWrapper(n_a=8, n_d=8)),\n",
    "    (\"TabNetRegressor_custom\", TabNetModelWrapper(n_a=32, n_d=32)),\n",
    "    (\"PLSRegression_4_components\", PLSRegression(n_components=4))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['APOE_epsilon2', 'APOE_epsilon3', 'APOE_epsilon4']\n",
    "continuous_features = [col for col in df_X.columns if col not in ordinal_features]\n",
    "\n",
    "# Prepare Tabular configurations (shared for all PyTorch models)\n",
    "data_config = DataConfig(\n",
    "    target=df_y.columns.tolist(),\n",
    "    continuous_cols=continuous_features,\n",
    "    categorical_cols=ordinal_features\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024, max_epochs=10, auto_lr_find=False,\n",
    "    early_stopping=\"valid_loss\", early_stopping_mode=\"min\", early_stopping_patience=5,\n",
    "    checkpoints=\"valid_loss\", load_best=True, progress_bar=\"nones\",\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "head_config = LinearHeadConfig(dropout=0.1).__dict__\n",
    "\n",
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabNetModelConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: LinearRegression\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskElasticNet\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskElasticNet_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskLasso\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskLasso_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: RandomForestRegressor\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: XGBoostRegressor\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: XGBoostRegressor_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabNetRegressor_default\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabNetRegressor_custom\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: PLSRegression_4_components\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: GatedAdditiveTreeEnsembleConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: DANetConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabTransformerConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabNetModelConfig_tab\n",
      "Combinations of preprocessing and models to test : 15\n"
     ]
    }
   ],
   "source": [
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "# Display all combinations\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    print(f\"Continuous Imputer: {continuous_imputer[0]}, Ordinal Imputer: {ordinal_imputer[0]}, Model: {model[0]}\") \n",
    "\n",
    "print(f\"Combinations of preprocessing and models to test : {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: LinearRegression\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskElasticNet\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskElasticNet_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskLasso\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskLasso_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: RandomForestRegressor\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: XGBoostRegressor\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: XGBoostRegressor_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabNetRegressor_default\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabNetRegressor_custom\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: PLSRegression_4_components\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: GatedAdditiveTreeEnsembleConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: DANetConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabTransformerConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabNetModelConfig_tab\n",
      "Combinations of preprocessing and models to test : 15\n"
     ]
    }
   ],
   "source": [
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "# Display all combinations\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    print(f\"Continuous Imputer: {continuous_imputer[0]}, Ordinal Imputer: {ordinal_imputer[0]}, Model: {model[0]}\")\n",
    "\n",
    "print(f\"Combinations of preprocessing and models to test : {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = [i for i, val in enumerate(idx_test) if val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'LinearRegression']\n",
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'MultiTaskElasticNet']\n",
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'MultiTaskElasticNet_tuned']\n",
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'MultiTaskLasso']\n",
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'MultiTaskLasso_tuned']\n",
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'RandomForestRegressor']\n",
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'XGBoostRegressor']\n",
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'XGBoostRegressor_tuned']\n",
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'TabNetRegressor_default']\n",
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'TabNetRegressor_custom']\n",
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'PLSRegression_4_components']\n",
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'GatedAdditiveTreeEnsembleConfig_tab']\n",
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'DANetConfig_tab']\n",
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'TabTransformerConfig_tab']\n",
      "Skipping existing combination (subset match): ['KNNImputer1', 'KNNImputer_5', 'TabNetModelConfig_tab']\n"
     ]
    }
   ],
   "source": [
    "# Initialize HDF5 file\n",
    "results_file = '../pickle/training_4_loona_dict_results.pickle'\n",
    "\n",
    "if os.path.exists(results_file): \n",
    "    with open(results_file, \"rb\") as input_file:\n",
    "        all_dict_results = pickle.load(input_file)\n",
    "\n",
    "else : \n",
    "    all_dict_results = []\n",
    "\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    name_continuous_imputer, continuous_imputer_instance = continuous_imputer\n",
    "    name_ordinal_imputer, ordinal_imputer_instance = ordinal_imputer\n",
    "    name_model, model_instance = model\n",
    "\n",
    "    params = {\n",
    "            \"ordinal_imputer\": name_ordinal_imputer, \n",
    "            \"continuous_imputer\": name_continuous_imputer, \n",
    "            \"model\": name_model, \"train_shape\" : (df_X.shape[0]-1, df_X.shape[1]), \n",
    "            \"test_shape\": (1, df_X.shape[1]),\n",
    "            \"test_rid\": df_all.iloc[test_indices][\"RID\"].tolist()\n",
    "        }\n",
    "\n",
    "    # Define the subset of keys you care about\n",
    "    keys_to_check = ['ordinal_imputer', 'continuous_imputer', 'model']  # or whatever subset you want\n",
    "    \n",
    "    # Check if a result in all_dict_results has the same values for just those keys\n",
    "    if any(all(result['params'].get(k) == params.get(k) for k in keys_to_check) for result in all_dict_results):\n",
    "        print(f\"Skipping existing combination (subset match): {[params[k] for k in keys_to_check]}\")\n",
    "        continue\n",
    "    \n",
    "    dict_results = {\n",
    "            \"params\": params, \n",
    "            \"imputation_time\": [],\n",
    "            \"fitting_time\": [], \n",
    "            \"results_adj\": [], \n",
    "            \"results_org\": []\n",
    "        }\n",
    "\n",
    "    for test_nloc in test_indices: \n",
    "\n",
    "        idx_train = [True for i in range(df_X.shape[0])]\n",
    "        idx_test = [False for i in range(df_X.shape[0])]\n",
    "\n",
    "        idx_test[test_nloc] = True\n",
    "        idx_train[test_nloc] = False\n",
    "\n",
    "        df_X_train = df_X.loc[idx_train]\n",
    "        df_X_test = df_X.loc[idx_test]\n",
    "\n",
    "        df_y_train = df_y.loc[idx_train]\n",
    "        df_y_test = df_y.loc[idx_test]\n",
    "\n",
    "        c_train = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_train]\n",
    "        c_test = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_test]\n",
    "\n",
    "        try: \n",
    "        \n",
    "            # Now you can call your `train_model` function with these components\n",
    "            fold_dict_results = train_imputer_model(\n",
    "                df_X_train, df_X_test, df_y_train, df_y_test,\n",
    "                c_train, c_test,\n",
    "                ordinal_imputer_instance, name_ordinal_imputer,\n",
    "                continuous_imputer_instance, name_continuous_imputer,\n",
    "                model_instance, name_model,\n",
    "                separate_imputers=True  # Or however you want to specify\n",
    "            )\n",
    "\n",
    "            dict_results[\"imputation_time\"].append(fold_dict_results[\"imputation_time\"])  \n",
    "            dict_results[\"fitting_time\"].append(fold_dict_results[\"fitting_time\"])  \n",
    "            dict_results[\"results_adj\"].append(fold_dict_results[\"results_adj\"])  \n",
    "            dict_results[\"results_org\"].append(fold_dict_results[\"results_org\"])    \n",
    "\n",
    "        except Exception as e:  \n",
    "\n",
    "            print(e)\n",
    "            \n",
    "    # Optionally keep the all_dict_results list updated\n",
    "    all_dict_results.append(dict_results)\n",
    "    \n",
    "    # Save the updated results back to the pickle file\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(all_dict_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open(results_file, 'wb') as handle:\n",
    "    pickle.dump(all_dict_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/training_4_loona_dict_results.pickle', \"rb\") as input_file:\n",
    "    dict_results_loo_na = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI-Only Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "idx_na = list(df_X.isna().any(axis=1))\n",
    "idx_nona = list(~df_X.isna().any(axis=1))\n",
    "\n",
    "# Identify unique RIDs for rows with and without missing data\n",
    "rid_na = df_all.loc[idx_na, \"RID\"].unique()\n",
    "rid_nona = df_all.loc[idx_nona, \"RID\"].unique()\n",
    "\n",
    "# Identify RIDs eligible for test set (not in train set)\n",
    "eligible_rid_na = np.setdiff1d(rid_na, rid_nona)\n",
    "\n",
    "df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]] = df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]].astype(\"int\", errors='ignore')\n",
    "\n",
    "\n",
    "single_measurement_rids = (\n",
    "    df_all[df_all[\"RID\"].isin(eligible_rid_na)]\n",
    "    .groupby(\"RID\")\n",
    "    .filter(lambda x: len(x) == 1)\n",
    "    .RID.unique()\n",
    ")\n",
    "\n",
    "test_rids = np.random.choice(single_measurement_rids, size=20, replace=False)\n",
    "\n",
    "# Create boolean mask for the test set\n",
    "idx_test = df_all[\"RID\"].isin(test_rids)\n",
    "\n",
    "# Create boolean mask for the train set (all not in test)\n",
    "idx_train = ~idx_test\n",
    "\n",
    "print(idx_test.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42\n",
    "n_imputation_iter = 10\n",
    "\n",
    "# Continuous Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "continuous_imputer_list = [\n",
    "    (\"NoImputer\", KNNImputer(n_neighbors=1)),\n",
    "\n",
    "]\n",
    "\n",
    "# Ordinal Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "ordinal_imputer_list = [\n",
    "    (\"NoImputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "]\n",
    "\n",
    "# Predictive Models List (list of tuples with unique strings and corresponding instances)\n",
    "predictive_models_list = [\n",
    "    (\"LinearRegression\", LinearRegression()),\n",
    "    (\"MultiTaskElasticNet\", MultiTaskElasticNet()),\n",
    "    (\"MultiTaskElasticNet_tuned\", MultiTaskElasticNet(**{'alpha': 0.1, 'l1_ratio': 0.1})),\n",
    "    (\"MultiTaskLasso\", MultiTaskLasso()),\n",
    "    (\"MultiTaskLasso_tuned\", MultiTaskLasso(**{'alpha': 0.001})),\n",
    "    (\"RandomForestRegressor\", RandomForestRegressor()),\n",
    "    (\"XGBoostRegressor\", XGBoostRegressor()),\n",
    "    (\"XGBoostRegressor_tuned\", XGBoostRegressor(**{'colsample_bytree': 0.8776807051588262, 'learning_rate': 0.13329520360246094, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.5924272277627636})),\n",
    "    (\"TabNetRegressor_default\", TabNetModelWrapper(n_a=8, n_d=8)),\n",
    "    (\"TabNetRegressor_custom\", TabNetModelWrapper(n_a=32, n_d=32)),\n",
    "    (\"PLSRegression_4_components\", PLSRegression(n_components=4))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['APOE_epsilon2', 'APOE_epsilon3', 'APOE_epsilon4']\n",
    "continuous_features = [col for col in df_X.columns if col not in ordinal_features]\n",
    "\n",
    "# Prepare Tabular configurations (shared for all PyTorch models)\n",
    "data_config = DataConfig(\n",
    "    target=df_y.columns.tolist(),\n",
    "    continuous_cols=dict_select[\"MRIth\"],\n",
    "    categorical_cols=[]\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024, max_epochs=10, auto_lr_find=True,\n",
    "    early_stopping=\"valid_loss\", early_stopping_mode=\"min\", early_stopping_patience=5,\n",
    "    checkpoints=\"valid_loss\", load_best=True, progress_bar=\"nones\",\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "head_config = LinearHeadConfig(dropout=0.1).__dict__\n",
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabNetModelConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: LinearRegression\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskElasticNet\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskElasticNet_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskLasso\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskLasso_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: RandomForestRegressor\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: XGBoostRegressor\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: XGBoostRegressor_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetRegressor_default\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetRegressor_custom\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: PLSRegression_4_components\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: GatedAdditiveTreeEnsembleConfig_tab\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: DANetConfig_tab\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabTransformerConfig_tab\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetModelConfig_tab\n",
      "Combinations of preprocessing and models to test : 15\n"
     ]
    }
   ],
   "source": [
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "# Display all combinations\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    print(f\"Continuous Imputer: {continuous_imputer[0]}, Ordinal Imputer: {ordinal_imputer[0]}, Model: {model[0]}\")\n",
    "\n",
    "print(f\"Combinations of preprocessing and models to test : {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = [i for i, val in enumerate(idx_test) if val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HDF5 file\n",
    "results_file = '../pickle/training_4_loona_dict_results.pickle'\n",
    "\n",
    "if os.path.exists(results_file): \n",
    "    with open(results_file, \"rb\") as input_file:\n",
    "        all_dict_results = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "test_rids = all_dict_results[0][\"params\"][\"test_rid\"]\n",
    "\n",
    "# Create boolean mask for the test set\n",
    "idx_test = df_all[\"RID\"].isin(test_rids)\n",
    "\n",
    "# Create boolean mask for the train set (all not in test)\n",
    "idx_train = ~idx_test\n",
    "\n",
    "print(idx_test.sum())\n",
    "\n",
    "test_indices = [i for i, val in enumerate(idx_test) if val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([results[\"params\"][\"test_rid\"] == test_rids for results in all_dict_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_dict_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[480,\n",
       " 501,\n",
       " 569,\n",
       " 632,\n",
       " 733,\n",
       " 899,\n",
       " 952,\n",
       " 1113,\n",
       " 1145,\n",
       " 1219,\n",
       " 1781,\n",
       " 1848,\n",
       " 1961,\n",
       " 2104,\n",
       " 2150,\n",
       " 2209,\n",
       " 2325,\n",
       " 2382,\n",
       " 2420,\n",
       " 2833]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HDF5 file\n",
    "results_file = '../pickle/training_4_loona_dict_results.pickle'\n",
    "\n",
    "if os.path.exists(results_file): \n",
    "    with open(results_file, \"rb\") as input_file:\n",
    "        all_dict_results = pickle.load(input_file)\n",
    "\n",
    "else : \n",
    "    all_dict_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'LinearRegression']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'MultiTaskElasticNet']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'MultiTaskElasticNet_tuned']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'MultiTaskLasso']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'MultiTaskLasso_tuned']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'RandomForestRegressor']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'XGBoostRegressor']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'XGBoostRegressor_tuned']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'TabNetRegressor_default']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'TabNetRegressor_custom']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'PLSRegression_4_components']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'GatedAdditiveTreeEnsembleConfig_tab']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'DANetConfig_tab']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'TabTransformerConfig_tab']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'TabNetModelConfig_tab']\n"
     ]
    }
   ],
   "source": [
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    name_continuous_imputer, continuous_imputer_instance = continuous_imputer\n",
    "    name_ordinal_imputer, ordinal_imputer_instance = ordinal_imputer\n",
    "    name_model, model_instance = model\n",
    "\n",
    "    params = {\n",
    "            \"ordinal_imputer\": name_ordinal_imputer, \n",
    "            \"continuous_imputer\": name_continuous_imputer, \n",
    "            \"model\": name_model, \"train_shape\" : (df_X.shape[0]-1, df_X.shape[1]), \n",
    "            \"test_shape\": (1, df_X.shape[1]),\n",
    "            \"test_rid\": df_all.iloc[test_indices][\"RID\"].tolist()\n",
    "        }\n",
    "\n",
    "    # Define the subset of keys you care about\n",
    "    keys_to_check = ['ordinal_imputer', 'continuous_imputer', 'model']  # or whatever subset you want\n",
    "    \n",
    "    # Check if a result in all_dict_results has the same values for just those keys\n",
    "    if any(all(result['params'].get(k) == params.get(k) for k in keys_to_check) for result in all_dict_results):\n",
    "        print(f\"Skipping existing combination (subset match): {[params[k] for k in keys_to_check]}\")\n",
    "        continue\n",
    "    \n",
    "    dict_results = {\n",
    "            \"params\": params, \n",
    "            \"imputation_time\": [],\n",
    "            \"fitting_time\": [], \n",
    "            \"results_adj\": [], \n",
    "            \"results_org\": []\n",
    "        }\n",
    "\n",
    "    for test_nloc in test_indices: \n",
    "\n",
    "        idx_train = [True for i in range(df_X.shape[0])]\n",
    "        idx_test = [False for i in range(df_X.shape[0])]\n",
    "\n",
    "        idx_test[test_nloc] = True\n",
    "        idx_train[test_nloc] = False\n",
    "\n",
    "        df_X_train = df_X[dict_select[\"MRIth\"]].loc[idx_train]\n",
    "        df_X_test = df_X[dict_select[\"MRIth\"]].loc[idx_test]\n",
    "\n",
    "        df_y_train = df_y.loc[idx_train]\n",
    "        df_y_test = df_y.loc[idx_test]\n",
    "\n",
    "        c_train = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_train]\n",
    "        c_test = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_test]\n",
    "\n",
    "        try: \n",
    "        \n",
    "            # Now you can call your `train_model` function with these components\n",
    "            fold_dict_results = train_imputer_model(\n",
    "                df_X_train, df_X_test, df_y_train, df_y_test,\n",
    "                c_train, c_test,\n",
    "                ordinal_imputer_instance, name_ordinal_imputer,\n",
    "                continuous_imputer_instance, name_continuous_imputer,\n",
    "                model_instance, name_model,\n",
    "                separate_imputers=True  # Or however you want to specify\n",
    "            )\n",
    "\n",
    "            dict_results[\"imputation_time\"].append(fold_dict_results[\"imputation_time\"])  \n",
    "            dict_results[\"fitting_time\"].append(fold_dict_results[\"fitting_time\"])  \n",
    "            dict_results[\"results_adj\"].append(fold_dict_results[\"results_adj\"])  \n",
    "            dict_results[\"results_org\"].append(fold_dict_results[\"results_org\"])    \n",
    "\n",
    "        except Exception as e:  \n",
    "\n",
    "            print(e)\n",
    "            \n",
    "    # Optionally keep the all_dict_results list updated\n",
    "    all_dict_results.append(dict_results)\n",
    "    \n",
    "    # Save the updated results back to the pickle file\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(all_dict_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_dict_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Summary and Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/training_4_loona_dict_results.pickle', \"rb\") as input_file:\n",
    "    dict_results_loona = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metric_table(\n",
    "    results_list,\n",
    "    targets,\n",
    "    metric_name=\"r2\",\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=None,\n",
    "    sort_order=\"descending\"\n",
    "):\n",
    "    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "    from scipy.stats import pearsonr\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # Choose the key\n",
    "    key = \"results_adj\" if source.lower() == \"adjusted\" else \"results_org\"\n",
    "    df_rows = []\n",
    "\n",
    "    for res in results_list:\n",
    "        result_blocks = res.get(key, [])\n",
    "        if not isinstance(result_blocks, list) or len(result_blocks) == 0:\n",
    "            continue\n",
    "\n",
    "        # Aggregate all predictions across folds\n",
    "        y_preds_all = {target: [] for target in targets}\n",
    "        y_tests_all = {target: [] for target in targets}\n",
    "\n",
    "        for fold in result_blocks:\n",
    "            y_pred = fold[\"y_pred\"]\n",
    "            y_test = fold[\"y_test\"]\n",
    "\n",
    "            if y_pred.shape != y_test.shape:\n",
    "                continue\n",
    "\n",
    "            for i, target in enumerate(targets):\n",
    "                if y_pred.shape[1] <= i:\n",
    "                    continue\n",
    "                y_preds_all[target].append(y_pred[0, i])\n",
    "                y_tests_all[target].append(y_test[0, i])\n",
    "\n",
    "        # Compute metric for each target\n",
    "        target_metrics = []\n",
    "        for target in targets:\n",
    "            y_preds = y_preds_all[target]\n",
    "            y_tests = y_tests_all[target]\n",
    "\n",
    "            if len(y_preds) < 2:\n",
    "                metric = float(\"nan\")\n",
    "            else:\n",
    "                if metric_name == \"r2\":\n",
    "                    metric = r2_score(y_tests, y_preds)\n",
    "                elif metric_name == \"mae\":\n",
    "                    metric = mean_absolute_error(y_tests, y_preds)\n",
    "                elif metric_name == \"mse\":\n",
    "                    metric = mean_squared_error(y_tests, y_preds)\n",
    "                elif metric_name == \"explained_variance\":\n",
    "                    metric = explained_variance_score(y_tests, y_preds)\n",
    "                elif metric_name == \"corr\":\n",
    "                    metric = pearsonr(y_tests, y_preds)[0]\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported metric: {metric_name}\")\n",
    "\n",
    "            target_metrics.append(metric)\n",
    "\n",
    "        # Compute mean ± std across targets\n",
    "        values = np.array(target_metrics, dtype=np.float64)\n",
    "        mean_val = np.nanmean(values)\n",
    "        std_val = np.nanstd(values)\n",
    "\n",
    "        # Get times\n",
    "        imp_times = np.array(res.get(\"imputation_time\", []), dtype=np.float64)\n",
    "        fit_times = np.array(res.get(\"fitting_time\", []), dtype=np.float64)\n",
    "\n",
    "        row = {\n",
    "            \"continuous_imputer\": res[\"params\"].get(\"continuous_imputer\"),\n",
    "            \"ordinal_imputer\": res[\"params\"].get(\"ordinal_imputer\"),\n",
    "            \"model\": res[\"params\"].get(\"model\"),\n",
    "            **{target: val for target, val in zip(targets, target_metrics)},\n",
    "            \"mean ± std\": f\"{mean_val:.3f} ± {std_val:.3f}\",\n",
    "            \"imp_time (s)\": f\"{np.nanmean(imp_times):.1f} ± {np.nanstd(imp_times):.1f}\",\n",
    "            \"fit_time (s)\": f\"{np.nanmean(fit_times):.1f} ± {np.nanstd(fit_times):.1f}\",\n",
    "            \"_sort_val\": mean_val  # hidden sort key\n",
    "        }\n",
    "        df_rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(df_rows)\n",
    "\n",
    "    # Sort by mean value\n",
    "    df = df.sort_values(by=\"_sort_val\", ascending=(sort_order == \"ascending\")).drop(columns=\"_sort_val\")\n",
    "\n",
    "    # Optional: Save to CSV\n",
    "    if csv_filename:\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    # Format for LaTeX output\n",
    "    latex_df = df.copy()\n",
    "    for target in targets:\n",
    "        latex_df[target] = latex_df[target].apply(lambda x: f\"{x:.3f}\" if pd.notnull(x) else \"–\")\n",
    "\n",
    "    latex_output = latex_df.to_latex(index=False, escape=False)\n",
    "\n",
    "    return df, latex_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "continuous_imputer & ordinal_imputer & model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & mean ± std & imp_time (s) & fit_time (s) \\\\\n",
      "\\midrule\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor & 0.759 & 0.858 & 0.808 & 0.877 & 0.825 ± 0.046 & 2.5 ± 0.0 & 1.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & RandomForestRegressor & 0.726 & 0.822 & 0.784 & 0.829 & 0.790 ± 0.041 & 2.5 ± 0.1 & 39.4 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer & PLSRegression_4_components & 0.825 & 0.759 & 0.754 & 0.812 & 0.787 ± 0.032 & 2.6 ± 0.0 & 0.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet & 0.804 & 0.752 & 0.708 & 0.836 & 0.775 ± 0.049 & 2.7 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_default & 0.800 & 0.790 & 0.738 & 0.766 & 0.774 ± 0.024 & 2.6 ± 0.0 & 12.6 ± 0.7 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet_tuned & 0.816 & 0.697 & 0.756 & 0.797 & 0.766 ± 0.045 & 2.7 ± 0.1 & 1.4 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & GatedAdditiveTreeEnsembleConfig_tab & 0.769 & 0.664 & 0.753 & 0.764 & 0.737 ± 0.043 & 2.5 ± 0.0 & 16.3 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor_tuned & 0.724 & 0.769 & 0.641 & 0.769 & 0.726 ± 0.052 & 2.5 ± 0.1 & 4.6 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso_tuned & 0.793 & 0.624 & 0.665 & 0.749 & 0.708 ± 0.067 & 2.6 ± 0.0 & 1.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & LinearRegression & 0.790 & 0.613 & 0.650 & 0.740 & 0.698 ± 0.070 & 2.6 ± 0.1 & 0.1 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & PLSRegression_4_components & 0.730 & 0.733 & 0.411 & 0.718 & 0.648 ± 0.137 & 4.1 ± 0.4 & 0.7 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 0.590 & 0.609 & 0.650 & 0.741 & 0.647 ± 0.058 & nan ± nan & 12.8 ± 0.5 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & XGBoostRegressor & 0.626 & 0.535 & 0.742 & 0.658 & 0.640 ± 0.074 & 1.8 ± 0.0 & 1.2 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & 0.595 & 0.562 & 0.746 & 0.619 & 0.631 ± 0.070 & nan ± nan & 0.8 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & GatedAdditiveTreeEnsembleConfig_tab & 0.715 & 0.683 & 0.404 & 0.710 & 0.628 ± 0.130 & 4.2 ± 0.3 & 36.4 ± 1.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_custom & 0.689 & 0.747 & 0.367 & 0.702 & 0.626 ± 0.151 & 2.5 ± 0.1 & 13.0 ± 0.6 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & RandomForestRegressor & 0.541 & 0.570 & 0.759 & 0.624 & 0.623 ± 0.084 & 1.9 ± 0.2 & 40.8 ± 1.9 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 0.552 & 0.499 & 0.757 & 0.664 & 0.618 ± 0.100 & nan ± nan & 32.0 ± 0.5 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & XGBoostRegressor & 0.675 & 0.686 & 0.350 & 0.621 & 0.583 ± 0.137 & 4.1 ± 0.6 & 165.8 ± 2.6 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskElasticNet_tuned & 0.780 & 0.658 & 0.187 & 0.669 & 0.574 ± 0.228 & 4.0 ± 0.5 & 2.7 ± 0.3 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabNetRegressor_default & 0.472 & 0.512 & 0.722 & 0.549 & 0.564 ± 0.096 & 1.8 ± 0.1 & 13.3 ± 0.6 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabNetRegressor_custom & 0.573 & 0.618 & 0.500 & 0.556 & 0.562 ± 0.042 & 1.9 ± 0.0 & 13.8 ± 1.3 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & XGBoostRegressor_tuned & 0.500 & 0.504 & 0.545 & 0.632 & 0.545 ± 0.053 & 1.8 ± 0.1 & 5.1 ± 0.2 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskElasticNet_tuned & 0.603 & 0.504 & 0.425 & 0.629 & 0.540 ± 0.081 & 1.9 ± 0.1 & 1.3 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & XGBoostRegressor_tuned & 0.712 & 0.599 & 0.172 & 0.665 & 0.537 ± 0.215 & 4.1 ± 0.6 & 408.4 ± 2.1 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & 0.589 & 0.502 & 0.429 & 0.620 & 0.535 ± 0.075 & nan ± nan & 1.2 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & GatedAdditiveTreeEnsembleConfig_tab & 0.471 & 0.505 & 0.614 & 0.539 & 0.532 ± 0.053 & 1.8 ± 0.1 & 16.3 ± 1.9 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & 0.433 & 0.550 & 0.490 & 0.649 & 0.531 ± 0.080 & nan ± nan & 3.9 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & 0.455 & 0.583 & 0.457 & 0.579 & 0.518 ± 0.062 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskLasso_tuned & 0.552 & 0.424 & 0.460 & 0.619 & 0.514 ± 0.077 & 1.8 ± 0.0 & 1.1 ± 0.0 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & LinearRegression & 0.545 & 0.421 & 0.469 & 0.620 & 0.514 ± 0.076 & 2.0 ± 0.1 & 0.2 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & PLSRegression_4_components & 0.429 & 0.545 & 0.422 & 0.601 & 0.499 ± 0.076 & 1.9 ± 0.1 & 0.1 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskLasso_tuned & 0.752 & 0.584 & 0.029 & 0.604 & 0.492 ± 0.275 & 4.0 ± 0.6 & 1.6 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & LinearRegression & 0.747 & 0.578 & 0.018 & 0.595 & 0.485 ± 0.277 & 3.9 ± 0.5 & 2.7 ± 0.5 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskElasticNet & 0.519 & 0.586 & 0.302 & 0.526 & 0.483 ± 0.108 & 4.1 ± 0.3 & 0.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & 0.548 & 0.412 & 0.382 & 0.570 & 0.478 ± 0.082 & nan ± nan & 0.9 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabNetRegressor_default & 0.660 & 0.405 & 0.236 & 0.595 & 0.474 ± 0.166 & 4.4 ± 0.6 & 58.7 ± 1.1 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & 0.542 & 0.405 & 0.376 & 0.565 & 0.472 ± 0.082 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & 0.462 & 0.518 & 0.254 & 0.620 & 0.463 ± 0.134 & nan ± nan & 12.8 ± 0.8 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & RandomForestRegressor & 0.560 & 0.548 & 0.113 & 0.606 & 0.457 ± 0.200 & 4.2 ± 0.6 & 74.6 ± 2.0 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskElasticNet & 0.266 & 0.386 & 0.384 & 0.565 & 0.400 ± 0.107 & 1.9 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & 0.266 & 0.386 & 0.384 & 0.565 & 0.400 ± 0.107 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskLasso & 0.438 & 0.349 & 0.451 & 0.099 & 0.334 ± 0.141 & 4.4 ± 0.6 & 0.1 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso & 0.466 & -0.062 & 0.929 & -0.108 & 0.306 ± 0.424 & 2.7 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabNetRegressor_custom & 0.494 & 0.374 & -0.141 & 0.492 & 0.304 ± 0.262 & 4.0 ± 0.5 & 59.0 ± 1.6 \\\\\n",
      "KNNImputer_5 & KNNImputer & DANetConfig_tab & 0.407 & 0.365 & -0.156 & 0.596 & 0.303 ± 0.279 & 2.5 ± 0.0 & 1.7 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabTransformerConfig_tab & 0.490 & -0.008 & 0.166 & 0.472 & 0.280 ± 0.210 & 2.5 ± 0.1 & 1.5 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabTransformerConfig_tab & 0.464 & 0.165 & -0.218 & 0.625 & 0.259 ± 0.321 & 4.4 ± 0.5 & 4.6 ± 0.4 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabNetModelConfig_tab & -0.025 & 0.191 & 0.304 & 0.212 & 0.171 ± 0.121 & 1.8 ± 0.1 & 1.8 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabTransformerConfig_tab & -0.076 & 0.598 & -0.240 & 0.373 & 0.164 ± 0.337 & 1.9 ± 0.1 & 1.5 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetModelConfig_tab & 0.241 & 0.616 & -0.614 & 0.226 & 0.117 ± 0.450 & 2.5 ± 0.0 & 1.7 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabNetModelConfig_tab & 0.447 & 0.048 & -0.139 & -0.223 & 0.033 ± 0.258 & 4.2 ± 0.6 & 5.7 ± 0.4 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskLasso & -0.216 & -0.210 & 0.108 & 0.034 & -0.071 ± 0.144 & 1.8 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & -0.216 & -0.210 & 0.108 & 0.034 & -0.071 ± 0.144 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & DANetConfig_tab & 0.165 & -0.267 & -0.390 & 0.125 & -0.092 ± 0.241 & 4.1 ± 0.6 & 5.2 ± 0.4 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & DANetConfig_tab & -0.179 & 0.033 & 0.112 & -0.450 & -0.121 ± 0.218 & 1.9 ± 0.2 & 1.9 ± 0.3 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_corr = generate_metric_table(\n",
    "    results_list=dict_results_loona,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='corr',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/4_training_loona_corr_adjusted_sorted.csv\",\n",
    "    sort_order=\"descending\"\n",
    ")\n",
    "print(latex_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "continuous_imputer & ordinal_imputer & model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & mean ± std & imp_time (s) & fit_time (s) \\\\\n",
      "\\midrule\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor & 0.521 & 0.675 & 0.476 & 0.646 & 0.580 ± 0.083 & 2.5 ± 0.0 & 1.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & RandomForestRegressor & 0.480 & 0.627 & 0.496 & 0.570 & 0.543 ± 0.059 & 2.5 ± 0.1 & 39.4 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_default & 0.590 & 0.528 & 0.482 & 0.480 & 0.520 ± 0.045 & 2.6 ± 0.0 & 12.6 ± 0.7 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet_tuned & 0.594 & 0.404 & 0.450 & 0.466 & 0.478 ± 0.071 & 2.7 ± 0.1 & 1.4 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor_tuned & 0.499 & 0.542 & 0.313 & 0.560 & 0.478 ± 0.098 & 2.5 ± 0.1 & 4.6 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & PLSRegression_4_components & 0.606 & 0.445 & 0.400 & 0.444 & 0.474 ± 0.078 & 2.6 ± 0.0 & 0.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso_tuned & 0.582 & 0.327 & 0.399 & 0.445 & 0.438 ± 0.093 & 2.6 ± 0.0 & 1.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & LinearRegression & 0.581 & 0.314 & 0.390 & 0.437 & 0.431 ± 0.098 & 2.6 ± 0.1 & 0.1 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & GatedAdditiveTreeEnsembleConfig_tab & 0.524 & 0.327 & 0.332 & 0.441 & 0.406 ± 0.082 & 2.5 ± 0.0 & 16.3 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & PLSRegression_4_components & 0.505 & 0.493 & 0.163 & 0.453 & 0.403 ± 0.140 & 4.1 ± 0.4 & 0.7 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & GatedAdditiveTreeEnsembleConfig_tab & 0.503 & 0.464 & 0.070 & 0.475 & 0.378 ± 0.179 & 4.2 ± 0.3 & 36.4 ± 1.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_custom & 0.448 & 0.539 & 0.127 & 0.396 & 0.378 ± 0.153 & 2.5 ± 0.1 & 13.0 ± 0.6 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & XGBoostRegressor & 0.301 & 0.269 & 0.464 & 0.422 & 0.364 ± 0.081 & 1.8 ± 0.0 & 1.2 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & 0.282 & 0.299 & 0.440 & 0.362 & 0.346 ± 0.062 & nan ± nan & 0.8 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskElasticNet_tuned & 0.591 & 0.420 & -0.047 & 0.413 & 0.344 ± 0.237 & 4.0 ± 0.5 & 2.7 ± 0.3 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 0.184 & 0.266 & 0.404 & 0.432 & 0.322 ± 0.101 & nan ± nan & 12.8 ± 0.5 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & XGBoostRegressor & 0.445 & 0.409 & 0.089 & 0.341 & 0.321 ± 0.139 & 4.1 ± 0.6 & 165.8 ± 2.6 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 0.212 & 0.218 & 0.406 & 0.403 & 0.310 ± 0.095 & nan ± nan & 32.0 ± 0.5 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & RandomForestRegressor & 0.189 & 0.267 & 0.354 & 0.334 & 0.286 ± 0.065 & 1.9 ± 0.2 & 40.8 ± 1.9 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & XGBoostRegressor_tuned & 0.495 & 0.344 & -0.129 & 0.403 & 0.278 ± 0.241 & 4.1 ± 0.6 & 408.4 ± 2.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabNetRegressor_custom & 0.260 & 0.339 & 0.133 & 0.269 & 0.250 ± 0.074 & 1.9 ± 0.0 & 13.8 ± 1.3 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabNetRegressor_default & 0.075 & 0.226 & 0.462 & 0.228 & 0.248 ± 0.138 & 1.8 ± 0.1 & 13.3 ± 0.6 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & 0.056 & 0.295 & 0.206 & 0.415 & 0.243 ± 0.131 & nan ± nan & 3.9 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskElasticNet_tuned & 0.288 & 0.229 & 0.095 & 0.356 & 0.242 ± 0.096 & 1.9 ± 0.1 & 1.3 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & 0.283 & 0.226 & 0.106 & 0.353 & 0.242 ± 0.090 & nan ± nan & 1.2 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & 0.143 & 0.325 & 0.171 & 0.314 & 0.238 ± 0.082 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskLasso_tuned & 0.549 & 0.321 & -0.313 & 0.334 & 0.223 ± 0.322 & 4.0 ± 0.6 & 1.6 ± 0.3 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & XGBoostRegressor_tuned & 0.124 & 0.222 & 0.194 & 0.345 & 0.221 ± 0.080 & 1.8 ± 0.1 & 5.1 ± 0.2 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & LinearRegression & 0.537 & 0.307 & -0.344 & 0.321 & 0.205 ± 0.330 & 3.9 ± 0.5 & 2.7 ± 0.5 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & RandomForestRegressor & 0.274 & 0.290 & -0.043 & 0.272 & 0.198 ± 0.140 & 4.2 ± 0.6 & 74.6 ± 2.0 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & PLSRegression_4_components & 0.076 & 0.258 & 0.106 & 0.314 & 0.188 ± 0.100 & 1.9 ± 0.1 & 0.1 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & GatedAdditiveTreeEnsembleConfig_tab & 0.164 & 0.205 & 0.074 & 0.280 & 0.180 ± 0.074 & 1.8 ± 0.1 & 16.3 ± 1.9 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet & 0.251 & 0.171 & 0.143 & 0.156 & 0.180 ± 0.042 & 2.7 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskLasso_tuned & 0.195 & 0.107 & -0.001 & 0.356 & 0.164 ± 0.131 & 1.8 ± 0.0 & 1.1 ± 0.0 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & LinearRegression & 0.174 & 0.095 & -0.014 & 0.356 & 0.152 ± 0.135 & 2.0 ± 0.1 & 0.2 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & 0.219 & 0.097 & -0.028 & 0.298 & 0.146 ± 0.124 & nan ± nan & 0.9 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & 0.020 & 0.226 & 0.006 & 0.304 & 0.139 ± 0.129 & nan ± nan & 12.8 ± 0.8 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & 0.206 & 0.084 & -0.048 & 0.290 & 0.133 ± 0.128 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskElasticNet & 0.074 & 0.147 & 0.040 & 0.065 & 0.081 ± 0.040 & 4.1 ± 0.3 & 0.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabNetRegressor_default & 0.360 & -0.094 & -0.219 & 0.273 & 0.080 ± 0.242 & 4.4 ± 0.6 & 58.7 ± 1.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskElasticNet & -0.110 & 0.026 & -0.002 & 0.063 & -0.006 ± 0.064 & 1.9 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & -0.110 & 0.026 & -0.002 & 0.063 & -0.006 ± 0.064 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & DANetConfig_tab & 0.062 & -0.007 & -0.019 & -0.100 & -0.016 ± 0.057 & 2.5 ± 0.0 & 1.7 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso & -0.016 & -0.063 & -0.000 & -0.073 & -0.038 ± 0.031 & 2.7 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskLasso & -0.071 & -0.004 & -0.014 & -0.066 & -0.039 ± 0.030 & 4.4 ± 0.6 & 0.1 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetModelConfig_tab & -0.013 & 0.278 & -0.429 & -0.008 & -0.043 ± 0.252 & 2.5 ± 0.0 & 1.7 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabNetRegressor_custom & 0.171 & 0.045 & -0.691 & 0.199 & -0.069 ± 0.364 & 4.0 ± 0.5 & 59.0 ± 1.6 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabNetModelConfig_tab & -0.142 & -0.013 & -0.166 & -0.154 & -0.119 ± 0.062 & 4.2 ± 0.6 & 5.7 ± 0.4 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskLasso & -0.195 & -0.078 & -0.083 & -0.121 & -0.119 ± 0.047 & 1.8 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & -0.195 & -0.078 & -0.083 & -0.121 & -0.119 ± 0.047 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & DANetConfig_tab & -0.220 & -0.056 & -0.108 & -0.157 & -0.135 ± 0.061 & 4.1 ± 0.6 & 5.2 ± 0.4 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabTransformerConfig_tab & 0.071 & -0.438 & -0.308 & -0.121 & -0.199 ± 0.192 & 2.5 ± 0.1 & 1.5 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabNetModelConfig_tab & -0.832 & -0.018 & 0.090 & -0.080 & -0.210 ± 0.364 & 1.8 ± 0.1 & 1.8 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & DANetConfig_tab & -0.422 & -0.062 & -0.084 & -0.360 & -0.232 ± 0.161 & 1.9 ± 0.2 & 1.9 ± 0.3 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabTransformerConfig_tab & -0.741 & 0.319 & -1.185 & -0.106 & -0.428 ± 0.577 & 1.9 ± 0.1 & 1.5 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabTransformerConfig_tab & -0.448 & -0.499 & -1.629 & 0.340 & -0.559 ± 0.702 & 4.4 ± 0.5 & 4.6 ± 0.4 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_r2 = generate_metric_table(\n",
    "    results_list=dict_results_loona,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='r2',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/4_training_loona_r2_adjusted_sorted.csv\",\n",
    "    sort_order=\"descending\"\n",
    ")\n",
    "print(latex_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "continuous_imputer & ordinal_imputer & model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & mean ± std & imp_time (s) & fit_time (s) \\\\\n",
      "\\midrule\n",
      "KNNImputer_5 & KNNImputer1 & GatedAdditiveTreeEnsembleConfig_tab & 0.519 & 0.547 & 0.522 & 0.513 & 0.525 ± 0.013 & 4.2 ± 0.3 & 36.4 ± 1.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & PLSRegression_4_components & 0.496 & 0.544 & 0.511 & 0.568 & 0.530 ± 0.028 & 4.1 ± 0.4 & 0.7 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskElasticNet_tuned & 0.457 & 0.569 & 0.568 & 0.560 & 0.539 ± 0.047 & 4.0 ± 0.5 & 2.7 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & XGBoostRegressor_tuned & 0.501 & 0.561 & 0.571 & 0.555 & 0.547 ± 0.027 & 4.1 ± 0.6 & 408.4 ± 2.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & XGBoostRegressor & 0.529 & 0.554 & 0.516 & 0.610 & 0.553 ± 0.036 & 4.1 ± 0.6 & 165.8 ± 2.6 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskLasso_tuned & 0.467 & 0.613 & 0.604 & 0.606 & 0.573 ± 0.061 & 4.0 ± 0.6 & 1.6 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & LinearRegression & 0.470 & 0.621 & 0.608 & 0.612 & 0.578 ± 0.063 & 3.9 ± 0.5 & 2.7 ± 0.5 \\\\\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor & 0.638 & 0.520 & 0.573 & 0.617 & 0.587 ± 0.045 & 2.5 ± 0.0 & 1.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & RandomForestRegressor & 0.603 & 0.648 & 0.561 & 0.617 & 0.607 ± 0.031 & 4.2 ± 0.6 & 74.6 ± 2.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & RandomForestRegressor & 0.688 & 0.549 & 0.548 & 0.695 & 0.620 ± 0.072 & 2.5 ± 0.1 & 39.4 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskElasticNet & 0.686 & 0.659 & 0.497 & 0.734 & 0.644 ± 0.089 & 4.1 ± 0.3 & 0.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabNetRegressor_default & 0.579 & 0.766 & 0.591 & 0.640 & 0.644 ± 0.074 & 4.4 ± 0.6 & 58.7 ± 1.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & GatedAdditiveTreeEnsembleConfig_tab & 0.636 & 0.612 & 0.608 & 0.753 & 0.652 ± 0.059 & 2.5 ± 0.0 & 16.3 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer & PLSRegression_4_components & 0.615 & 0.613 & 0.581 & 0.815 & 0.656 ± 0.093 & 2.6 ± 0.0 & 0.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor_tuned & 0.628 & 0.619 & 0.666 & 0.721 & 0.659 ± 0.040 & 2.5 ± 0.1 & 4.6 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet_tuned & 0.615 & 0.688 & 0.553 & 0.802 & 0.665 ± 0.093 & 2.7 ± 0.1 & 1.4 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_default & 0.604 & 0.683 & 0.565 & 0.811 & 0.666 ± 0.094 & 2.6 ± 0.0 & 12.6 ± 0.7 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabNetRegressor_custom & 0.620 & 0.749 & 0.664 & 0.646 & 0.670 ± 0.048 & 4.0 ± 0.5 & 59.0 ± 1.6 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & XGBoostRegressor & 0.746 & 0.863 & 0.510 & 0.651 & 0.693 ± 0.129 & 1.8 ± 0.0 & 1.2 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskLasso & 0.752 & 0.731 & 0.500 & 0.808 & 0.698 ± 0.117 & 4.4 ± 0.6 & 0.1 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_custom & 0.677 & 0.552 & 0.761 & 0.809 & 0.700 ± 0.098 & 2.5 ± 0.1 & 13.0 ± 0.6 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 0.788 & 0.781 & 0.525 & 0.708 & 0.700 ± 0.106 & nan ± nan & 12.8 ± 0.5 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & 0.760 & 0.831 & 0.532 & 0.725 & 0.712 ± 0.111 & nan ± nan & 0.8 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 0.811 & 0.831 & 0.512 & 0.700 & 0.713 ± 0.127 & nan ± nan & 32.0 ± 0.5 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso_tuned & 0.665 & 0.780 & 0.567 & 0.849 & 0.715 ± 0.108 & 2.6 ± 0.0 & 1.1 ± 0.0 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskElasticNet_tuned & 0.730 & 0.852 & 0.600 & 0.687 & 0.718 ± 0.091 & 1.9 ± 0.1 & 1.3 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & DANetConfig_tab & 0.788 & 0.753 & 0.514 & 0.820 & 0.719 ± 0.121 & 4.1 ± 0.6 & 5.2 ± 0.4 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & RandomForestRegressor & 0.817 & 0.813 & 0.532 & 0.726 & 0.722 ± 0.116 & 1.9 ± 0.2 & 40.8 ± 1.9 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabNetRegressor_custom & 0.743 & 0.764 & 0.649 & 0.737 & 0.723 ± 0.044 & 1.9 ± 0.0 & 13.8 ± 1.3 \\\\\n",
      "KNNImputer_5 & KNNImputer & LinearRegression & 0.669 & 0.788 & 0.575 & 0.865 & 0.724 ± 0.111 & 2.6 ± 0.1 & 0.1 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabNetModelConfig_tab & 0.755 & 0.767 & 0.547 & 0.847 & 0.729 ± 0.111 & 4.2 ± 0.6 & 5.7 ± 0.4 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & 0.830 & 0.813 & 0.618 & 0.661 & 0.730 ± 0.093 & nan ± nan & 3.9 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskLasso_tuned & 0.765 & 0.917 & 0.559 & 0.681 & 0.730 ± 0.130 & 1.8 ± 0.0 & 1.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & 0.744 & 0.870 & 0.597 & 0.714 & 0.731 ± 0.097 & nan ± nan & 1.2 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & LinearRegression & 0.766 & 0.926 & 0.555 & 0.681 & 0.732 ± 0.135 & 2.0 ± 0.1 & 0.2 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & GatedAdditiveTreeEnsembleConfig_tab & 0.793 & 0.870 & 0.581 & 0.686 & 0.733 ± 0.109 & 1.8 ± 0.1 & 16.3 ± 1.9 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabNetRegressor_default & 0.836 & 0.840 & 0.509 & 0.748 & 0.733 ± 0.135 & 1.8 ± 0.1 & 13.3 ± 0.6 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & XGBoostRegressor_tuned & 0.852 & 0.819 & 0.578 & 0.689 & 0.734 ± 0.109 & 1.8 ± 0.1 & 5.1 ± 0.2 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & 0.799 & 0.817 & 0.614 & 0.724 & 0.738 ± 0.080 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & 0.887 & 0.782 & 0.663 & 0.656 & 0.747 ± 0.095 & nan ± nan & 12.8 ± 0.8 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & PLSRegression_4_components & 0.813 & 0.838 & 0.627 & 0.719 & 0.749 ± 0.083 & 1.9 ± 0.1 & 0.1 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & 0.755 & 0.954 & 0.583 & 0.757 & 0.762 ± 0.131 & nan ± nan & 0.9 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & 0.759 & 0.962 & 0.588 & 0.761 & 0.768 ± 0.133 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabTransformerConfig_tab & 0.903 & 0.843 & 0.797 & 0.630 & 0.793 ± 0.101 & 4.4 ± 0.5 & 4.6 ± 0.4 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskElasticNet & 0.947 & 0.908 & 0.615 & 0.844 & 0.829 ± 0.129 & 1.9 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & 0.947 & 0.908 & 0.615 & 0.844 & 0.829 ± 0.129 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet & 0.848 & 0.812 & 0.682 & 0.994 & 0.834 ± 0.111 & 2.7 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & 0.958 & 0.936 & 0.622 & 0.894 & 0.852 ± 0.135 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskLasso & 0.958 & 0.936 & 0.622 & 0.894 & 0.852 ± 0.135 & 1.8 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & DANetConfig_tab & 1.028 & 0.918 & 0.621 & 1.003 & 0.892 ± 0.162 & 1.9 ± 0.2 & 1.9 ± 0.3 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabNetModelConfig_tab & 1.216 & 0.986 & 0.588 & 0.903 & 0.923 ± 0.225 & 1.8 ± 0.1 & 1.8 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & DANetConfig_tab & 0.912 & 0.942 & 0.750 & 1.152 & 0.939 ± 0.143 & 2.5 ± 0.0 & 1.7 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso & 1.015 & 0.955 & 0.733 & 1.140 & 0.961 ± 0.147 & 2.7 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetModelConfig_tab & 0.976 & 0.898 & 0.905 & 1.127 & 0.976 ± 0.092 & 2.5 ± 0.0 & 1.7 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabTransformerConfig_tab & 1.206 & 0.817 & 1.009 & 0.917 & 0.987 ± 0.143 & 1.9 ± 0.1 & 1.5 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabTransformerConfig_tab & 0.960 & 1.205 & 0.967 & 1.168 & 1.075 ± 0.112 & 2.5 ± 0.1 & 1.5 ± 0.1 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=dict_results_loona,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='mae',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/4_training_loona_mae_adjusted_sorted.csv\",\n",
    "    sort_order=\"ascending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "continuous_imputer & ordinal_imputer & model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & mean ± std & imp_time (s) & fit_time (s) \\\\\n",
      "\\midrule\n",
      "KNNImputer_5 & KNNImputer1 & PLSRegression_4_components & 0.388 & 0.420 & 0.337 & 0.537 & 0.420 ± 0.074 & 4.1 ± 0.4 & 0.7 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & GatedAdditiveTreeEnsembleConfig_tab & 0.389 & 0.443 & 0.374 & 0.515 & 0.430 ± 0.055 & 4.2 ± 0.3 & 36.4 ± 1.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskElasticNet_tuned & 0.321 & 0.480 & 0.421 & 0.577 & 0.450 ± 0.093 & 4.0 ± 0.5 & 2.7 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & XGBoostRegressor & 0.435 & 0.489 & 0.367 & 0.647 & 0.484 ± 0.103 & 4.1 ± 0.6 & 165.8 ± 2.6 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & XGBoostRegressor_tuned & 0.396 & 0.543 & 0.454 & 0.586 & 0.495 ± 0.074 & 4.1 ± 0.6 & 408.4 ± 2.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskLasso_tuned & 0.354 & 0.562 & 0.528 & 0.653 & 0.524 ± 0.109 & 4.0 ± 0.6 & 1.6 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & LinearRegression & 0.363 & 0.574 & 0.541 & 0.667 & 0.536 ± 0.110 & 3.9 ± 0.5 & 2.7 ± 0.5 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & RandomForestRegressor & 0.569 & 0.587 & 0.420 & 0.714 & 0.573 ± 0.105 & 4.2 ± 0.6 & 74.6 ± 2.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor & 0.740 & 0.488 & 0.563 & 0.756 & 0.637 ± 0.115 & 2.5 ± 0.0 & 1.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabNetRegressor_default & 0.502 & 0.905 & 0.490 & 0.714 & 0.653 ± 0.171 & 4.4 ± 0.6 & 58.7 ± 1.1 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskElasticNet & 0.726 & 0.706 & 0.386 & 0.918 & 0.684 ± 0.191 & 4.1 ± 0.3 & 0.1 ± 0.0 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & XGBoostRegressor & 0.782 & 1.040 & 0.343 & 0.636 & 0.700 ± 0.252 & 1.8 ± 0.0 & 1.2 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & RandomForestRegressor & 0.803 & 0.560 & 0.541 & 0.918 & 0.706 ± 0.160 & 2.5 ± 0.1 & 39.4 ± 0.3 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & 0.803 & 0.997 & 0.358 & 0.701 & 0.715 ± 0.232 & nan ± nan & 0.8 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabNetRegressor_custom & 0.650 & 0.790 & 0.680 & 0.786 & 0.727 ± 0.063 & 4.0 ± 0.5 & 59.0 ± 1.6 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 0.913 & 1.044 & 0.381 & 0.625 & 0.741 ± 0.257 & nan ± nan & 12.8 ± 0.5 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_default & 0.634 & 0.708 & 0.557 & 1.112 & 0.753 ± 0.214 & 2.6 ± 0.0 & 12.6 ± 0.7 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 0.881 & 1.111 & 0.380 & 0.657 & 0.757 ± 0.270 & nan ± nan & 32.0 ± 0.5 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & RandomForestRegressor & 0.907 & 1.042 & 0.414 & 0.732 & 0.774 ± 0.235 & 1.9 ± 0.2 & 40.8 ± 1.9 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & MultiTaskLasso & 0.839 & 0.831 & 0.408 & 1.047 & 0.781 ± 0.232 & 4.4 ± 0.6 & 0.1 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabNetRegressor_custom & 0.828 & 0.940 & 0.555 & 0.804 & 0.782 ± 0.141 & 1.9 ± 0.0 & 13.8 ± 1.3 \\\\\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor_tuned & 0.774 & 0.688 & 0.739 & 0.941 & 0.785 ± 0.095 & 2.5 ± 0.1 & 4.6 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskElasticNet_tuned & 0.797 & 1.096 & 0.580 & 0.708 & 0.795 ± 0.190 & 1.9 ± 0.1 & 1.3 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & 0.802 & 1.101 & 0.573 & 0.712 & 0.797 ± 0.194 & nan ± nan & 1.2 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & 0.959 & 0.960 & 0.531 & 0.755 & 0.801 ± 0.177 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & 1.056 & 1.003 & 0.509 & 0.643 & 0.803 ± 0.232 & nan ± nan & 3.9 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet_tuned & 0.627 & 0.896 & 0.591 & 1.142 & 0.814 ± 0.223 & 2.7 ± 0.1 & 1.4 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & PLSRegression_4_components & 0.609 & 0.833 & 0.645 & 1.189 & 0.819 ± 0.230 & 2.6 ± 0.0 & 0.1 ± 0.0 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & XGBoostRegressor_tuned & 0.980 & 1.106 & 0.516 & 0.720 & 0.830 ± 0.229 & 1.8 ± 0.1 & 5.1 ± 0.2 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabNetRegressor_default & 1.034 & 1.100 & 0.344 & 0.849 & 0.832 ± 0.296 & 1.8 ± 0.1 & 13.3 ± 0.6 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabNetModelConfig_tab & 0.895 & 0.838 & 0.469 & 1.132 & 0.834 ± 0.238 & 4.2 ± 0.6 & 5.7 ± 0.4 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & DANetConfig_tab & 0.957 & 0.874 & 0.446 & 1.136 & 0.853 ± 0.254 & 4.1 ± 0.6 & 5.2 ± 0.4 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & PLSRegression_4_components & 1.034 & 1.056 & 0.573 & 0.754 & 0.854 ± 0.201 & 1.9 ± 0.1 & 0.1 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & GatedAdditiveTreeEnsembleConfig_tab & 0.936 & 1.130 & 0.593 & 0.792 & 0.863 ± 0.197 & 1.8 ± 0.1 & 16.3 ± 1.9 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso_tuned & 0.645 & 1.011 & 0.646 & 1.186 & 0.872 ± 0.235 & 2.6 ± 0.0 & 1.1 ± 0.0 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskLasso_tuned & 0.900 & 1.269 & 0.641 & 0.708 & 0.880 ± 0.244 & 1.8 ± 0.0 & 1.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & LinearRegression & 0.647 & 1.030 & 0.656 & 1.202 & 0.884 ± 0.240 & 2.6 ± 0.1 & 0.1 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & LinearRegression & 0.924 & 1.287 & 0.650 & 0.708 & 0.892 ± 0.250 & 2.0 ± 0.1 & 0.2 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & 0.873 & 1.284 & 0.659 & 0.773 & 0.897 ± 0.236 & nan ± nan & 0.9 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & 1.097 & 1.101 & 0.637 & 0.766 & 0.900 ± 0.204 & nan ± nan & 12.8 ± 0.8 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & 0.888 & 1.303 & 0.671 & 0.781 & 0.911 ± 0.239 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & GatedAdditiveTreeEnsembleConfig_tab & 0.735 & 1.010 & 0.718 & 1.195 & 0.915 ± 0.199 & 2.5 ± 0.0 & 16.3 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_custom & 0.852 & 0.692 & 0.938 & 1.291 & 0.943 ± 0.219 & 2.5 ± 0.1 & 13.0 ± 0.6 \\\\\n",
      "KNNImputer_5 & KNNImputer1 & TabTransformerConfig_tab & 1.135 & 1.240 & 1.057 & 0.648 & 1.020 ± 0.225 & 4.4 ± 0.5 & 4.6 ± 0.4 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskElasticNet & 1.241 & 1.385 & 0.642 & 1.031 & 1.075 ± 0.280 & 1.9 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & 1.241 & 1.385 & 0.642 & 1.031 & 1.075 ± 0.280 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & 1.337 & 1.533 & 0.694 & 1.233 & 1.199 ± 0.311 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & MultiTaskLasso & 1.337 & 1.533 & 0.694 & 1.233 & 1.199 ± 0.311 & 1.8 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet & 1.157 & 1.246 & 0.921 & 1.804 & 1.282 ± 0.324 & 2.7 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabNetModelConfig_tab & 2.049 & 1.447 & 0.583 & 1.188 & 1.317 ± 0.527 & 1.8 ± 0.1 & 1.8 ± 0.1 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & DANetConfig_tab & 1.591 & 1.510 & 0.694 & 1.496 & 1.323 ± 0.365 & 1.9 ± 0.2 & 1.9 ± 0.3 \\\\\n",
      "KNNImputer & SimpleImputer_most_frequent & TabTransformerConfig_tab & 1.947 & 0.969 & 1.400 & 1.217 & 1.383 ± 0.360 & 1.9 ± 0.1 & 1.5 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetModelConfig_tab & 1.564 & 1.084 & 1.536 & 2.155 & 1.584 ± 0.380 & 2.5 ± 0.0 & 1.7 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & DANetConfig_tab & 1.448 & 1.513 & 1.095 & 2.350 & 1.602 ± 0.460 & 2.5 ± 0.0 & 1.7 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso & 1.569 & 1.597 & 1.075 & 2.292 & 1.633 ± 0.434 & 2.7 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabTransformerConfig_tab & 1.434 & 2.160 & 1.406 & 2.396 & 1.849 ± 0.437 & 2.5 ± 0.1 & 1.5 ± 0.1 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mse = generate_metric_table(\n",
    "    results_list=dict_results_loona,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='mse',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/4_training_loona_mse_adjusted_sorted.csv\",\n",
    "    sort_order=\"ascending\"\n",
    ")\n",
    "print(latex_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
