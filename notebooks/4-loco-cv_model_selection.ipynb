{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import timeit\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "from itertools import product\n",
    "import warnings\n",
    "\n",
    "# System path modification\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning imports\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer, MissingIndicator\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, KFold, StratifiedKFold, GroupKFold, StratifiedGroupKFold, LeaveOneOut, cross_validate, cross_val_score\n",
    ")\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, Lasso, LassoCV, MultiTaskLasso, MultiTaskLassoCV,\n",
    "    ElasticNet, ElasticNetCV, MultiTaskElasticNet, MultiTaskElasticNetCV\n",
    ")\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Statistic imports \n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.special import kl_div\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Specialized imputation and visualization packages\n",
    "import miceforest as mf\n",
    "import missingno as msno\n",
    "#from missforest import MissForest\n",
    "#import magic\n",
    "from src.gain import *\n",
    "\n",
    "# Custom modules\n",
    "from src.train import *\n",
    "from src.functions import *\n",
    "from src.plots import *\n",
    "from src.dataset import *\n",
    "from src.multixgboost import *\n",
    "from src.wrapper import *\n",
    "from src.debug import *\n",
    "\n",
    "# Visualizatiokn \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning and machine learning specific \n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "from pytorch_tabular.config import DataConfig, TrainerConfig, OptimizerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.models import (\n",
    "    GatedAdditiveTreeEnsembleConfig,\n",
    "    DANetConfig,\n",
    "    TabTransformerConfig,\n",
    "    TabNetModelConfig,\n",
    ")\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Print CUDA availability for PyTorch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_pickle_data_palettes()\n",
    "\n",
    "results_pickle_folder = \"../pickle/\"\n",
    "\n",
    "# Unpack data\n",
    "df_X, df_y, df_all, df_FinalCombination = data[\"df_X\"], data[\"df_y\"], data[\"df_all\"], data[\"df_FinalCombination\"]\n",
    "dict_select = data[\"dict_select\"]\n",
    "\n",
    "# Unpack colormaps\n",
    "full_palette, gender_palette, dx_palette = data[\"colormaps\"].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "3609    2002\n",
      "5631    4167\n",
      "5662    4176\n",
      "5780    4215\n",
      "5950    4349\n",
      "6069    4292\n",
      "6077    4453\n",
      "6085    4489\n",
      "6224    4505\n",
      "6400    4576\n",
      "6429    4300\n",
      "7021    2374\n",
      "7192    4179\n",
      "Name: RID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "idx_train = list(df_X.isna().any(axis=1))\n",
    "idx_test = list(~df_X.isna().any(axis=1))\n",
    "\n",
    "set_intersect_rid = set(df_all[idx_train].RID).intersection(set(df_all[idx_test].RID))\n",
    "intersect_rid_idx = df_all.RID.isin(set_intersect_rid)\n",
    "\n",
    "for i, bool_test in enumerate(idx_test): \n",
    "    if intersect_rid_idx.iloc[i] & bool_test:\n",
    "        idx_test[i] = False\n",
    "        idx_train[i] = True\n",
    "\n",
    "print(sum(idx_test))\n",
    "\n",
    "print(df_all[idx_test].RID)\n",
    "\n",
    "df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]] = df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]].astype(\"category\")\n",
    "\n",
    "test_indices = [i for i, val in enumerate(idx_test) if val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-One-Complete-Out (LOCO-CV)\n",
    "\n",
    "## All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: LinearRegression\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: MultiTaskElasticNet\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: MultiTaskElasticNet_tuned\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: MultiTaskLasso\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: MultiTaskLasso_tuned\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: RandomForestRegressor\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: XGBoostRegressor\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: XGBoostRegressor_tuned\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: TabNetRegressor_default\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: TabNetRegressor_custom\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: PLSRegression_4_components\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: GatedAdditiveTreeEnsembleConfig_tab\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: DANetConfig_tab\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: TabTransformerConfig_tab\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: TabNetModelConfig_tab\n",
      "Combinations of preprocessing and models to test : 15\n"
     ]
    }
   ],
   "source": [
    "random_state=42\n",
    "n_imputation_iter = 10\n",
    "\n",
    "# Continuous Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "continuous_imputer_list = [\n",
    "    #(\"SimpleImputer_mean\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"KNNImputer\", KNNImputer(n_neighbors=1)),\n",
    "]\n",
    "\n",
    "# Ordinal Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "ordinal_imputer_list = [\n",
    "    (\"SimpleImputer_most_frequent\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "]\n",
    "\n",
    "# Predictive Models List (list of tuples with unique strings and corresponding instances)\n",
    "predictive_models_list = [\n",
    "    (\"LinearRegression\", LinearRegression()),\n",
    "    (\"MultiTaskElasticNet\", MultiTaskElasticNet()),\n",
    "    (\"MultiTaskElasticNet_tuned\", MultiTaskElasticNet(**{'alpha': 0.01, 'l1_ratio': 0.01})),\n",
    "    (\"MultiTaskLasso\", MultiTaskLasso()),\n",
    "    (\"MultiTaskLasso_tuned\", MultiTaskLasso(**{'alpha': 0.001})),\n",
    "    (\"RandomForestRegressor\", RandomForestRegressor()),\n",
    "    (\"XGBoostRegressor\", XGBoostRegressor()),\n",
    "    (\"XGBoostRegressor_tuned\", XGBoostRegressor(**{'colsample_bytree': 0.5079831261101071, 'learning_rate': 0.0769592094304232, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.8049983288913105})),\n",
    "    (\"TabNetRegressor_default\", TabNetModelWrapper(n_a=8, n_d=8)),\n",
    "    (\"TabNetRegressor_custom\", TabNetModelWrapper(n_a=32, n_d=32)),\n",
    "    (\"PLSRegression_4_components\", PLSRegression(n_components=4))\n",
    "]\n",
    "\n",
    "ordinal_features = ['APOE_epsilon2', 'APOE_epsilon3', 'APOE_epsilon4']\n",
    "continuous_features = [col for col in df_X.columns if col not in ordinal_features]\n",
    "\n",
    "# Prepare Tabular configurations (shared for all PyTorch models)\n",
    "data_config = DataConfig(\n",
    "    target=df_y.columns.tolist(),\n",
    "    continuous_cols=continuous_features,\n",
    "    categorical_cols=continuous_features\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024, max_epochs=1, auto_lr_find=True,\n",
    "    early_stopping=\"valid_loss\", early_stopping_mode=\"min\", early_stopping_patience=5,\n",
    "    checkpoints=\"valid_loss\", load_best=True, progress_bar=\"nones\",\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "head_config = LinearHeadConfig(dropout=0.1).__dict__\n",
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabNetModelConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]\n",
    "\n",
    "# Generate all combinations\n",
    "\n",
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "# Display all combinations\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    print(f\"Continuous Imputer: {continuous_imputer[0]}, Ordinal Imputer: {ordinal_imputer[0]}, Model: {model[0]}\")\n",
    "\n",
    "print(f\"Combinations of preprocessing and models to test : {len(combinations)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HDF5 file\n",
    "results_file = '../pickle/training_3_loonona_dict_results.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(results_file): \n",
    "    with open(results_file, \"rb\") as input_file:\n",
    "        all_dict_results = pickle.load(input_file)\n",
    "\n",
    "else : \n",
    "    all_dict_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed due to key-value match: fitting_time=None\n",
      "Removed due to key-value match: fitting_time=None\n",
      "Removed due to key-value match: fitting_time=None\n",
      "Removed due to key-value match: fitting_time=None\n",
      "Removed due to key-value match: fitting_time=None\n",
      "Removed due to key-value match: fitting_time=None\n"
     ]
    }
   ],
   "source": [
    "all_dict_results = clean_dict_list(all_dict_results, remove_if_none=False, remove_key_val={\"fitting_time\":None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing combination (subset match): ['SimpleImputer_most_frequent', 'KNNImputer', 'LinearRegression']\n",
      "Skipping existing combination (subset match): ['SimpleImputer_most_frequent', 'KNNImputer', 'MultiTaskElasticNet']\n",
      "Skipping existing combination (subset match): ['SimpleImputer_most_frequent', 'KNNImputer', 'MultiTaskElasticNet_tuned']\n",
      "Skipping existing combination (subset match): ['SimpleImputer_most_frequent', 'KNNImputer', 'MultiTaskLasso']\n",
      "Skipping existing combination (subset match): ['SimpleImputer_most_frequent', 'KNNImputer', 'MultiTaskLasso_tuned']\n",
      "Skipping existing combination (subset match): ['SimpleImputer_most_frequent', 'KNNImputer', 'RandomForestRegressor']\n",
      "Skipping existing combination (subset match): ['SimpleImputer_most_frequent', 'KNNImputer', 'XGBoostRegressor']\n",
      "Skipping existing combination (subset match): ['SimpleImputer_most_frequent', 'KNNImputer', 'XGBoostRegressor_tuned']\n",
      "Skipping existing combination (subset match): ['SimpleImputer_most_frequent', 'KNNImputer', 'TabNetRegressor_default']\n",
      "Skipping existing combination (subset match): ['SimpleImputer_most_frequent', 'KNNImputer', 'TabNetRegressor_custom']\n",
      "Skipping existing combination (subset match): ['SimpleImputer_most_frequent', 'KNNImputer', 'PLSRegression_4_components']\n",
      "1790\n",
      "Using separate imputers for ordinal and continuous data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">17:59:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">952</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m17:59:39\u001b[0m,\u001b[1;36m952\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">17:59:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">213</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m17:59:40\u001b[0m,\u001b[1;36m213\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">17:59:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">290</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m17:59:40\u001b[0m,\u001b[1;36m290\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">17:59:41</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">615</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model:                        \n",
       "GatedAdditiveTreeEnsembleModel                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m17:59:41\u001b[0m,\u001b[1;36m615\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model:                        \n",
       "GatedAdditiveTreeEnsembleModel                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    name_continuous_imputer, continuous_imputer_instance = continuous_imputer\n",
    "    name_ordinal_imputer, ordinal_imputer_instance = ordinal_imputer\n",
    "    name_model, model_instance = model\n",
    "\n",
    "    params = {\n",
    "            \"ordinal_imputer\": name_ordinal_imputer, \n",
    "            \"continuous_imputer\": name_continuous_imputer, \n",
    "            \"model\": name_model, \"train_shape\" : [df_X.shape[0]-1, df_X.shape[1]],\n",
    "            \"test_shape\": [1, df_X.shape[1]]\n",
    "        }\n",
    "    \n",
    "    # Define the subset of keys you care about\n",
    "    keys_to_check = ['ordinal_imputer', 'continuous_imputer', 'model']  # or whatever subset you want\n",
    "\n",
    "    # Check if a result in all_dict_results has the same values for just those keys\n",
    "    if any(all(result['params'].get(k) == params.get(k) for k in keys_to_check) for result in all_dict_results):\n",
    "        print(f\"Skipping existing combination (subset match): {[params[k] for k in keys_to_check]}\")\n",
    "        continue\n",
    "\n",
    "    dict_results = {\n",
    "            \"params\": params, \n",
    "            \"imputation_time\": [],\n",
    "            \"fitting_time\": [], \n",
    "            \"results_adj\": [], \n",
    "            \"results_org\": []\n",
    "        }\n",
    "\n",
    "    for test_nloc in test_indices: \n",
    "        print(test_nloc)\n",
    "\n",
    "        idx_train = [True for i in range(df_X.shape[0])]\n",
    "        idx_test = [False for i in range(df_X.shape[0])]\n",
    "\n",
    "        idx_test[test_nloc] = True\n",
    "        idx_train[test_nloc] = False\n",
    "\n",
    "        df_X_train = df_X.loc[idx_train]\n",
    "        df_X_test = df_X.loc[idx_test]\n",
    "\n",
    "        df_y_train = df_y.loc[idx_train]\n",
    "        df_y_test = df_y.loc[idx_test]\n",
    "\n",
    "        c_train = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_train]\n",
    "        c_test = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_test]\n",
    "\n",
    "        try: \n",
    "        \n",
    "            # Now you can call your `train_model` function with these components\n",
    "            fold_dict_results = train_imputer_model(\n",
    "                df_X_train, df_X_test, df_y_train, df_y_test,\n",
    "                c_train, c_test,\n",
    "                ordinal_imputer_instance, name_ordinal_imputer,\n",
    "                continuous_imputer_instance, name_continuous_imputer,\n",
    "                model_instance, name_model,\n",
    "                separate_imputers=True  # Or however you want to specify\n",
    "            )\n",
    "            \n",
    "            dict_results[\"imputation_time\"].append(fold_dict_results[\"imputation_time\"]) \n",
    "            dict_results[\"fitting_time\"].append(fold_dict_results[\"fitting_time\"])  \n",
    "            dict_results[\"results_adj\"].append(fold_dict_results[\"results_adj\"])  \n",
    "            dict_results[\"results_org\"].append(fold_dict_results[\"results_org\"])  \n",
    "\n",
    "        except Exception as e:  \n",
    "\n",
    "            print(e)\n",
    "            \n",
    "    # Optionally keep the all_dict_results list updated\n",
    "    all_dict_results.append(dict_results)\n",
    "\n",
    "    # Save the updated results back to the pickle file\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(all_dict_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open(results_file, 'wb') as handle:\n",
    "    pickle.dump(all_dict_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../pickle/training_3_loonona_dict_results.pickle'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_file, \"rb\") as input_file:\n",
    "    dict_results_loo_nona = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_nona = pd.json_normalize(dict_results_loo_nona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imputation_time</th>\n",
       "      <th>fitting_time</th>\n",
       "      <th>results_adj</th>\n",
       "      <th>results_org</th>\n",
       "      <th>params.ordinal_imputer</th>\n",
       "      <th>params.continuous_imputer</th>\n",
       "      <th>params.model</th>\n",
       "      <th>params.train_shape</th>\n",
       "      <th>params.test_shape</th>\n",
       "      <th>results_adj.mse_score</th>\n",
       "      <th>...</th>\n",
       "      <th>results_adj.corr</th>\n",
       "      <th>results_org.mse_score</th>\n",
       "      <th>results_org.mae_score</th>\n",
       "      <th>results_org.r2</th>\n",
       "      <th>results_org.explained_variance</th>\n",
       "      <th>results_org.corr</th>\n",
       "      <th>results_adj.y_pred</th>\n",
       "      <th>results_adj.y_test</th>\n",
       "      <th>results_org.y_pred</th>\n",
       "      <th>results_org.y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5.229451656341553, 5.224140405654907, 4.88628...</td>\n",
       "      <td>[0.13473129272460938, 0.16941094398498535, 0.1...</td>\n",
       "      <td>[{'y_pred': [[0.38339124 1.36452359 0.90239184...</td>\n",
       "      <td>[{'y_pred': [[0.57795035 1.56277408 0.77520515...</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[2893, 276]</td>\n",
       "      <td>[1, 276]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5.230526685714722, 5.0653698444366455, 4.9066...</td>\n",
       "      <td>[0.11099720001220703, 0.1282353401184082, 0.11...</td>\n",
       "      <td>[{'y_pred': [[0.10086017 0.10725904 0.05499171...</td>\n",
       "      <td>[{'y_pred': [[ 0.29541929  0.30550953 -0.07219...</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>MultiTaskElasticNet</td>\n",
       "      <td>[2893, 276]</td>\n",
       "      <td>[1, 276]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[5.669898509979248, 5.173243522644043, 5.43714...</td>\n",
       "      <td>[0.11304473876953125, 0.09992218017578125, 0.0...</td>\n",
       "      <td>[{'y_pred': [[-1.14021159e-10 -7.73913117e-10 ...</td>\n",
       "      <td>[{'y_pred': [[ 0.19455912  0.19825049 -0.12718...</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>MultiTaskLasso</td>\n",
       "      <td>[2893, 276]</td>\n",
       "      <td>[1, 276]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[5.4710493087768555, 4.276649236679077, 4.9804...</td>\n",
       "      <td>[83.91225457191467, 85.66633605957031, 82.1046...</td>\n",
       "      <td>[{'y_pred': [[0.02039783 0.14644362 0.105301  ...</td>\n",
       "      <td>[{'y_pred': [[ 0.21495695  0.34469411 -0.02188...</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[2893, 276]</td>\n",
       "      <td>[1, 276]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4.8368706703186035, 4.746110200881958, 5.2583...</td>\n",
       "      <td>[1.5729725360870361, 1.5240373611450195, 1.668...</td>\n",
       "      <td>[{'y_pred': [[ 0.48383513  0.326277    0.18075...</td>\n",
       "      <td>[{'y_pred': [[0.67839425 0.52452748 0.05356718...</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>XGBoostRegressor</td>\n",
       "      <td>[2893, 276]</td>\n",
       "      <td>[1, 276]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>None</td>\n",
       "      <td>0.820673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>XGBoostRegressor</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>[1.396900592527884, 0.6808544922736753, 0.5201...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.31505040262294537, 0.6426285914558707, 0.21...</td>\n",
       "      <td>[1.39690059255922, 0.6808545021709723, 0.52016...</td>\n",
       "      <td>[0.8889444392281249, 0.719333032737343, 0.6592...</td>\n",
       "      <td>[-0.48594226232401594, 0.2372550720998049, -0....</td>\n",
       "      <td>[-0.05470367836475187, 0.4031941017700993, -0....</td>\n",
       "      <td>[0.28610400894431154, 0.6514650420855009, 0.28...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>None</td>\n",
       "      <td>0.546306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>XGBoostRegressor_tuned</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>[1.1700773910713715, 0.7772240853907448, 0.378...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.4529549822199553, 0.5938214250045247, 0.509...</td>\n",
       "      <td>[1.170077398099455, 0.7772240861956425, 0.3789...</td>\n",
       "      <td>[0.8496799883802885, 0.7068718997732054, 0.577...</td>\n",
       "      <td>[-0.2446608336250624, 0.1292945442861685, 0.26...</td>\n",
       "      <td>[0.13760970501821224, 0.268519270462352, 0.281...</td>\n",
       "      <td>[0.3751078181926709, 0.5833670677449029, 0.563...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>None</td>\n",
       "      <td>50.069587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>TabNetRegressor_default</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>[0.8170419227656482, 0.5715514449114356, 0.406...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.6031101606289643, 0.6537688516458474, 0.389...</td>\n",
       "      <td>[0.8170419241962154, 0.5715514425895181, 0.406...</td>\n",
       "      <td>[0.7375893486865746, 0.6424268457036709, 0.593...</td>\n",
       "      <td>[0.13087793668308434, 0.35970466159931236, 0.2...</td>\n",
       "      <td>[0.3283086405835556, 0.41955217263041966, 0.20...</td>\n",
       "      <td>[0.5732464874829685, 0.6525678487389671, 0.462...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>None</td>\n",
       "      <td>68.943131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>TabNetRegressor_custom</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>[0.8429184782224125, 0.8770448626618089, 0.568...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.6183710986346835, 0.38355286946032546, 0.08...</td>\n",
       "      <td>[0.8429184770950826, 0.8770448622425996, 0.568...</td>\n",
       "      <td>[0.7050968718750137, 0.8054401306859978, 0.699...</td>\n",
       "      <td>[0.10335195254326457, 0.01746772903253513, -0....</td>\n",
       "      <td>[0.34901351040167294, 0.08265360055931903, -0....</td>\n",
       "      <td>[0.5942827389282197, 0.38535348854043006, 0.16...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>None</td>\n",
       "      <td>0.043539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>PLSRegression_4_components</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>[1.0814090820211586, 0.7876511651265149, 0.569...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.4328608768006915, 0.4454234137390077, -0.05...</td>\n",
       "      <td>[1.0814090864925796, 0.7876511645655123, 0.569...</td>\n",
       "      <td>[0.7924841505728403, 0.7906801478543424, 0.721...</td>\n",
       "      <td>[-0.15034059906622033, 0.11761333910345118, -0...</td>\n",
       "      <td>[0.14275170798456394, 0.20609467187801855, -0....</td>\n",
       "      <td>[0.38124619506043567, 0.45398548757731494, 0.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      imputation_time  \\\n",
       "0   [5.229451656341553, 5.224140405654907, 4.88628...   \n",
       "1   [5.230526685714722, 5.0653698444366455, 4.9066...   \n",
       "2   [5.669898509979248, 5.173243522644043, 5.43714...   \n",
       "3   [5.4710493087768555, 4.276649236679077, 4.9804...   \n",
       "4   [4.8368706703186035, 4.746110200881958, 5.2583...   \n",
       "..                                                ...   \n",
       "94                                               None   \n",
       "95                                               None   \n",
       "96                                               None   \n",
       "97                                               None   \n",
       "98                                               None   \n",
       "\n",
       "                                         fitting_time  \\\n",
       "0   [0.13473129272460938, 0.16941094398498535, 0.1...   \n",
       "1   [0.11099720001220703, 0.1282353401184082, 0.11...   \n",
       "2   [0.11304473876953125, 0.09992218017578125, 0.0...   \n",
       "3   [83.91225457191467, 85.66633605957031, 82.1046...   \n",
       "4   [1.5729725360870361, 1.5240373611450195, 1.668...   \n",
       "..                                                ...   \n",
       "94                                           0.820673   \n",
       "95                                           0.546306   \n",
       "96                                          50.069587   \n",
       "97                                          68.943131   \n",
       "98                                           0.043539   \n",
       "\n",
       "                                          results_adj  \\\n",
       "0   [{'y_pred': [[0.38339124 1.36452359 0.90239184...   \n",
       "1   [{'y_pred': [[0.10086017 0.10725904 0.05499171...   \n",
       "2   [{'y_pred': [[-1.14021159e-10 -7.73913117e-10 ...   \n",
       "3   [{'y_pred': [[0.02039783 0.14644362 0.105301  ...   \n",
       "4   [{'y_pred': [[ 0.48383513  0.326277    0.18075...   \n",
       "..                                                ...   \n",
       "94                                                NaN   \n",
       "95                                                NaN   \n",
       "96                                                NaN   \n",
       "97                                                NaN   \n",
       "98                                                NaN   \n",
       "\n",
       "                                          results_org  \\\n",
       "0   [{'y_pred': [[0.57795035 1.56277408 0.77520515...   \n",
       "1   [{'y_pred': [[ 0.29541929  0.30550953 -0.07219...   \n",
       "2   [{'y_pred': [[ 0.19455912  0.19825049 -0.12718...   \n",
       "3   [{'y_pred': [[ 0.21495695  0.34469411 -0.02188...   \n",
       "4   [{'y_pred': [[0.67839425 0.52452748 0.05356718...   \n",
       "..                                                ...   \n",
       "94                                                NaN   \n",
       "95                                                NaN   \n",
       "96                                                NaN   \n",
       "97                                                NaN   \n",
       "98                                                NaN   \n",
       "\n",
       "         params.ordinal_imputer params.continuous_imputer  \\\n",
       "0   SimpleImputer_most_frequent                KNNImputer   \n",
       "1   SimpleImputer_most_frequent                KNNImputer   \n",
       "2   SimpleImputer_most_frequent                KNNImputer   \n",
       "3   SimpleImputer_most_frequent                KNNImputer   \n",
       "4   SimpleImputer_most_frequent                KNNImputer   \n",
       "..                          ...                       ...   \n",
       "94                    NoImputer                 NoImputer   \n",
       "95                    NoImputer                 NoImputer   \n",
       "96                    NoImputer                 NoImputer   \n",
       "97                    NoImputer                 NoImputer   \n",
       "98                    NoImputer                 NoImputer   \n",
       "\n",
       "                  params.model params.train_shape params.test_shape  \\\n",
       "0             LinearRegression        [2893, 276]          [1, 276]   \n",
       "1          MultiTaskElasticNet        [2893, 276]          [1, 276]   \n",
       "2               MultiTaskLasso        [2893, 276]          [1, 276]   \n",
       "3        RandomForestRegressor        [2893, 276]          [1, 276]   \n",
       "4             XGBoostRegressor        [2893, 276]          [1, 276]   \n",
       "..                         ...                ...               ...   \n",
       "94            XGBoostRegressor        (2881, 200)         (13, 200)   \n",
       "95      XGBoostRegressor_tuned        (2881, 200)         (13, 200)   \n",
       "96     TabNetRegressor_default        (2881, 200)         (13, 200)   \n",
       "97      TabNetRegressor_custom        (2881, 200)         (13, 200)   \n",
       "98  PLSRegression_4_components        (2881, 200)         (13, 200)   \n",
       "\n",
       "                                results_adj.mse_score  ...  \\\n",
       "0                                                 NaN  ...   \n",
       "1                                                 NaN  ...   \n",
       "2                                                 NaN  ...   \n",
       "3                                                 NaN  ...   \n",
       "4                                                 NaN  ...   \n",
       "..                                                ...  ...   \n",
       "94  [1.396900592527884, 0.6808544922736753, 0.5201...  ...   \n",
       "95  [1.1700773910713715, 0.7772240853907448, 0.378...  ...   \n",
       "96  [0.8170419227656482, 0.5715514449114356, 0.406...  ...   \n",
       "97  [0.8429184782224125, 0.8770448626618089, 0.568...  ...   \n",
       "98  [1.0814090820211586, 0.7876511651265149, 0.569...  ...   \n",
       "\n",
       "                                     results_adj.corr  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "94  [0.31505040262294537, 0.6426285914558707, 0.21...   \n",
       "95  [0.4529549822199553, 0.5938214250045247, 0.509...   \n",
       "96  [0.6031101606289643, 0.6537688516458474, 0.389...   \n",
       "97  [0.6183710986346835, 0.38355286946032546, 0.08...   \n",
       "98  [0.4328608768006915, 0.4454234137390077, -0.05...   \n",
       "\n",
       "                                results_org.mse_score  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "94  [1.39690059255922, 0.6808545021709723, 0.52016...   \n",
       "95  [1.170077398099455, 0.7772240861956425, 0.3789...   \n",
       "96  [0.8170419241962154, 0.5715514425895181, 0.406...   \n",
       "97  [0.8429184770950826, 0.8770448622425996, 0.568...   \n",
       "98  [1.0814090864925796, 0.7876511645655123, 0.569...   \n",
       "\n",
       "                                results_org.mae_score  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "94  [0.8889444392281249, 0.719333032737343, 0.6592...   \n",
       "95  [0.8496799883802885, 0.7068718997732054, 0.577...   \n",
       "96  [0.7375893486865746, 0.6424268457036709, 0.593...   \n",
       "97  [0.7050968718750137, 0.8054401306859978, 0.699...   \n",
       "98  [0.7924841505728403, 0.7906801478543424, 0.721...   \n",
       "\n",
       "                                       results_org.r2  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "94  [-0.48594226232401594, 0.2372550720998049, -0....   \n",
       "95  [-0.2446608336250624, 0.1292945442861685, 0.26...   \n",
       "96  [0.13087793668308434, 0.35970466159931236, 0.2...   \n",
       "97  [0.10335195254326457, 0.01746772903253513, -0....   \n",
       "98  [-0.15034059906622033, 0.11761333910345118, -0...   \n",
       "\n",
       "                       results_org.explained_variance  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "94  [-0.05470367836475187, 0.4031941017700993, -0....   \n",
       "95  [0.13760970501821224, 0.268519270462352, 0.281...   \n",
       "96  [0.3283086405835556, 0.41955217263041966, 0.20...   \n",
       "97  [0.34901351040167294, 0.08265360055931903, -0....   \n",
       "98  [0.14275170798456394, 0.20609467187801855, -0....   \n",
       "\n",
       "                                     results_org.corr results_adj.y_pred  \\\n",
       "0                                                 NaN                NaN   \n",
       "1                                                 NaN                NaN   \n",
       "2                                                 NaN                NaN   \n",
       "3                                                 NaN                NaN   \n",
       "4                                                 NaN                NaN   \n",
       "..                                                ...                ...   \n",
       "94  [0.28610400894431154, 0.6514650420855009, 0.28...                NaN   \n",
       "95  [0.3751078181926709, 0.5833670677449029, 0.563...                NaN   \n",
       "96  [0.5732464874829685, 0.6525678487389671, 0.462...                NaN   \n",
       "97  [0.5942827389282197, 0.38535348854043006, 0.16...                NaN   \n",
       "98  [0.38124619506043567, 0.45398548757731494, 0.0...                NaN   \n",
       "\n",
       "   results_adj.y_test results_org.y_pred results_org.y_test  \n",
       "0                 NaN                NaN                NaN  \n",
       "1                 NaN                NaN                NaN  \n",
       "2                 NaN                NaN                NaN  \n",
       "3                 NaN                NaN                NaN  \n",
       "4                 NaN                NaN                NaN  \n",
       "..                ...                ...                ...  \n",
       "94                NaN                NaN                NaN  \n",
       "95                NaN                NaN                NaN  \n",
       "96                NaN                NaN                NaN  \n",
       "97                NaN                NaN                NaN  \n",
       "98                NaN                NaN                NaN  \n",
       "\n",
       "[99 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_nona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train only on MRI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = list(df_X.isna().any(axis=1))\n",
    "idx_test = list(~df_X.isna().any(axis=1))\n",
    "\n",
    "set_intersect_rid = set(df_all[idx_train].RID).intersection(set(df_all[idx_test].RID))\n",
    "intersect_rid_idx = df_all.RID.isin(set_intersect_rid)\n",
    "\n",
    "for i, bool_test in enumerate(idx_test): \n",
    "    if intersect_rid_idx.iloc[i] & bool_test:\n",
    "        idx_test[i] = False\n",
    "        idx_train[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]] = df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train = df_X[dict_select[\"MRIth\"]].loc[idx_train]\n",
    "df_X_test = df_X[dict_select[\"MRIth\"]].loc[idx_test]\n",
    "\n",
    "df_y_train = df_y.loc[idx_train]\n",
    "df_y_test = df_y.loc[idx_test]\n",
    "\n",
    "c_train = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_train]\n",
    "c_test = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42\n",
    "n_imputation_iter = 10\n",
    "\n",
    "# Continuous Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "continuous_imputer_list = [\n",
    "    (\"NoImputer\", KNNImputer(n_neighbors=1)),\n",
    "\n",
    "]\n",
    "\n",
    "# Ordinal Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "ordinal_imputer_list = [\n",
    "    (\"NoImputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "]\n",
    "\n",
    "# Predictive Models List (list of tuples with unique strings and corresponding instances)\n",
    "predictive_models_list = [\n",
    "    (\"LinearRegression\", LinearRegression()),\n",
    "    (\"MultiTaskElasticNet\", MultiTaskElasticNet()),\n",
    "    (\"MultiTaskElasticNet_tuned\", MultiTaskElasticNet(**{'alpha': 0.01, 'l1_ratio': 0.01})),\n",
    "    (\"MultiTaskLasso\", MultiTaskLasso()),\n",
    "    (\"MultiTaskLasso_tuned\", MultiTaskLasso(**{'alpha': 0.001})),\n",
    "    (\"RandomForestRegressor\", RandomForestRegressor()),\n",
    "    (\"XGBoostRegressor\", XGBoostRegressor()),\n",
    "    (\"XGBoostRegressor_tuned\", XGBoostRegressor(**{'colsample_bytree': 0.5079831261101071, 'learning_rate': 0.0769592094304232, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.8049983288913105})),\n",
    "    (\"TabNetRegressor_default\", TabNetModelWrapper(n_a=8, n_d=8)),\n",
    "    (\"TabNetRegressor_custom\", TabNetModelWrapper(n_a=32, n_d=32)),\n",
    "    (\"PLSRegression_4_components\", PLSRegression(n_components=4))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: LinearRegression\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskElasticNet\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskElasticNet_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskLasso\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskLasso_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: RandomForestRegressor\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: XGBoostRegressor\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: XGBoostRegressor_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetRegressor_default\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetRegressor_custom\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: PLSRegression_4_components\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: GatedAdditiveTreeEnsembleConfig_tab\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: DANetConfig_tab\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabTransformerConfig_tab\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetModelConfig_tab\n",
      "Combinations of preprocessing and models to test : 15\n"
     ]
    }
   ],
   "source": [
    "ordinal_features = ['APOE_epsilon2', 'APOE_epsilon3', 'APOE_epsilon4']\n",
    "continuous_features = [col for col in df_X_train.columns if col not in ordinal_features]\n",
    "\n",
    "# Prepare Tabular configurations (shared for all PyTorch models)\n",
    "data_config = DataConfig(\n",
    "    target=df_y_train.columns.tolist(),\n",
    "    continuous_cols=continuous_features,\n",
    "    categorical_cols=[]\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024, max_epochs=1, auto_lr_find=True,\n",
    "    early_stopping=\"valid_loss\", early_stopping_mode=\"min\", early_stopping_patience=5,\n",
    "    checkpoints=\"valid_loss\", load_best=True, progress_bar=\"nones\",\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "head_config = LinearHeadConfig(dropout=0.1).__dict__\n",
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabNetModelConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "# Display all combinations\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    print(f\"Continuous Imputer: {continuous_imputer[0]}, Ordinal Imputer: {ordinal_imputer[0]}, Model: {model[0]}\")\n",
    "\n",
    "print(f\"Combinations of preprocessing and models to test : {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HDF5 file\n",
    "results_file = '../pickle/training_3_loonona_dict_results.pickle'\n",
    "\n",
    "with open('../pickle/training_3_loonona_dict_results.pickle', \"rb\") as input_file:\n",
    "    all_dict_results = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'LinearRegression']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'MultiTaskElasticNet']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'MultiTaskElasticNet_tuned']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'MultiTaskLasso']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'MultiTaskLasso_tuned']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'RandomForestRegressor']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'XGBoostRegressor']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'XGBoostRegressor_tuned']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'TabNetRegressor_default']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'TabNetRegressor_custom']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'PLSRegression_4_components']\n",
      "1790\n",
      "Using separate imputers for ordinal and continuous data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:06:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">892</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:06:51\u001b[0m,\u001b[1;36m892\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:06:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">935</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:06:51\u001b[0m,\u001b[1;36m935\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:06:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">947</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:06:51\u001b[0m,\u001b[1;36m947\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:06:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">991</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model:                        \n",
       "GatedAdditiveTreeEnsembleModel                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:06:51\u001b[0m,\u001b[1;36m991\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model:                        \n",
       "GatedAdditiveTreeEnsembleModel                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:06:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">444</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gate.gate_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">255</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:06:52\u001b[0m,\u001b[1;36m444\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gate.gate_model:\u001b[1;36m255\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:06:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">517</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:06:52\u001b[0m,\u001b[1;36m517\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:06:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">560</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:06:52\u001b[0m,\u001b[1;36m560\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45de4d1272774186b154fceb8775f442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "LR finder stopped early after 3 steps due to diverging loss.\n",
      "Failed to compute suggestion for learning rate because there are not enough points. Increase the loop iteration limits or the size of your dataset/dataloader.\n",
      "Restoring states from the checkpoint path at /home/chris/Documents/CHUV/PhD_project/Optimus/optimus/notebooks/.lr_find_484eddd4-a197-45dc-91a3-0a8e06b1eb43.ckpt\n",
      "Restored all states from the checkpoint at /home/chris/Documents/CHUV/PhD_project/Optimus/optimus/notebooks/.lr_find_484eddd4-a197-45dc-91a3-0a8e06b1eb43.ckpt\n",
      "Failed to compute suggestion for learning rate because there are not enough points. Increase the loop iteration limits or the size of your dataset/dataloader.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:07:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">790</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:07:06\u001b[0m,\u001b[1;36m790\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[3;35mNone\u001b[0m. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:07:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">818</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gate.gate_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">255</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:07:06\u001b[0m,\u001b[1;36m818\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gate.gate_model:\u001b[1;36m255\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:07:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">876</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:07:06\u001b[0m,\u001b[1;36m876\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name             | Type                       | Params | Mode \n",
      "------------------------------------------------------------------------\n",
      "0 | _backbone        | GatedAdditiveTreesBackbone | 2.1 M  | train\n",
      "1 | _embedding_layer | Embedding1dLayer           | 400    | train\n",
      "2 | _head            | CustomHead                 | 156    | train\n",
      "3 | loss             | MSELoss                    | 0      | train\n",
      "------------------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.417     Total estimated model params size (MB)\n",
      "689       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b81dc19fcad458ba0b0539133dc49bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0040800dfe643c49db8ad8583ff5744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de779db14c545b0b1cdf5b0392c2be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:07:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">878</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:07:20\u001b[0m,\u001b[1;36m878\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:07:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">881</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:07:20\u001b[0m,\u001b[1;36m881\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal values wrongly modified!\n",
      "2390\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:07:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">419</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:07:36\u001b[0m,\u001b[1;36m419\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:07:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">452</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:07:36\u001b[0m,\u001b[1;36m452\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:07:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">467</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:07:36\u001b[0m,\u001b[1;36m467\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:07:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">522</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model:                        \n",
       "GatedAdditiveTreeEnsembleModel                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:07:36\u001b[0m,\u001b[1;36m522\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model:                        \n",
       "GatedAdditiveTreeEnsembleModel                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:07:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">994</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gate.gate_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">255</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:07:36\u001b[0m,\u001b[1;36m994\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gate.gate_model:\u001b[1;36m255\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:07:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">069</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:07:37\u001b[0m,\u001b[1;36m069\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:07:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">117</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m18:07:37\u001b[0m,\u001b[1;36m117\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86a58c706fe4dd39241444e29b904d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'exit' is not defined\n",
      "2401\n",
      "Using separate imputers for ordinal and continuous data.\n"
     ]
    }
   ],
   "source": [
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    name_continuous_imputer, continuous_imputer_instance = continuous_imputer\n",
    "    name_ordinal_imputer, ordinal_imputer_instance = ordinal_imputer\n",
    "    name_model, model_instance = model\n",
    "\n",
    "    params = {\n",
    "            \"ordinal_imputer\": name_ordinal_imputer, \n",
    "            \"continuous_imputer\": name_continuous_imputer, \n",
    "            \"model\": name_model, \"train_shape\" : [df_X.shape[0]-1, df_X.shape[1]],\n",
    "            \"test_shape\": [1, df_X.shape[1]]\n",
    "        }\n",
    "    \n",
    "    # Define the subset of keys you care about\n",
    "    keys_to_check = ['ordinal_imputer', 'continuous_imputer', 'model']  # or whatever subset you want\n",
    "\n",
    "    # Check if a result in all_dict_results has the same values for just those keys\n",
    "    if any(all(result['params'].get(k) == params.get(k) for k in keys_to_check) for result in all_dict_results):\n",
    "        print(f\"Skipping existing combination (subset match): {[params[k] for k in keys_to_check]}\")\n",
    "        continue\n",
    "\n",
    "    dict_results = {\n",
    "            \"params\": params, \n",
    "            \"imputation_time\": [],\n",
    "            \"fitting_time\": [], \n",
    "            \"results_adj\": [], \n",
    "            \"results_org\": []\n",
    "        }\n",
    "\n",
    "    for test_nloc in test_indices: \n",
    "        print(test_nloc)\n",
    "\n",
    "        idx_train = [True for i in range(df_X.shape[0])]\n",
    "        idx_test = [False for i in range(df_X.shape[0])]\n",
    "\n",
    "        idx_test[test_nloc] = True\n",
    "        idx_train[test_nloc] = False\n",
    "\n",
    "        df_X_train = df_X.loc[idx_train]\n",
    "        df_X_test = df_X.loc[idx_test]\n",
    "\n",
    "        df_y_train = df_y.loc[idx_train]\n",
    "        df_y_test = df_y.loc[idx_test]\n",
    "\n",
    "        c_train = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_train]\n",
    "        c_test = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_test]\n",
    "\n",
    "        try: \n",
    "        \n",
    "            # Now you can call your `train_model` function with these components\n",
    "            fold_dict_results = train_imputer_model(\n",
    "                df_X_train, df_X_test, df_y_train, df_y_test,\n",
    "                c_train, c_test,\n",
    "                ordinal_imputer_instance, name_ordinal_imputer,\n",
    "                continuous_imputer_instance, name_continuous_imputer,\n",
    "                model_instance, name_model,\n",
    "                separate_imputers=True  # Or however you want to specify\n",
    "            )\n",
    "            \n",
    "            dict_results[\"imputation_time\"].append(fold_dict_results[\"imputation_time\"]) \n",
    "            dict_results[\"fitting_time\"].append(fold_dict_results[\"fitting_time\"])  \n",
    "            dict_results[\"results_adj\"].append(fold_dict_results[\"results_adj\"])  \n",
    "            dict_results[\"results_org\"].append(fold_dict_results[\"results_org\"])  \n",
    "\n",
    "        except Exception as e:  \n",
    "\n",
    "            print(e)\n",
    "            \n",
    "    # Optionally keep the all_dict_results list updated\n",
    "    all_dict_results.append(dict_results)\n",
    "\n",
    "    # Save the updated results back to the pickle file\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(all_dict_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open(results_file, 'wb') as handle:\n",
    "    pickle.dump(all_dict_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_file, \"rb\") as input_file:\n",
    "    all_dict_results = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Table for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/training_3_loonona_dict_results.pickle', \"rb\") as input_file:\n",
    "    dict_results_loo_nona = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imputation_time</th>\n",
       "      <th>fitting_time</th>\n",
       "      <th>results_adj</th>\n",
       "      <th>results_org</th>\n",
       "      <th>params.ordinal_imputer</th>\n",
       "      <th>params.continuous_imputer</th>\n",
       "      <th>params.model</th>\n",
       "      <th>params.train_shape</th>\n",
       "      <th>params.test_shape</th>\n",
       "      <th>results_adj.mse_score</th>\n",
       "      <th>results_adj.mae_score</th>\n",
       "      <th>results_adj.r2</th>\n",
       "      <th>results_adj.explained_variance</th>\n",
       "      <th>results_adj.corr</th>\n",
       "      <th>results_org.mse_score</th>\n",
       "      <th>results_org.mae_score</th>\n",
       "      <th>results_org.r2</th>\n",
       "      <th>results_org.explained_variance</th>\n",
       "      <th>results_org.corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3.3089418411254883, 3.2607581615448, 3.286860...</td>\n",
       "      <td>[0.11002111434936523, 0.24651741981506348, 0.1...</td>\n",
       "      <td>[{'y_pred': [[0.56338451 1.36697629 0.61842186...</td>\n",
       "      <td>[{'y_pred': [[0.75794363 1.56522677 0.49123517...</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>[2893, 348]</td>\n",
       "      <td>[1, 348]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3.4814867973327637, 3.5424869060516357, 3.515...</td>\n",
       "      <td>[0.08670425415039062, 0.08908843994140625, 0.0...</td>\n",
       "      <td>[{'y_pred': [[0.10086018 0.10725904 0.05499171...</td>\n",
       "      <td>[{'y_pred': [[ 0.29541929  0.30550953 -0.07219...</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>MultiTaskElasticNet</td>\n",
       "      <td>[2893, 348]</td>\n",
       "      <td>[1, 348]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3.544888734817505, 3.5088696479797363, 3.4993...</td>\n",
       "      <td>[1.513960361480713, 1.5192315578460693, 1.5161...</td>\n",
       "      <td>[{'y_pred': [[0.43508893 1.25141221 0.45281623...</td>\n",
       "      <td>[{'y_pred': [[0.62964805 1.4496627  0.32562954...</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>MultiTaskElasticNet_tuned</td>\n",
       "      <td>[2893, 348]</td>\n",
       "      <td>[1, 348]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[3.458850145339966, 3.4527065753936768, 3.4638...</td>\n",
       "      <td>[0.0770413875579834, 0.07488107681274414, 0.07...</td>\n",
       "      <td>[{'y_pred': [[-1.14021119e-10 -7.73912862e-10 ...</td>\n",
       "      <td>[{'y_pred': [[ 0.19455912  0.19825049 -0.12718...</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>MultiTaskLasso</td>\n",
       "      <td>[2893, 348]</td>\n",
       "      <td>[1, 348]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3.5399937629699707, 3.5302608013153076, 3.551...</td>\n",
       "      <td>[1.4914090633392334, 1.5125789642333984, 1.522...</td>\n",
       "      <td>[{'y_pred': [[0.50635131 1.33052966 0.55415854...</td>\n",
       "      <td>[{'y_pred': [[0.70091043 1.52878015 0.42697185...</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>MultiTaskLasso_tuned</td>\n",
       "      <td>[2893, 348]</td>\n",
       "      <td>[1, 348]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[3.5142085552215576, 3.3101305961608887, 3.446...</td>\n",
       "      <td>[52.41137504577637, 52.029266357421875, 51.895...</td>\n",
       "      <td>[{'y_pred': [[0.29340068 0.37610565 0.22158855...</td>\n",
       "      <td>[{'y_pred': [[0.48795979 0.57435613 0.09440186...</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[2893, 348]</td>\n",
       "      <td>[1, 348]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>XGBoostRegressor</td>\n",
       "      <td>[2893, 348]</td>\n",
       "      <td>[1, 348]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>XGBoostRegressor_tuned</td>\n",
       "      <td>[2893, 348]</td>\n",
       "      <td>[1, 348]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[3.467628240585327, 3.957735300064087, 3.52839...</td>\n",
       "      <td>[13.44585394859314, 14.944092273712158, 14.055...</td>\n",
       "      <td>[{'y_pred': [[-0.33021685  0.02510688  0.12306...</td>\n",
       "      <td>[{'y_pred': [[-0.13565774  0.22335736 -0.00412...</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>TabNetRegressor_default</td>\n",
       "      <td>[2893, 348]</td>\n",
       "      <td>[1, 348]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[3.212691068649292, 3.3576810359954834, 3.2116...</td>\n",
       "      <td>[12.390780925750732, 13.0169358253479, 12.1248...</td>\n",
       "      <td>[{'y_pred': [[0.38124186 0.36439073 0.21427807...</td>\n",
       "      <td>[{'y_pred': [[0.57580098 0.56264122 0.08709138...</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>TabNetRegressor_custom</td>\n",
       "      <td>[2893, 348]</td>\n",
       "      <td>[1, 348]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[3.6080546379089355, 3.3281357288360596, 3.487...</td>\n",
       "      <td>[0.15614581108093262, 0.14843535423278809, 0.1...</td>\n",
       "      <td>[{'y_pred': [[0.57530848 0.50261499 0.2766727 ...</td>\n",
       "      <td>[{'y_pred': [[0.7698676  0.70086548 0.14948601...</td>\n",
       "      <td>SimpleImputer_most_frequent</td>\n",
       "      <td>KNNImputer</td>\n",
       "      <td>PLSRegression_4_components</td>\n",
       "      <td>[2893, 348]</td>\n",
       "      <td>[1, 348]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>0.068446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>[1.1119234898099377, 0.676686264997117, 0.6199...</td>\n",
       "      <td>[0.7284983137064507, 0.7023597272362397, 0.709...</td>\n",
       "      <td>[-0.12379654970384224, 0.23213669686583083, -0...</td>\n",
       "      <td>[0.02475189284221302, 0.28845770677144666, -0....</td>\n",
       "      <td>[0.3320458491424125, 0.5476551369606042, 0.016...</td>\n",
       "      <td>[1.111923487408025, 0.6766862634588122, 0.6199...</td>\n",
       "      <td>[0.7284983177320566, 0.7023597287538657, 0.709...</td>\n",
       "      <td>[-0.18280005836581759, 0.24192464970535776, -0...</td>\n",
       "      <td>[-0.026452269431272546, 0.29752774244051705, -...</td>\n",
       "      <td>[0.27766053298168986, 0.5501268350934375, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>0.016177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>MultiTaskElasticNet</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>[1.1801224687295142, 0.9504153428153488, 0.507...</td>\n",
       "      <td>[0.8841416741691975, 0.7868357222322307, 0.653...</td>\n",
       "      <td>[-0.19272375369361128, -0.07847477070736275, -...</td>\n",
       "      <td>[0.11229868297941448, 0.03189858449038585, -0....</td>\n",
       "      <td>[0.42176385593133126, 0.17864276958690972, -0....</td>\n",
       "      <td>[1.1801224777332378, 0.9504153411821713, 0.507...</td>\n",
       "      <td>[0.8841416790017589, 0.78683572655586, 0.65378...</td>\n",
       "      <td>[-0.2553462098327579, -0.06472745435881033, 0....</td>\n",
       "      <td>[0.06569104121430824, 0.0442389812184012, 0.01...</td>\n",
       "      <td>[0.2586375518883661, 0.21083052633240612, 0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>MultiTaskElasticNet_tuned</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>None</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>MultiTaskLasso</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>[1.3936376654364884, 1.0405633863212842, 0.488...</td>\n",
       "      <td>[0.9912757529866387, 0.7845715674120901, 0.621...</td>\n",
       "      <td>[-0.4085188543166307, -0.18076940566326094, -0...</td>\n",
       "      <td>[-2.220446049250313e-16, 0.0, 0.0, 1.110223024...</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>[1.39363767778841, 1.040563386289657, 0.488669...</td>\n",
       "      <td>[0.9912757578191999, 0.7845715717907388, 0.621...</td>\n",
       "      <td>[-0.4824713618303562, -0.16571814171801091, 0....</td>\n",
       "      <td>[-0.05250374534439928, 0.012747008661847414, 0...</td>\n",
       "      <td>[-0.084866598168827, 0.1145532618513419, 0.272...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>MultiTaskLasso_tuned</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>None</td>\n",
       "      <td>32.180776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>[1.0004929827487936, 0.6583307726546211, 0.476...</td>\n",
       "      <td>[0.7462698406196145, 0.6893144678982224, 0.633...</td>\n",
       "      <td>[-0.011176193613992913, 0.2529654172194542, 0....</td>\n",
       "      <td>[0.29851275592520854, 0.40207199079436096, 0.0...</td>\n",
       "      <td>[0.5463813448253922, 0.6389458445773373, 0.230...</td>\n",
       "      <td>[1.0004929816978152, 0.6583307783476453, 0.476...</td>\n",
       "      <td>[0.7462698467726478, 0.6893144699477052, 0.633...</td>\n",
       "      <td>[-0.0642667148845999, 0.26248785832489097, 0.0...</td>\n",
       "      <td>[0.26168205835166036, 0.40969378155791614, 0.0...</td>\n",
       "      <td>[0.5116701022090266, 0.6455531281709198, 0.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>None</td>\n",
       "      <td>0.979116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>XGBoostRegressor</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>[0.9972977744677737, 0.5528588765184321, 0.498...</td>\n",
       "      <td>[0.754455924042236, 0.6345107831666245, 0.6429...</td>\n",
       "      <td>[-0.00794686706886405, 0.37264864819991916, -0...</td>\n",
       "      <td>[0.26511087910522013, 0.47604273516010087, -0....</td>\n",
       "      <td>[0.5217493590966826, 0.698490826142268, 0.2117...</td>\n",
       "      <td>[0.9972977727407778, 0.5528588798070297, 0.498...</td>\n",
       "      <td>[0.7544559347068825, 0.6345107852161074, 0.642...</td>\n",
       "      <td>[-0.060867835929641734, 0.3806454902291253, 0....</td>\n",
       "      <td>[0.22652645919993875, 0.4827216219837368, 0.03...</td>\n",
       "      <td>[0.4896643382156407, 0.7025785550998865, 0.273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>None</td>\n",
       "      <td>2.150189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>XGBoostRegressor_tuned</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>[1.015361101896433, 0.6385197295978015, 0.4634...</td>\n",
       "      <td>[0.7345770328134464, 0.7145827532706496, 0.630...</td>\n",
       "      <td>[-0.0262030737472283, 0.2754458099021808, 0.03...</td>\n",
       "      <td>[0.22165364381976016, 0.3489773943943325, 0.05...</td>\n",
       "      <td>[0.48104477356404635, 0.590754815507922, 0.306...</td>\n",
       "      <td>[1.0153611005115688, 0.638519728895267, 0.4634...</td>\n",
       "      <td>[0.7345770389664799, 0.7145827553201324, 0.630...</td>\n",
       "      <td>[-0.08008256192789931, 0.2846817006774043, 0.0...</td>\n",
       "      <td>[0.1807875566442022, 0.3572759857952956, 0.122...</td>\n",
       "      <td>[0.4467819127944371, 0.5977575782775101, 0.368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>None</td>\n",
       "      <td>12.833267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>TabNetRegressor_default</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>[1.0002425052752673, 0.852160951239341, 0.6231...</td>\n",
       "      <td>[0.7806465891501985, 0.8013238013969162, 0.679...</td>\n",
       "      <td>[-0.010923041555324087, 0.03301846562027699, -...</td>\n",
       "      <td>[0.3827598339020245, 0.13551578326538694, -0.2...</td>\n",
       "      <td>[0.6294661381345319, 0.47112118305582457, 0.06...</td>\n",
       "      <td>[1.0002425013137521, 0.8521609524638865, 0.623...</td>\n",
       "      <td>[0.780646592900706, 0.801323803446399, 0.67955...</td>\n",
       "      <td>[-0.06400026830239858, 0.045344574833686035, -...</td>\n",
       "      <td>[0.35035242511877496, 0.14653536835020642, -0....</td>\n",
       "      <td>[0.6085272367008092, 0.4852576960459974, 0.122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>None</td>\n",
       "      <td>11.839218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>TabNetRegressor_custom</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>[0.9261003635990263, 0.7642873814427985, 0.611...</td>\n",
       "      <td>[0.7133815430335131, 0.7584149374303166, 0.671...</td>\n",
       "      <td>[0.06401078596697707, 0.13273216316732506, -0....</td>\n",
       "      <td>[0.2220996090267332, 0.26101411024552224, -0.2...</td>\n",
       "      <td>[0.5532913119709318, 0.580845291517589, 0.2370...</td>\n",
       "      <td>[0.9261003504544436, 0.7642873867924493, 0.611...</td>\n",
       "      <td>[0.7133815361285443, 0.758414935004866, 0.6711...</td>\n",
       "      <td>[0.01486787447618565, 0.1437872175696555, -0.1...</td>\n",
       "      <td>[0.18125694946016357, 0.2704339649804939, -0.1...</td>\n",
       "      <td>[0.5379584649934801, 0.5901319798405044, 0.273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>None</td>\n",
       "      <td>0.049735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>PLSRegression_4_components</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>[1.081409082021159, 0.7876511651265149, 0.5694...</td>\n",
       "      <td>[0.7924841444198072, 0.7906801463917367, 0.721...</td>\n",
       "      <td>[-0.09295631069140176, 0.10622033184891166, -0...</td>\n",
       "      <td>[0.1855152043553444, 0.19584409010586212, -0.1...</td>\n",
       "      <td>[0.4328608768006912, 0.4454234137390073, -0.05...</td>\n",
       "      <td>[1.0814090864925796, 0.7876511645655125, 0.569...</td>\n",
       "      <td>[0.7924841505728405, 0.7906801478543428, 0.721...</td>\n",
       "      <td>[-0.15034059906622055, 0.11761333910345084, -0...</td>\n",
       "      <td>[0.14275170798456327, 0.2060946718780181, -0.1...</td>\n",
       "      <td>[0.38124619506043506, 0.4539854875773144, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>GatedAdditiveTreeEnsembleConfig_tab</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>DANetConfig_tab</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>TabTransformerConfig_tab</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>NoImputer</td>\n",
       "      <td>TabNetModelConfig_tab</td>\n",
       "      <td>(2881, 200)</td>\n",
       "      <td>(13, 200)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      imputation_time  \\\n",
       "0   [3.3089418411254883, 3.2607581615448, 3.286860...   \n",
       "1   [3.4814867973327637, 3.5424869060516357, 3.515...   \n",
       "2   [3.544888734817505, 3.5088696479797363, 3.4993...   \n",
       "3   [3.458850145339966, 3.4527065753936768, 3.4638...   \n",
       "4   [3.5399937629699707, 3.5302608013153076, 3.551...   \n",
       "5   [3.5142085552215576, 3.3101305961608887, 3.446...   \n",
       "6                                                  []   \n",
       "7                                                  []   \n",
       "8   [3.467628240585327, 3.957735300064087, 3.52839...   \n",
       "9   [3.212691068649292, 3.3576810359954834, 3.2116...   \n",
       "10  [3.6080546379089355, 3.3281357288360596, 3.487...   \n",
       "11                                               None   \n",
       "12                                               None   \n",
       "13                                               None   \n",
       "14                                               None   \n",
       "15                                               None   \n",
       "16                                               None   \n",
       "17                                               None   \n",
       "18                                               None   \n",
       "19                                               None   \n",
       "20                                               None   \n",
       "21                                               None   \n",
       "22                                               None   \n",
       "23                                               None   \n",
       "24                                               None   \n",
       "25                                               None   \n",
       "\n",
       "                                         fitting_time  \\\n",
       "0   [0.11002111434936523, 0.24651741981506348, 0.1...   \n",
       "1   [0.08670425415039062, 0.08908843994140625, 0.0...   \n",
       "2   [1.513960361480713, 1.5192315578460693, 1.5161...   \n",
       "3   [0.0770413875579834, 0.07488107681274414, 0.07...   \n",
       "4   [1.4914090633392334, 1.5125789642333984, 1.522...   \n",
       "5   [52.41137504577637, 52.029266357421875, 51.895...   \n",
       "6                                                  []   \n",
       "7                                                  []   \n",
       "8   [13.44585394859314, 14.944092273712158, 14.055...   \n",
       "9   [12.390780925750732, 13.0169358253479, 12.1248...   \n",
       "10  [0.15614581108093262, 0.14843535423278809, 0.1...   \n",
       "11                                           0.068446   \n",
       "12                                           0.016177   \n",
       "13                                               None   \n",
       "14                                           0.007943   \n",
       "15                                               None   \n",
       "16                                          32.180776   \n",
       "17                                           0.979116   \n",
       "18                                           2.150189   \n",
       "19                                          12.833267   \n",
       "20                                          11.839218   \n",
       "21                                           0.049735   \n",
       "22                                               None   \n",
       "23                                               None   \n",
       "24                                               None   \n",
       "25                                               None   \n",
       "\n",
       "                                          results_adj  \\\n",
       "0   [{'y_pred': [[0.56338451 1.36697629 0.61842186...   \n",
       "1   [{'y_pred': [[0.10086018 0.10725904 0.05499171...   \n",
       "2   [{'y_pred': [[0.43508893 1.25141221 0.45281623...   \n",
       "3   [{'y_pred': [[-1.14021119e-10 -7.73912862e-10 ...   \n",
       "4   [{'y_pred': [[0.50635131 1.33052966 0.55415854...   \n",
       "5   [{'y_pred': [[0.29340068 0.37610565 0.22158855...   \n",
       "6                                                  []   \n",
       "7                                                  []   \n",
       "8   [{'y_pred': [[-0.33021685  0.02510688  0.12306...   \n",
       "9   [{'y_pred': [[0.38124186 0.36439073 0.21427807...   \n",
       "10  [{'y_pred': [[0.57530848 0.50261499 0.2766727 ...   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                               None   \n",
       "14                                                NaN   \n",
       "15                                               None   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                               None   \n",
       "23                                               None   \n",
       "24                                               None   \n",
       "25                                               None   \n",
       "\n",
       "                                          results_org  \\\n",
       "0   [{'y_pred': [[0.75794363 1.56522677 0.49123517...   \n",
       "1   [{'y_pred': [[ 0.29541929  0.30550953 -0.07219...   \n",
       "2   [{'y_pred': [[0.62964805 1.4496627  0.32562954...   \n",
       "3   [{'y_pred': [[ 0.19455912  0.19825049 -0.12718...   \n",
       "4   [{'y_pred': [[0.70091043 1.52878015 0.42697185...   \n",
       "5   [{'y_pred': [[0.48795979 0.57435613 0.09440186...   \n",
       "6                                                  []   \n",
       "7                                                  []   \n",
       "8   [{'y_pred': [[-0.13565774  0.22335736 -0.00412...   \n",
       "9   [{'y_pred': [[0.57580098 0.56264122 0.08709138...   \n",
       "10  [{'y_pred': [[0.7698676  0.70086548 0.14948601...   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                               None   \n",
       "14                                                NaN   \n",
       "15                                               None   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                               None   \n",
       "23                                               None   \n",
       "24                                               None   \n",
       "25                                               None   \n",
       "\n",
       "         params.ordinal_imputer params.continuous_imputer  \\\n",
       "0   SimpleImputer_most_frequent                KNNImputer   \n",
       "1   SimpleImputer_most_frequent                KNNImputer   \n",
       "2   SimpleImputer_most_frequent                KNNImputer   \n",
       "3   SimpleImputer_most_frequent                KNNImputer   \n",
       "4   SimpleImputer_most_frequent                KNNImputer   \n",
       "5   SimpleImputer_most_frequent                KNNImputer   \n",
       "6   SimpleImputer_most_frequent                KNNImputer   \n",
       "7   SimpleImputer_most_frequent                KNNImputer   \n",
       "8   SimpleImputer_most_frequent                KNNImputer   \n",
       "9   SimpleImputer_most_frequent                KNNImputer   \n",
       "10  SimpleImputer_most_frequent                KNNImputer   \n",
       "11                    NoImputer                 NoImputer   \n",
       "12                    NoImputer                 NoImputer   \n",
       "13                    NoImputer                 NoImputer   \n",
       "14                    NoImputer                 NoImputer   \n",
       "15                    NoImputer                 NoImputer   \n",
       "16                    NoImputer                 NoImputer   \n",
       "17                    NoImputer                 NoImputer   \n",
       "18                    NoImputer                 NoImputer   \n",
       "19                    NoImputer                 NoImputer   \n",
       "20                    NoImputer                 NoImputer   \n",
       "21                    NoImputer                 NoImputer   \n",
       "22                    NoImputer                 NoImputer   \n",
       "23                    NoImputer                 NoImputer   \n",
       "24                    NoImputer                 NoImputer   \n",
       "25                    NoImputer                 NoImputer   \n",
       "\n",
       "                           params.model params.train_shape params.test_shape  \\\n",
       "0                      LinearRegression        [2893, 348]          [1, 348]   \n",
       "1                   MultiTaskElasticNet        [2893, 348]          [1, 348]   \n",
       "2             MultiTaskElasticNet_tuned        [2893, 348]          [1, 348]   \n",
       "3                        MultiTaskLasso        [2893, 348]          [1, 348]   \n",
       "4                  MultiTaskLasso_tuned        [2893, 348]          [1, 348]   \n",
       "5                 RandomForestRegressor        [2893, 348]          [1, 348]   \n",
       "6                      XGBoostRegressor        [2893, 348]          [1, 348]   \n",
       "7                XGBoostRegressor_tuned        [2893, 348]          [1, 348]   \n",
       "8               TabNetRegressor_default        [2893, 348]          [1, 348]   \n",
       "9                TabNetRegressor_custom        [2893, 348]          [1, 348]   \n",
       "10           PLSRegression_4_components        [2893, 348]          [1, 348]   \n",
       "11                     LinearRegression        (2881, 200)         (13, 200)   \n",
       "12                  MultiTaskElasticNet        (2881, 200)         (13, 200)   \n",
       "13            MultiTaskElasticNet_tuned        (2881, 200)         (13, 200)   \n",
       "14                       MultiTaskLasso        (2881, 200)         (13, 200)   \n",
       "15                 MultiTaskLasso_tuned        (2881, 200)         (13, 200)   \n",
       "16                RandomForestRegressor        (2881, 200)         (13, 200)   \n",
       "17                     XGBoostRegressor        (2881, 200)         (13, 200)   \n",
       "18               XGBoostRegressor_tuned        (2881, 200)         (13, 200)   \n",
       "19              TabNetRegressor_default        (2881, 200)         (13, 200)   \n",
       "20               TabNetRegressor_custom        (2881, 200)         (13, 200)   \n",
       "21           PLSRegression_4_components        (2881, 200)         (13, 200)   \n",
       "22  GatedAdditiveTreeEnsembleConfig_tab        (2881, 200)         (13, 200)   \n",
       "23                      DANetConfig_tab        (2881, 200)         (13, 200)   \n",
       "24             TabTransformerConfig_tab        (2881, 200)         (13, 200)   \n",
       "25                TabNetModelConfig_tab        (2881, 200)         (13, 200)   \n",
       "\n",
       "                                results_adj.mse_score  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11  [1.1119234898099377, 0.676686264997117, 0.6199...   \n",
       "12  [1.1801224687295142, 0.9504153428153488, 0.507...   \n",
       "13                                                NaN   \n",
       "14  [1.3936376654364884, 1.0405633863212842, 0.488...   \n",
       "15                                                NaN   \n",
       "16  [1.0004929827487936, 0.6583307726546211, 0.476...   \n",
       "17  [0.9972977744677737, 0.5528588765184321, 0.498...   \n",
       "18  [1.015361101896433, 0.6385197295978015, 0.4634...   \n",
       "19  [1.0002425052752673, 0.852160951239341, 0.6231...   \n",
       "20  [0.9261003635990263, 0.7642873814427985, 0.611...   \n",
       "21  [1.081409082021159, 0.7876511651265149, 0.5694...   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "\n",
       "                                results_adj.mae_score  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11  [0.7284983137064507, 0.7023597272362397, 0.709...   \n",
       "12  [0.8841416741691975, 0.7868357222322307, 0.653...   \n",
       "13                                                NaN   \n",
       "14  [0.9912757529866387, 0.7845715674120901, 0.621...   \n",
       "15                                                NaN   \n",
       "16  [0.7462698406196145, 0.6893144678982224, 0.633...   \n",
       "17  [0.754455924042236, 0.6345107831666245, 0.6429...   \n",
       "18  [0.7345770328134464, 0.7145827532706496, 0.630...   \n",
       "19  [0.7806465891501985, 0.8013238013969162, 0.679...   \n",
       "20  [0.7133815430335131, 0.7584149374303166, 0.671...   \n",
       "21  [0.7924841444198072, 0.7906801463917367, 0.721...   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "\n",
       "                                       results_adj.r2  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11  [-0.12379654970384224, 0.23213669686583083, -0...   \n",
       "12  [-0.19272375369361128, -0.07847477070736275, -...   \n",
       "13                                                NaN   \n",
       "14  [-0.4085188543166307, -0.18076940566326094, -0...   \n",
       "15                                                NaN   \n",
       "16  [-0.011176193613992913, 0.2529654172194542, 0....   \n",
       "17  [-0.00794686706886405, 0.37264864819991916, -0...   \n",
       "18  [-0.0262030737472283, 0.2754458099021808, 0.03...   \n",
       "19  [-0.010923041555324087, 0.03301846562027699, -...   \n",
       "20  [0.06401078596697707, 0.13273216316732506, -0....   \n",
       "21  [-0.09295631069140176, 0.10622033184891166, -0...   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "\n",
       "                       results_adj.explained_variance  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11  [0.02475189284221302, 0.28845770677144666, -0....   \n",
       "12  [0.11229868297941448, 0.03189858449038585, -0....   \n",
       "13                                                NaN   \n",
       "14  [-2.220446049250313e-16, 0.0, 0.0, 1.110223024...   \n",
       "15                                                NaN   \n",
       "16  [0.29851275592520854, 0.40207199079436096, 0.0...   \n",
       "17  [0.26511087910522013, 0.47604273516010087, -0....   \n",
       "18  [0.22165364381976016, 0.3489773943943325, 0.05...   \n",
       "19  [0.3827598339020245, 0.13551578326538694, -0.2...   \n",
       "20  [0.2220996090267332, 0.26101411024552224, -0.2...   \n",
       "21  [0.1855152043553444, 0.19584409010586212, -0.1...   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "\n",
       "                                     results_adj.corr  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11  [0.3320458491424125, 0.5476551369606042, 0.016...   \n",
       "12  [0.42176385593133126, 0.17864276958690972, -0....   \n",
       "13                                                NaN   \n",
       "14                               [nan, nan, nan, nan]   \n",
       "15                                                NaN   \n",
       "16  [0.5463813448253922, 0.6389458445773373, 0.230...   \n",
       "17  [0.5217493590966826, 0.698490826142268, 0.2117...   \n",
       "18  [0.48104477356404635, 0.590754815507922, 0.306...   \n",
       "19  [0.6294661381345319, 0.47112118305582457, 0.06...   \n",
       "20  [0.5532913119709318, 0.580845291517589, 0.2370...   \n",
       "21  [0.4328608768006912, 0.4454234137390073, -0.05...   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "\n",
       "                                results_org.mse_score  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11  [1.111923487408025, 0.6766862634588122, 0.6199...   \n",
       "12  [1.1801224777332378, 0.9504153411821713, 0.507...   \n",
       "13                                                NaN   \n",
       "14  [1.39363767778841, 1.040563386289657, 0.488669...   \n",
       "15                                                NaN   \n",
       "16  [1.0004929816978152, 0.6583307783476453, 0.476...   \n",
       "17  [0.9972977727407778, 0.5528588798070297, 0.498...   \n",
       "18  [1.0153611005115688, 0.638519728895267, 0.4634...   \n",
       "19  [1.0002425013137521, 0.8521609524638865, 0.623...   \n",
       "20  [0.9261003504544436, 0.7642873867924493, 0.611...   \n",
       "21  [1.0814090864925796, 0.7876511645655125, 0.569...   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "\n",
       "                                results_org.mae_score  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11  [0.7284983177320566, 0.7023597287538657, 0.709...   \n",
       "12  [0.8841416790017589, 0.78683572655586, 0.65378...   \n",
       "13                                                NaN   \n",
       "14  [0.9912757578191999, 0.7845715717907388, 0.621...   \n",
       "15                                                NaN   \n",
       "16  [0.7462698467726478, 0.6893144699477052, 0.633...   \n",
       "17  [0.7544559347068825, 0.6345107852161074, 0.642...   \n",
       "18  [0.7345770389664799, 0.7145827553201324, 0.630...   \n",
       "19  [0.780646592900706, 0.801323803446399, 0.67955...   \n",
       "20  [0.7133815361285443, 0.758414935004866, 0.6711...   \n",
       "21  [0.7924841505728405, 0.7906801478543428, 0.721...   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "\n",
       "                                       results_org.r2  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11  [-0.18280005836581759, 0.24192464970535776, -0...   \n",
       "12  [-0.2553462098327579, -0.06472745435881033, 0....   \n",
       "13                                                NaN   \n",
       "14  [-0.4824713618303562, -0.16571814171801091, 0....   \n",
       "15                                                NaN   \n",
       "16  [-0.0642667148845999, 0.26248785832489097, 0.0...   \n",
       "17  [-0.060867835929641734, 0.3806454902291253, 0....   \n",
       "18  [-0.08008256192789931, 0.2846817006774043, 0.0...   \n",
       "19  [-0.06400026830239858, 0.045344574833686035, -...   \n",
       "20  [0.01486787447618565, 0.1437872175696555, -0.1...   \n",
       "21  [-0.15034059906622055, 0.11761333910345084, -0...   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "\n",
       "                       results_org.explained_variance  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11  [-0.026452269431272546, 0.29752774244051705, -...   \n",
       "12  [0.06569104121430824, 0.0442389812184012, 0.01...   \n",
       "13                                                NaN   \n",
       "14  [-0.05250374534439928, 0.012747008661847414, 0...   \n",
       "15                                                NaN   \n",
       "16  [0.26168205835166036, 0.40969378155791614, 0.0...   \n",
       "17  [0.22652645919993875, 0.4827216219837368, 0.03...   \n",
       "18  [0.1807875566442022, 0.3572759857952956, 0.122...   \n",
       "19  [0.35035242511877496, 0.14653536835020642, -0....   \n",
       "20  [0.18125694946016357, 0.2704339649804939, -0.1...   \n",
       "21  [0.14275170798456327, 0.2060946718780181, -0.1...   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "\n",
       "                                     results_org.corr  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11  [0.27766053298168986, 0.5501268350934375, 0.07...  \n",
       "12  [0.2586375518883661, 0.21083052633240612, 0.14...  \n",
       "13                                                NaN  \n",
       "14  [-0.084866598168827, 0.1145532618513419, 0.272...  \n",
       "15                                                NaN  \n",
       "16  [0.5116701022090266, 0.6455531281709198, 0.318...  \n",
       "17  [0.4896643382156407, 0.7025785550998865, 0.273...  \n",
       "18  [0.4467819127944371, 0.5977575782775101, 0.368...  \n",
       "19  [0.6085272367008092, 0.4852576960459974, 0.122...  \n",
       "20  [0.5379584649934801, 0.5901319798405044, 0.273...  \n",
       "21  [0.38124619506043506, 0.4539854875773144, 0.03...  \n",
       "22                                                NaN  \n",
       "23                                                NaN  \n",
       "24                                                NaN  \n",
       "25                                                NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_nona = pd.json_normalize(dict_results_loo_nona)\n",
    "df_results_nona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metric_table(\n",
    "    results_list,\n",
    "    targets,\n",
    "    metric_name,\n",
    "    source=\"Adjusted\",\n",
    "    float_format=\"%.3f\",\n",
    "    csv_filename=None,\n",
    "    sort_order=\"ascending\"  # or \"descending\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a LaTeX table for a single metric across targets, models, and imputers.\n",
    "    Optionally export the same table as CSV and sort by mean performance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results_list : list of dict\n",
    "        List of experiment results.\n",
    "    targets : list of str\n",
    "        Target names (e.g., ['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN']).\n",
    "    metric_name : str\n",
    "        Metric to extract (e.g., 'mae_score').\n",
    "    source : str\n",
    "        'Adjusted' or 'Original'.\n",
    "    float_format : str\n",
    "        Format for floats (e.g., '%.3f').\n",
    "    csv_filename : str or None\n",
    "        If provided, saves the table to CSV.\n",
    "    sort_order : str\n",
    "        'ascending' or 'descending' for sorting by mean.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        LaTeX-formatted table string.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    version_key = \"results_adj\" if source.lower() == \"adjusted\" else \"results_org\"\n",
    "\n",
    "    for res in results_list:\n",
    "        result_block = res.get(version_key)\n",
    "        if result_block is None:\n",
    "            continue\n",
    "\n",
    "        metric_values = result_block.get(metric_name)\n",
    "        if metric_values is None:\n",
    "            continue\n",
    "\n",
    "        if len(metric_values) != len(targets):\n",
    "            continue\n",
    "\n",
    "        ordinal_imputer = res[\"params\"].get(\"ordinal_imputer\")\n",
    "        model = res[\"params\"].get(\"model\")\n",
    "\n",
    "        values = np.array(metric_values, dtype=np.float64)\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "\n",
    "        row = {\n",
    "            \"Ordinal Imputer\": ordinal_imputer,\n",
    "            \"Model\": model,\n",
    "            \"Mean\": mean_val,  # for sorting\n",
    "            \"Mean Â± SD\": f\"{mean_val:.3f} Â± {std_val:.3f}\",\n",
    "        }\n",
    "        row.update({target: val for target, val in zip(targets, values)})\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Reorder columns for display\n",
    "    display_cols = [\"Ordinal Imputer\", \"Model\"] + targets + [\"Mean Â± SD\"]\n",
    "    df = df.sort_values(by=\"Mean\", ascending=(sort_order == \"ascending\"))\n",
    "    df = df[display_cols]\n",
    "\n",
    "    # Save CSV\n",
    "    if csv_filename:\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    # LaTeX output\n",
    "    latex_table = df.to_latex(\n",
    "        index=False,\n",
    "        escape=False,\n",
    "        float_format=float_format,\n",
    "        caption=f\"{metric_name.replace('_', ' ').upper()} across targets\",\n",
    "        label=f\"tab:{metric_name}\",\n",
    "        longtable=False\n",
    "    )\n",
    "\n",
    "    return df, latex_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m latex_df, latex_mae \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_metric_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_dict_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mADNI_MEM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mADNI_EF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mADNI_VS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mADNI_LAN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcorr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAdjusted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcsv_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../tables/2_training_train_test_corr_adjusted_sorted.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescending\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(latex_mae)\n",
      "Cell \u001b[0;32mIn[36], line 44\u001b[0m, in \u001b[0;36mgenerate_metric_table\u001b[0;34m(results_list, targets, metric_name, source, float_format, csv_filename, sort_order)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result_block \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m metric_values \u001b[38;5;241m=\u001b[39m \u001b[43mresult_block\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(metric_name)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='corr',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_corr_adjusted_sorted.csv\",\n",
    "    sort_order=\"descending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='r2',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_r2_adjusted_sorted.csv\",\n",
    "    sort_order=\"descending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='mse_score',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_mse_adjusted_sorted.csv\",\n",
    "    sort_order=\"ascending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{MAE SCORE across targets}\n",
      "\\label{tab:mae_score}\n",
      "\\begin{tabular}{llrrrrl}\n",
      "\\toprule\n",
      "Ordinal Imputer & Model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & Mean Â± SD \\\\\n",
      "\\midrule\n",
      "SimpleImputer_most_frequent & MultiTaskLasso_tuned & 0.622 & 0.551 & 0.578 & 0.595 & 0.586 Â± 0.026 \\\\\n",
      "SimpleImputer_most_frequent & LinearRegression & 0.640 & 0.551 & 0.565 & 0.600 & 0.589 Â± 0.034 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskElasticNet_tuned & 0.630 & 0.554 & 0.580 & 0.600 & 0.591 Â± 0.028 \\\\\n",
      "SimpleImputer_most_frequent & TabNetRegressor_default & 0.691 & 0.608 & 0.536 & 0.595 & 0.607 Â± 0.055 \\\\\n",
      "SimpleImputer_most_frequent & RandomForestRegressor & 0.669 & 0.640 & 0.608 & 0.648 & 0.641 Â± 0.022 \\\\\n",
      "NoImputer & XGBoostRegressor & 0.754 & 0.635 & 0.643 & 0.644 & 0.669 Â± 0.049 \\\\\n",
      "NoImputer & XGBoostRegressor_tuned & 0.735 & 0.715 & 0.630 & 0.613 & 0.673 Â± 0.052 \\\\\n",
      "NoImputer & RandomForestRegressor & 0.755 & 0.684 & 0.635 & 0.632 & 0.677 Â± 0.050 \\\\\n",
      "NoImputer & MultiTaskLasso_tuned & 0.724 & 0.705 & 0.713 & 0.706 & 0.712 Â± 0.008 \\\\\n",
      "NoImputer & MultiTaskElasticNet_tuned & 0.727 & 0.703 & 0.714 & 0.708 & 0.713 Â± 0.009 \\\\\n",
      "NoImputer & LinearRegression & 0.728 & 0.702 & 0.710 & 0.712 & 0.713 Â± 0.010 \\\\\n",
      "NoImputer & TabNetRegressor_custom & 0.713 & 0.758 & 0.671 & 0.724 & 0.717 Â± 0.031 \\\\\n",
      "NoImputer & TabNetRegressor_default & 0.781 & 0.801 & 0.680 & 0.672 & 0.733 Â± 0.058 \\\\\n",
      "SimpleImputer_most_frequent & PLSRegression_4_components & 0.805 & 0.738 & 0.689 & 0.764 & 0.749 Â± 0.042 \\\\\n",
      "NoImputer & PLSRegression_4_components & 0.792 & 0.791 & 0.722 & 0.735 & 0.760 Â± 0.032 \\\\\n",
      "NoImputer & MultiTaskElasticNet & 0.884 & 0.787 & 0.654 & 0.827 & 0.788 Â± 0.085 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskElasticNet & 0.884 & 0.787 & 0.654 & 0.827 & 0.788 Â± 0.085 \\\\\n",
      "SimpleImputer_most_frequent & TabNetRegressor_custom & 0.765 & 0.969 & 0.765 & 0.763 & 0.815 Â± 0.089 \\\\\n",
      "NoImputer & MultiTaskLasso & 0.991 & 0.785 & 0.621 & 0.934 & 0.833 Â± 0.144 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskLasso & 0.991 & 0.785 & 0.621 & 0.934 & 0.833 Â± 0.144 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='mae_score',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_mae_adjusted_sorted.csv\",\n",
    "    sort_order=\"ascending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "MultiTaskLasso_tuned          2\n",
       "LinearRegression              2\n",
       "MultiTaskElasticNet_tuned     2\n",
       "TabNetRegressor_default       2\n",
       "RandomForestRegressor         2\n",
       "PLSRegression_4_components    2\n",
       "TabNetRegressor_custom        2\n",
       "MultiTaskElasticNet           2\n",
       "MultiTaskLasso                2\n",
       "XGBoostRegressor_tuned        1\n",
       "XGBoostRegressor              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latex_df.Model.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
