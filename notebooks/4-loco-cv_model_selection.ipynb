{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.serialization.safe_globals at 0x7b07bc472030>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import timeit\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "from itertools import product\n",
    "import warnings\n",
    "\n",
    "# System path modification\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning imports\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer, MissingIndicator\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, KFold, StratifiedKFold, GroupKFold, StratifiedGroupKFold, LeaveOneOut, cross_validate, cross_val_score\n",
    ")\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, Lasso, LassoCV, MultiTaskLasso, MultiTaskLassoCV,\n",
    "    ElasticNet, ElasticNetCV, MultiTaskElasticNet, MultiTaskElasticNetCV\n",
    ")\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Statistic imports \n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.special import kl_div\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Specialized imputation and visualization packages\n",
    "import miceforest as mf\n",
    "import missingno as msno\n",
    "#from missforest import MissForest\n",
    "#import magic\n",
    "from src.gain import *\n",
    "\n",
    "# Custom modules\n",
    "from src.train import *\n",
    "from src.functions import *\n",
    "from src.plots import *\n",
    "from src.dataset import *\n",
    "from src.multixgboost import *\n",
    "from src.wrapper import *\n",
    "from src.debug import *\n",
    "\n",
    "# Visualizatiokn \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning and machine learning specific \n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "from pytorch_tabular.config import DataConfig, TrainerConfig, OptimizerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.models import (\n",
    "    GatedAdditiveTreeEnsembleConfig,\n",
    "    DANetConfig,\n",
    "    TabTransformerConfig,\n",
    "    TabNetModelConfig,\n",
    ")\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Print CUDA availability for PyTorch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "from omegaconf import DictConfig\n",
    "torch.serialization.safe_globals([DictConfig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_pickle_data_palettes()\n",
    "\n",
    "results_pickle_folder = \"../pickle/\"\n",
    "\n",
    "# Unpack data\n",
    "df_X, df_y, df_all, df_FinalCombination = data[\"df_X\"], data[\"df_y\"], data[\"df_all\"], data[\"df_FinalCombination\"]\n",
    "dict_select = data[\"dict_select\"]\n",
    "\n",
    "# Unpack colormaps\n",
    "full_palette, gender_palette, dx_palette = data[\"colormaps\"].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "3609    2002\n",
      "5631    4167\n",
      "5662    4176\n",
      "5780    4215\n",
      "5950    4349\n",
      "6069    4292\n",
      "6077    4453\n",
      "6085    4489\n",
      "6224    4505\n",
      "6400    4576\n",
      "6429    4300\n",
      "7021    2374\n",
      "7192    4179\n",
      "Name: RID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "idx_train = list(df_X.isna().any(axis=1))\n",
    "idx_test = list(~df_X.isna().any(axis=1))\n",
    "\n",
    "set_intersect_rid = set(df_all[idx_train].RID).intersection(set(df_all[idx_test].RID))\n",
    "intersect_rid_idx = df_all.RID.isin(set_intersect_rid)\n",
    "\n",
    "for i, bool_test in enumerate(idx_test): \n",
    "    if intersect_rid_idx.iloc[i] & bool_test:\n",
    "        idx_test[i] = False\n",
    "        idx_train[i] = True\n",
    "\n",
    "print(sum(idx_test))\n",
    "\n",
    "print(df_all[idx_test].RID)\n",
    "\n",
    "df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]] = df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]].astype(\"int\", errors='ignore')\n",
    "\n",
    "test_indices = [i for i, val in enumerate(idx_test) if val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-One-Complete-Out (LOCO-CV)\n",
    "\n",
    "## All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42\n",
    "\n",
    "# Continuous Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "continuous_imputer_list = [\n",
    "    (\"KNNImputer_5\", KNNImputer(n_neighbors=5)),\n",
    "]\n",
    "\n",
    "# Ordinal Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "ordinal_imputer_list = [\n",
    "    (\"KNNImputer\", KNNImputer(n_neighbors=1)),\n",
    "]\n",
    "\n",
    "# Predictive Models List (list of tuples with unique strings and corresponding instances)\n",
    "predictive_models_list = [\n",
    "    (\"LinearRegression\", LinearRegression()),\n",
    "    (\"MultiTaskElasticNet\", MultiTaskElasticNet()),\n",
    "    (\"MultiTaskElasticNet_tuned\", MultiTaskElasticNet(**{'alpha': 0.1, 'l1_ratio': 0.1})),\n",
    "    (\"MultiTaskLasso\", MultiTaskLasso()),\n",
    "    (\"MultiTaskLasso_tuned\", MultiTaskLasso(**{'alpha': 0.001})),\n",
    "    (\"RandomForestRegressor\", RandomForestRegressor()),\n",
    "    (\"XGBoostRegressor\", XGBoostRegressor()),\n",
    "    (\"XGBoostRegressor_tuned\", XGBoostRegressor(**{'colsample_bytree': 0.8776807051588262, 'learning_rate': 0.13329520360246094, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.5924272277627636})),\n",
    "    (\"TabNetRegressor_default\", TabNetModelWrapper(n_a=8, n_d=8)),\n",
    "    (\"TabNetRegressor_custom\", TabNetModelWrapper(n_a=32, n_d=32)),\n",
    "    (\"PLSRegression_4_components\", PLSRegression(n_components=4))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['APOE_epsilon2', 'APOE_epsilon3', 'APOE_epsilon4']\n",
    "continuous_features = [col for col in df_X.columns if col not in ordinal_features]\n",
    "\n",
    "# Prepare Tabular configurations (shared for all PyTorch models)\n",
    "data_config = DataConfig(\n",
    "    target=df_y.columns.tolist(),\n",
    "    continuous_cols=continuous_features,\n",
    "    categorical_cols=ordinal_features\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024, max_epochs=10, auto_lr_find=False,\n",
    "    early_stopping=\"valid_loss\", early_stopping_mode=\"min\", early_stopping_patience=5,\n",
    "    checkpoints=\"valid_loss\", load_best=True, progress_bar=\"nones\",\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "head_config = LinearHeadConfig(dropout=0.1).__dict__\n",
    "\n",
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabNetModelConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: LinearRegression\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: MultiTaskElasticNet\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: MultiTaskElasticNet_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: MultiTaskLasso\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: MultiTaskLasso_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: RandomForestRegressor\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: XGBoostRegressor\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: XGBoostRegressor_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: TabNetRegressor_default\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: TabNetRegressor_custom\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: PLSRegression_4_components\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: GatedAdditiveTreeEnsembleConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: DANetConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: TabTransformerConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer, Model: TabNetModelConfig_tab\n",
      "Combinations of preprocessing and models to test : 15\n"
     ]
    }
   ],
   "source": [
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "# Display all combinations\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    print(f\"Continuous Imputer: {continuous_imputer[0]}, Ordinal Imputer: {ordinal_imputer[0]}, Model: {model[0]}\")\n",
    "\n",
    "print(f\"Combinations of preprocessing and models to test : {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HDF5 file\n",
    "results_file = '../pickle/training_3_loonona_dict_results.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(results_file): \n",
    "    with open(results_file, \"rb\") as input_file:\n",
    "        all_dict_results = pickle.load(input_file)\n",
    "\n",
    "else : \n",
    "    all_dict_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False : \n",
    "    params_comb = [{'ordinal_imputer': 'SimpleImputer_most_frequent', 'continuous_imputer': 'KNNImputer', 'model': 'GatedAdditiveTreeEnsembleConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "    {'ordinal_imputer': 'SimpleImputer_most_frequent', 'continuous_imputer': 'KNNImputer', 'model': 'DANetConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "    {'ordinal_imputer': 'SimpleImputer_most_frequent', 'continuous_imputer': 'KNNImputer', 'model': 'TabTransformerConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "    {'ordinal_imputer': 'SimpleImputer_most_frequent', 'continuous_imputer': 'KNNImputer', 'model': 'TabNetModelConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "    {'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'GatedAdditiveTreeEnsembleConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "    {'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'DANetConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "    {'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'TabTransformerConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "    {'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'TabNetModelConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]}]\n",
    "\n",
    "    for params in params_comb:\n",
    "        all_dict_results = clean_dict_list(all_dict_results, remove_if_none=False, remove_key_val={\"params\": params})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict_results = clean_dict_list(all_dict_results, remove_if_none=False, remove_key_val={\"fitting_time\":None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'LinearRegression']\n",
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'MultiTaskElasticNet']\n",
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'MultiTaskElasticNet_tuned']\n",
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'MultiTaskLasso']\n",
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'MultiTaskLasso_tuned']\n",
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'RandomForestRegressor']\n",
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'XGBoostRegressor']\n",
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'XGBoostRegressor_tuned']\n",
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'TabNetRegressor_default']\n",
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'TabNetRegressor_custom']\n",
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'PLSRegression_4_components']\n",
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'GatedAdditiveTreeEnsembleConfig_tab']\n",
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'DANetConfig_tab']\n",
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'TabTransformerConfig_tab']\n",
      "Skipping existing combination (subset match): ['KNNImputer', 'KNNImputer_5', 'TabNetModelConfig_tab']\n"
     ]
    }
   ],
   "source": [
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    name_continuous_imputer, continuous_imputer_instance = continuous_imputer\n",
    "    name_ordinal_imputer, ordinal_imputer_instance = ordinal_imputer\n",
    "    name_model, model_instance = model\n",
    "\n",
    "    params = {\n",
    "            \"ordinal_imputer\": name_ordinal_imputer, \n",
    "            \"continuous_imputer\": name_continuous_imputer, \n",
    "            \"model\": name_model, \"train_shape\" : [df_X.shape[0]-1, df_X.shape[1]],\n",
    "            \"test_shape\": [1, df_X.shape[1]]\n",
    "        }\n",
    "    \n",
    "    # Define the subset of keys you care about\n",
    "    keys_to_check = ['ordinal_imputer', 'continuous_imputer', 'model']  # or whatever subset you want\n",
    "\n",
    "    # Check if a result in all_dict_results has the same values for just those keys\n",
    "    if any(all(result['params'].get(k) == params.get(k) for k in keys_to_check) for result in all_dict_results):\n",
    "        print(f\"Skipping existing combination (subset match): {[params[k] for k in keys_to_check]}\")\n",
    "        continue\n",
    "\n",
    "    dict_results = {\n",
    "            \"params\": params, \n",
    "            \"imputation_time\": [],\n",
    "            \"fitting_time\": [], \n",
    "            \"results_adj\": [], \n",
    "            \"results_org\": []\n",
    "        }\n",
    "\n",
    "    for test_nloc in test_indices: \n",
    "        print(test_nloc)\n",
    "\n",
    "        idx_train = [True for i in range(df_X.shape[0])]\n",
    "        idx_test = [False for i in range(df_X.shape[0])]\n",
    "\n",
    "        idx_test[test_nloc] = True\n",
    "        idx_train[test_nloc] = False\n",
    "\n",
    "        df_X_train = df_X.loc[idx_train]\n",
    "        df_X_test = df_X.loc[idx_test]\n",
    "\n",
    "        df_y_train = df_y.loc[idx_train]\n",
    "        df_y_test = df_y.loc[idx_test]\n",
    "\n",
    "        c_train = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_train]\n",
    "        c_test = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_test]\n",
    "\n",
    "        try: \n",
    "        \n",
    "            # Now you can call your `train_model` function with these components\n",
    "            fold_dict_results = train_imputer_model(\n",
    "                df_X_train, df_X_test, df_y_train, df_y_test,\n",
    "                c_train, c_test,\n",
    "                ordinal_imputer_instance, name_ordinal_imputer,\n",
    "                continuous_imputer_instance, name_continuous_imputer,\n",
    "                model_instance, name_model,\n",
    "                separate_imputers=True  # Or however you want to specify\n",
    "            )\n",
    "            \n",
    "            dict_results[\"imputation_time\"].append(fold_dict_results[\"imputation_time\"]) \n",
    "            dict_results[\"fitting_time\"].append(fold_dict_results[\"fitting_time\"])  \n",
    "            dict_results[\"results_adj\"].append(fold_dict_results[\"results_adj\"])  \n",
    "            dict_results[\"results_org\"].append(fold_dict_results[\"results_org\"])  \n",
    "\n",
    "        except Exception as e:  \n",
    "\n",
    "            print(e)\n",
    "            \n",
    "    # Optionally keep the all_dict_results list updated\n",
    "    all_dict_results.append(dict_results)\n",
    "\n",
    "    # Save the updated results back to the pickle file\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(all_dict_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open(results_file, 'wb') as handle:\n",
    "    pickle.dump(all_dict_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../pickle/training_3_loonona_dict_results.pickle'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_file, \"rb\") as input_file:\n",
    "    dict_results_loo_nona = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_nona = pd.json_normalize(dict_results_loo_nona)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train only on MRI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = list(df_X.isna().any(axis=1))\n",
    "idx_test = list(~df_X.isna().any(axis=1))\n",
    "\n",
    "set_intersect_rid = set(df_all[idx_train].RID).intersection(set(df_all[idx_test].RID))\n",
    "intersect_rid_idx = df_all.RID.isin(set_intersect_rid)\n",
    "\n",
    "for i, bool_test in enumerate(idx_test): \n",
    "    if intersect_rid_idx.iloc[i] & bool_test:\n",
    "        idx_test[i] = False\n",
    "        idx_train[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]] = df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]].astype(\"int\", errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train = df_X[dict_select[\"MRIth\"]].loc[idx_train]\n",
    "df_X_test = df_X[dict_select[\"MRIth\"]].loc[idx_test]\n",
    "\n",
    "df_y_train = df_y.loc[idx_train]\n",
    "df_y_test = df_y.loc[idx_test]\n",
    "\n",
    "c_train = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_train]\n",
    "c_test = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42\n",
    "n_imputation_iter = 10\n",
    "\n",
    "# Continuous Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "continuous_imputer_list = [\n",
    "    (\"NoImputer\", KNNImputer(n_neighbors=1)),\n",
    "\n",
    "]\n",
    "\n",
    "# Ordinal Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "ordinal_imputer_list = [\n",
    "    (\"NoImputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "]\n",
    "\n",
    "# Predictive Models List (list of tuples with unique strings and corresponding instances)\n",
    "predictive_models_list = [\n",
    "    (\"LinearRegression\", LinearRegression()),\n",
    "    (\"MultiTaskElasticNet\", MultiTaskElasticNet()),\n",
    "    (\"MultiTaskElasticNet_tuned\", MultiTaskElasticNet(**{'alpha': 0.1, 'l1_ratio': 0.1})),\n",
    "    (\"MultiTaskLasso\", MultiTaskLasso()),\n",
    "    (\"MultiTaskLasso_tuned\", MultiTaskLasso(**{'alpha': 0.001})),\n",
    "    (\"RandomForestRegressor\", RandomForestRegressor()),\n",
    "    (\"XGBoostRegressor\", XGBoostRegressor()),\n",
    "    (\"XGBoostRegressor_tuned\", XGBoostRegressor(**{'colsample_bytree': 0.8776807051588262, 'learning_rate': 0.13329520360246094, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.5924272277627636})),\n",
    "    (\"TabNetRegressor_default\", TabNetModelWrapper(n_a=8, n_d=8)),\n",
    "    (\"TabNetRegressor_custom\", TabNetModelWrapper(n_a=32, n_d=32)),\n",
    "    (\"PLSRegression_4_components\", PLSRegression(n_components=4))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['APOE_epsilon2', 'APOE_epsilon3', 'APOE_epsilon4']\n",
    "continuous_features = [col for col in df_X_train.columns if col not in ordinal_features]\n",
    "\n",
    "# Prepare Tabular configurations (shared for all PyTorch models)\n",
    "data_config = DataConfig(\n",
    "    target=df_y_train.columns.tolist(),\n",
    "    continuous_cols=dict_select[\"MRIth\"],\n",
    "    categorical_cols=[]\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024, max_epochs=10, auto_lr_find=True,\n",
    "    early_stopping=\"valid_loss\", early_stopping_mode=\"min\", early_stopping_patience=5,\n",
    "    checkpoints=\"valid_loss\", load_best=True, progress_bar=\"nones\",\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "head_config = LinearHeadConfig(dropout=0.1).__dict__\n",
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabNetModelConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: LinearRegression\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskElasticNet\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskElasticNet_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskLasso\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskLasso_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: RandomForestRegressor\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: XGBoostRegressor\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: XGBoostRegressor_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetRegressor_default\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetRegressor_custom\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: PLSRegression_4_components\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: GatedAdditiveTreeEnsembleConfig_tab\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: DANetConfig_tab\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabTransformerConfig_tab\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetModelConfig_tab\n",
      "Combinations of preprocessing and models to test : 15\n"
     ]
    }
   ],
   "source": [
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "# Display all combinations\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    print(f\"Continuous Imputer: {continuous_imputer[0]}, Ordinal Imputer: {ordinal_imputer[0]}, Model: {model[0]}\")\n",
    "\n",
    "print(f\"Combinations of preprocessing and models to test : {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HDF5 file\n",
    "results_file = '../pickle/training_3_loonona_dict_results.pickle'\n",
    "\n",
    "with open('../pickle/training_3_loonona_dict_results.pickle', \"rb\") as input_file:\n",
    "    all_dict_results = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict_results = clean_dict_list(all_dict_results, remove_if_none=False, remove_key_val={\"fitting_time\":None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'LinearRegression', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'MultiTaskElasticNet', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'MultiTaskElasticNet_tuned', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'MultiTaskLasso', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'MultiTaskLasso_tuned', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'RandomForestRegressor', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'XGBoostRegressor', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'XGBoostRegressor_tuned', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'TabNetRegressor_default', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'TabNetRegressor_custom', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'PLSRegression_4_components', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'GatedAdditiveTreeEnsembleConfig_tab', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'DANetConfig_tab', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'TabTransformerConfig_tab', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'KNNImputer', 'continuous_imputer': 'KNNImputer_5', 'model': 'TabNetModelConfig_tab', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'LinearRegression', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'MultiTaskElasticNet', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'MultiTaskElasticNet_tuned', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'MultiTaskLasso', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'MultiTaskLasso_tuned', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'RandomForestRegressor', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'XGBoostRegressor', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'XGBoostRegressor_tuned', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'TabNetRegressor_default', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'TabNetRegressor_custom', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'PLSRegression_4_components', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'GatedAdditiveTreeEnsembleConfig_tab', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'DANetConfig_tab', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'TabTransformerConfig_tab', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n",
      "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'TabNetModelConfig_tab', 'train_shape': [2893, 256], 'test_shape': [1, 256]}\n"
     ]
    }
   ],
   "source": [
    "for res in all_dict_results: \n",
    "    print(res[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.debug import *\n",
    "\n",
    "rm_combinations = [{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'LinearRegression', 'train_shape': (2881, 200), 'test_shape': (13, 200)},\n",
    "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'MultiTaskElasticNet', 'train_shape': (2881, 200), 'test_shape': (13, 200)},\n",
    "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'MultiTaskLasso', 'train_shape': (2881, 200), 'test_shape': (13, 200)},\n",
    "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'RandomForestRegressor', 'train_shape': (2881, 200), 'test_shape': (13, 200)},\n",
    "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'XGBoostRegressor', 'train_shape': (2881, 200), 'test_shape': (13, 200)},\n",
    "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'XGBoostRegressor_tuned', 'train_shape': (2881, 200), 'test_shape': (13, 200)},\n",
    "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'TabNetRegressor_default', 'train_shape': (2881, 200), 'test_shape': (13, 200)},\n",
    "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'TabNetRegressor_custom', 'train_shape': (2881, 200), 'test_shape': (13, 200)},\n",
    "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'PLSRegression_4_components', 'train_shape': (2881, 200), 'test_shape': (13, 200)},\n",
    "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'MultiTaskElasticNet_tuned', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'MultiTaskLasso_tuned', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'GatedAdditiveTreeEnsembleConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'DANetConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'TabTransformerConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "{'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'TabNetModelConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]}, \n",
    "]\n",
    "if False : \n",
    "    for par in rm_combinations:\n",
    "        all_dict_results = clean_dict_list(all_dict_results, remove_if_none=False, remove_key_val={\"params\":par})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'LinearRegression']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'MultiTaskElasticNet']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'MultiTaskElasticNet_tuned']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'MultiTaskLasso']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'MultiTaskLasso_tuned']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'RandomForestRegressor']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'XGBoostRegressor']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'XGBoostRegressor_tuned']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'TabNetRegressor_default']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'TabNetRegressor_custom']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'PLSRegression_4_components']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'GatedAdditiveTreeEnsembleConfig_tab']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'DANetConfig_tab']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'TabTransformerConfig_tab']\n",
      "Skipping existing combination (subset match): ['NoImputer', 'NoImputer', 'TabNetModelConfig_tab']\n"
     ]
    }
   ],
   "source": [
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    name_continuous_imputer, continuous_imputer_instance = continuous_imputer\n",
    "    name_ordinal_imputer, ordinal_imputer_instance = ordinal_imputer\n",
    "    name_model, model_instance = model\n",
    "\n",
    "    params = {\n",
    "            \"ordinal_imputer\": name_ordinal_imputer, \n",
    "            \"continuous_imputer\": name_continuous_imputer, \n",
    "            \"model\": name_model, \"train_shape\" : [df_X.shape[0]-1, df_X.shape[1]],\n",
    "            \"test_shape\": [1, df_X.shape[1]]\n",
    "        }\n",
    "    \n",
    "    # Define the subset of keys you care about\n",
    "    keys_to_check = ['ordinal_imputer', 'continuous_imputer', 'model']  # or whatever subset you want\n",
    "\n",
    "    # Check if a result in all_dict_results has the same values for just those keys\n",
    "    if any(all(result['params'].get(k) == params.get(k) for k in keys_to_check) for result in all_dict_results):\n",
    "        print(f\"Skipping existing combination (subset match): {[params[k] for k in keys_to_check]}\")\n",
    "        continue\n",
    "\n",
    "    dict_results = {\n",
    "            \"params\": params, \n",
    "            \"imputation_time\": [],\n",
    "            \"fitting_time\": [], \n",
    "            \"results_adj\": [], \n",
    "            \"results_org\": []\n",
    "        }\n",
    "\n",
    "    for test_nloc in test_indices: \n",
    "        print(test_nloc)\n",
    "\n",
    "        idx_train = [True for i in range(df_X.shape[0])]\n",
    "        idx_test = [False for i in range(df_X.shape[0])]\n",
    "\n",
    "        idx_test[test_nloc] = True\n",
    "        idx_train[test_nloc] = False\n",
    "\n",
    "        df_X_train = df_X[dict_select[\"MRIth\"]].loc[idx_train]\n",
    "        df_X_test = df_X[dict_select[\"MRIth\"]].loc[idx_test]\n",
    "\n",
    "        df_y_train = df_y.loc[idx_train]\n",
    "        df_y_test = df_y.loc[idx_test]\n",
    "\n",
    "        c_train = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_train]\n",
    "        c_test = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_test]\n",
    "\n",
    "        try: \n",
    "        \n",
    "            # Now you can call your `train_model` function with these components\n",
    "            fold_dict_results = train_imputer_model(\n",
    "                df_X_train, df_X_test, df_y_train, df_y_test,\n",
    "                c_train, c_test,\n",
    "                ordinal_imputer_instance, name_ordinal_imputer,\n",
    "                continuous_imputer_instance, name_continuous_imputer,\n",
    "                model_instance, name_model,\n",
    "                separate_imputers=True  # Or however you want to specify\n",
    "            )\n",
    "            \n",
    "            dict_results[\"imputation_time\"].append(fold_dict_results[\"imputation_time\"]) \n",
    "            dict_results[\"fitting_time\"].append(fold_dict_results[\"fitting_time\"])  \n",
    "            dict_results[\"results_adj\"].append(fold_dict_results[\"results_adj\"])  \n",
    "            dict_results[\"results_org\"].append(fold_dict_results[\"results_org\"])  \n",
    "\n",
    "        except Exception as e:  \n",
    "\n",
    "            print(e)\n",
    "            \n",
    "    # Optionally keep the all_dict_results list updated\n",
    "    all_dict_results.append(dict_results)\n",
    "\n",
    "    # Save the updated results back to the pickle file\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(all_dict_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open(results_file, 'wb') as handle:\n",
    "    pickle.dump(all_dict_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_file, \"rb\") as input_file:\n",
    "    all_dict_results = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Table for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/training_3_loonona_dict_results.pickle', \"rb\") as input_file:\n",
    "    dict_results_loo_nona = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metric_table(\n",
    "    results_list,\n",
    "    targets,\n",
    "    metric_name=\"r2\",\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=None,\n",
    "    sort_order=\"descending\"\n",
    "):\n",
    "    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "    from scipy.stats import pearsonr\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # Choose the key\n",
    "    key = \"results_adj\" if source.lower() == \"adjusted\" else \"results_org\"\n",
    "    df_rows = []\n",
    "\n",
    "    for res in results_list:\n",
    "        result_blocks = res.get(key, [])\n",
    "        if not isinstance(result_blocks, list) or len(result_blocks) == 0:\n",
    "            continue\n",
    "\n",
    "        # Aggregate all predictions across folds\n",
    "        y_preds_all = {target: [] for target in targets}\n",
    "        y_tests_all = {target: [] for target in targets}\n",
    "\n",
    "        for fold in result_blocks:\n",
    "            y_pred = fold[\"y_pred\"]\n",
    "            y_test = fold[\"y_test\"]\n",
    "\n",
    "            if y_pred.shape != y_test.shape:\n",
    "                continue\n",
    "\n",
    "            for i, target in enumerate(targets):\n",
    "                if y_pred.shape[1] <= i:\n",
    "                    continue\n",
    "                y_preds_all[target].append(y_pred[0, i])\n",
    "                y_tests_all[target].append(y_test[0, i])\n",
    "\n",
    "        # Compute metric for each target\n",
    "        target_metrics = []\n",
    "        for target in targets:\n",
    "            y_preds = y_preds_all[target]\n",
    "            y_tests = y_tests_all[target]\n",
    "\n",
    "            if len(y_preds) < 2:\n",
    "                metric = float(\"nan\")\n",
    "            else:\n",
    "                if metric_name == \"r2\":\n",
    "                    metric = r2_score(y_tests, y_preds)\n",
    "                elif metric_name == \"mae\":\n",
    "                    metric = mean_absolute_error(y_tests, y_preds)\n",
    "                elif metric_name == \"mse\":\n",
    "                    metric = mean_squared_error(y_tests, y_preds)\n",
    "                elif metric_name == \"explained_variance\":\n",
    "                    metric = explained_variance_score(y_tests, y_preds)\n",
    "                elif metric_name == \"corr\":\n",
    "                    metric = pearsonr(y_tests, y_preds)[0]\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported metric: {metric_name}\")\n",
    "\n",
    "            target_metrics.append(metric)\n",
    "\n",
    "        # Compute mean ± std across targets\n",
    "        values = np.array(target_metrics, dtype=np.float64)\n",
    "        mean_val = np.nanmean(values)\n",
    "        std_val = np.nanstd(values)\n",
    "\n",
    "        # Get times\n",
    "        imp_times = np.array(res.get(\"imputation_time\", []), dtype=np.float64)\n",
    "        fit_times = np.array(res.get(\"fitting_time\", []), dtype=np.float64)\n",
    "\n",
    "        row = {\n",
    "            \"continuous_imputer\": res[\"params\"].get(\"continuous_imputer\"),\n",
    "            \"ordinal_imputer\": res[\"params\"].get(\"ordinal_imputer\"),\n",
    "            \"model\": res[\"params\"].get(\"model\"),\n",
    "            **{target: val for target, val in zip(targets, target_metrics)},\n",
    "            \"mean ± std\": f\"{mean_val:.3f} ± {std_val:.3f}\",\n",
    "            \"imp_time (s)\": f\"{np.nanmean(imp_times):.1f} ± {np.nanstd(imp_times):.1f}\",\n",
    "            \"fit_time (s)\": f\"{np.nanmean(fit_times):.1f} ± {np.nanstd(fit_times):.1f}\",\n",
    "            \"_sort_val\": mean_val  # hidden sort key\n",
    "        }\n",
    "        df_rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(df_rows)\n",
    "\n",
    "    # Sort by mean value\n",
    "    df = df.sort_values(by=\"_sort_val\", ascending=(sort_order == \"ascending\")).drop(columns=\"_sort_val\")\n",
    "\n",
    "    # Optional: Save to CSV\n",
    "    if csv_filename:\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    # Format for LaTeX output\n",
    "    latex_df = df.copy()\n",
    "    for target in targets:\n",
    "        latex_df[target] = latex_df[target].apply(lambda x: f\"{x:.3f}\" if pd.notnull(x) else \"–\")\n",
    "\n",
    "    latex_output = latex_df.to_latex(index=False, escape=False)\n",
    "\n",
    "    return df, latex_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "continuous_imputer & ordinal_imputer & model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & mean ± std & imp_time (s) & fit_time (s) \\\\\n",
      "\\midrule\n",
      "KNNImputer_5 & KNNImputer & RandomForestRegressor & 0.678 & 0.738 & 0.358 & 0.700 & 0.619 ± 0.152 & 2.5 ± 0.0 & 39.8 ± 0.5 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_default & 0.678 & 0.556 & 0.489 & 0.711 & 0.609 ± 0.090 & 2.5 ± 0.0 & 12.4 ± 0.7 \\\\\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor & 0.620 & 0.685 & 0.272 & 0.680 & 0.564 ± 0.171 & 2.5 ± 0.0 & 1.1 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & GatedAdditiveTreeEnsembleConfig_tab & 0.684 & 0.573 & 0.108 & 0.773 & 0.535 ± 0.256 & 2.6 ± 0.1 & 18.8 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor_tuned & 0.550 & 0.623 & 0.468 & 0.429 & 0.517 ± 0.075 & 2.5 ± 0.0 & 5.0 ± 0.2 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & 0.543 & 0.636 & 0.246 & 0.636 & 0.515 ± 0.160 & nan ± nan & 0.8 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 0.548 & 0.624 & 0.248 & 0.582 & 0.500 ± 0.148 & nan ± nan & 32.5 ± 0.3 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & 0.496 & 0.658 & 0.276 & 0.536 & 0.492 ± 0.138 & nan ± nan & 4.2 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet_tuned & 0.493 & 0.695 & 0.117 & 0.523 & 0.457 ± 0.211 & 2.7 ± 0.1 & 1.4 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & LinearRegression & 0.490 & 0.707 & 0.176 & 0.449 & 0.455 ± 0.189 & 2.7 ± 0.1 & 0.2 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso_tuned & 0.489 & 0.707 & 0.166 & 0.453 & 0.454 ± 0.192 & 2.6 ± 0.0 & 1.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & 0.415 & 0.585 & 0.427 & 0.339 & 0.442 ± 0.089 & nan ± nan & 14.6 ± 0.6 \\\\\n",
      "KNNImputer_5 & KNNImputer & PLSRegression_4_components & 0.460 & 0.568 & 0.115 & 0.498 & 0.410 ± 0.175 & 2.6 ± 0.0 & 0.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & 0.393 & 0.566 & -0.010 & 0.480 & 0.357 ± 0.221 & nan ± nan & 1.2 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & 0.346 & 0.556 & 0.017 & 0.396 & 0.329 ± 0.196 & nan ± nan & 0.9 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & 0.338 & 0.555 & 0.021 & 0.385 & 0.325 ± 0.193 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & 0.434 & 0.447 & -0.052 & 0.458 & 0.322 ± 0.216 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet & 0.376 & 0.205 & -0.132 & 0.429 & 0.220 ± 0.219 & 2.7 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & 0.420 & 0.176 & -0.167 & 0.446 & 0.219 ± 0.246 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & DANetConfig_tab & 0.110 & 0.269 & 0.279 & 0.186 & 0.211 ± 0.069 & 2.6 ± 0.0 & 1.8 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 0.306 & 0.150 & 0.115 & 0.238 & 0.202 ± 0.075 & nan ± nan & 15.2 ± 1.8 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabTransformerConfig_tab & 0.029 & 0.158 & -0.035 & 0.520 & 0.168 ± 0.215 & 2.6 ± 0.0 & 1.5 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_custom & 0.253 & 0.191 & -0.185 & 0.405 & 0.166 ± 0.217 & 2.8 ± 0.2 & 16.4 ± 1.7 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetModelConfig_tab & -0.142 & 0.309 & 0.137 & -0.072 & 0.058 ± 0.177 & 2.6 ± 0.0 & 1.8 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso & 0.288 & -0.213 & 0.463 & -0.324 & 0.054 ± 0.330 & 2.6 ± 0.0 & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & 0.288 & -0.213 & 0.463 & -0.324 & 0.054 ± 0.330 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_corr = generate_metric_table(\n",
    "    results_list=dict_results_loo_nona,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='corr',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/3_training_loonona_corr_adjusted_sorted.csv\",\n",
    "    sort_order=\"descending\"\n",
    ")\n",
    "print(latex_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "continuous_imputer & ordinal_imputer & model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & mean ± std & imp_time (s) & fit_time (s) \\\\\n",
      "\\midrule\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_default & 0.292 & 0.267 & 0.236 & 0.312 & 0.277 ± 0.028 & 2.5 ± 0.0 & 12.4 ± 0.7 \\\\\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor & 0.195 & 0.378 & 0.029 & 0.192 & 0.199 ± 0.123 & 2.5 ± 0.0 & 1.1 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & RandomForestRegressor & 0.176 & 0.410 & 0.102 & 0.098 & 0.197 ± 0.127 & 2.5 ± 0.0 & 39.8 ± 0.5 \\\\\n",
      "KNNImputer_5 & KNNImputer & GatedAdditiveTreeEnsembleConfig_tab & 0.238 & 0.318 & -0.028 & 0.095 & 0.156 ± 0.133 & 2.6 ± 0.1 & 18.8 ± 0.3 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & 0.051 & 0.301 & -0.000 & 0.103 & 0.114 ± 0.114 & nan ± nan & 0.8 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 0.084 & 0.290 & 0.012 & 0.023 & 0.102 ± 0.112 & nan ± nan & 32.5 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet_tuned & 0.100 & 0.382 & -0.089 & 0.009 & 0.100 ± 0.176 & 2.7 ± 0.1 & 1.4 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso_tuned & 0.101 & 0.435 & -0.153 & -0.073 & 0.078 ± 0.226 & 2.6 ± 0.0 & 1.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor_tuned & 0.090 & 0.342 & 0.190 & -0.320 & 0.075 ± 0.245 & 2.5 ± 0.0 & 5.0 ± 0.2 \\\\\n",
      "KNNImputer_5 & KNNImputer & LinearRegression & 0.102 & 0.440 & -0.171 & -0.077 & 0.074 ± 0.233 & 2.7 ± 0.1 & 0.2 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & PLSRegression_4_components & 0.005 & 0.256 & -0.045 & -0.036 & 0.045 ± 0.124 & 2.6 ± 0.0 & 0.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & -0.082 & 0.353 & -0.045 & -0.133 & 0.023 ± 0.193 & nan ± nan & 4.2 ± 0.3 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & -0.043 & 0.237 & -0.199 & -0.052 & -0.014 ± 0.158 & nan ± nan & 1.2 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & -0.173 & 0.214 & 0.140 & -0.453 & -0.068 ± 0.265 & nan ± nan & 14.6 ± 0.6 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & -0.093 & 0.242 & -0.277 & -0.154 & -0.070 ± 0.192 & nan ± nan & 0.9 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & -0.086 & 0.111 & -0.186 & -0.143 & -0.076 ± 0.114 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & -0.104 & 0.243 & -0.281 & -0.171 & -0.078 ± 0.196 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & DANetConfig_tab & -0.205 & -0.172 & 0.028 & -0.213 & -0.141 ± 0.098 & 2.6 ± 0.0 & 1.8 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & -0.190 & -0.079 & -0.060 & -0.249 & -0.144 ± 0.078 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet & -0.216 & -0.073 & -0.049 & -0.268 & -0.151 ± 0.093 & 2.7 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & -0.172 & -0.096 & -0.102 & -0.248 & -0.155 ± 0.062 & nan ± nan & 15.2 ± 1.8 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso & -0.405 & -0.179 & -0.020 & -0.504 & -0.277 ± 0.189 & 2.6 ± 0.0 & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & -0.405 & -0.179 & -0.020 & -0.504 & -0.277 ± 0.189 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_custom & -0.376 & -0.263 & -0.961 & -0.073 & -0.418 ± 0.331 & 2.8 ± 0.2 & 16.4 ± 1.7 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetModelConfig_tab & -0.405 & -0.451 & -0.647 & -0.500 & -0.501 ± 0.091 & 2.6 ± 0.0 & 1.8 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabTransformerConfig_tab & -1.087 & -0.623 & -1.880 & 0.126 & -0.866 ± 0.728 & 2.6 ± 0.0 & 1.5 ± 0.1 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_r2 = generate_metric_table(\n",
    "    results_list=dict_results_loo_nona,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='r2',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/3_training_loonona_r2_adjusted_sorted.csv\",\n",
    "    sort_order=\"descending\"\n",
    ")\n",
    "print(latex_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "continuous_imputer & ordinal_imputer & model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & mean ± std & imp_time (s) & fit_time (s) \\\\\n",
      "\\midrule\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_default & 0.648 & 0.624 & 0.550 & 0.592 & 0.603 ± 0.037 & 2.5 ± 0.0 & 12.4 ± 0.7 \\\\\n",
      "KNNImputer_5 & KNNImputer & RandomForestRegressor & 0.667 & 0.608 & 0.619 & 0.636 & 0.633 ± 0.022 & 2.5 ± 0.0 & 39.8 ± 0.5 \\\\\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor & 0.653 & 0.639 & 0.626 & 0.617 & 0.633 ± 0.013 & 2.5 ± 0.0 & 1.1 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & LinearRegression & 0.692 & 0.539 & 0.633 & 0.753 & 0.654 ± 0.079 & 2.7 ± 0.1 & 0.2 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & GatedAdditiveTreeEnsembleConfig_tab & 0.644 & 0.673 & 0.647 & 0.670 & 0.658 ± 0.013 & 2.6 ± 0.1 & 18.8 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso_tuned & 0.692 & 0.554 & 0.642 & 0.748 & 0.659 ± 0.071 & 2.6 ± 0.0 & 1.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & 0.736 & 0.702 & 0.626 & 0.595 & 0.665 ± 0.056 & nan ± nan & 0.8 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 0.736 & 0.682 & 0.640 & 0.634 & 0.673 ± 0.041 & nan ± nan & 32.5 ± 0.3 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & 0.737 & 0.669 & 0.620 & 0.677 & 0.676 ± 0.042 & nan ± nan & 4.2 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor_tuned & 0.752 & 0.612 & 0.565 & 0.819 & 0.687 ± 0.103 & 2.5 ± 0.0 & 5.0 ± 0.2 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet_tuned & 0.703 & 0.659 & 0.690 & 0.731 & 0.696 ± 0.026 & 2.7 ± 0.1 & 1.4 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & 0.725 & 0.699 & 0.711 & 0.695 & 0.708 ± 0.012 & nan ± nan & 0.9 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & 0.849 & 0.692 & 0.509 & 0.780 & 0.708 ± 0.127 & nan ± nan & 14.6 ± 0.6 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & 0.729 & 0.696 & 0.708 & 0.701 & 0.708 ± 0.013 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & 0.746 & 0.733 & 0.720 & 0.672 & 0.718 ± 0.028 & nan ± nan & 1.2 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & PLSRegression_4_components & 0.806 & 0.724 & 0.682 & 0.764 & 0.744 ± 0.046 & 2.6 ± 0.0 & 0.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & 0.790 & 0.788 & 0.721 & 0.731 & 0.758 ± 0.032 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & DANetConfig_tab & 0.909 & 0.788 & 0.604 & 0.833 & 0.784 ± 0.113 & 2.6 ± 0.0 & 1.8 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & 0.884 & 0.787 & 0.655 & 0.826 & 0.788 ± 0.084 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 0.857 & 0.875 & 0.611 & 0.810 & 0.788 ± 0.105 & nan ± nan & 15.2 ± 1.8 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet & 0.898 & 0.782 & 0.652 & 0.839 & 0.792 ± 0.091 & 2.7 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & 0.991 & 0.785 & 0.622 & 0.934 & 0.833 ± 0.143 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso & 0.991 & 0.785 & 0.622 & 0.934 & 0.833 ± 0.143 & 2.6 ± 0.0 & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_custom & 0.966 & 0.885 & 0.842 & 0.726 & 0.855 ± 0.087 & 2.8 ± 0.2 & 16.4 ± 1.7 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetModelConfig_tab & 1.079 & 0.951 & 0.782 & 0.946 & 0.940 ± 0.105 & 2.6 ± 0.0 & 1.8 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabTransformerConfig_tab & 1.199 & 1.021 & 0.998 & 0.744 & 0.990 ± 0.162 & 2.6 ± 0.0 & 1.5 ± 0.1 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=dict_results_loo_nona,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='mae',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/3_training_loonona_mae_adjusted_sorted.csv\",\n",
    "    sort_order=\"ascending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "continuous_imputer & ordinal_imputer & model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & mean ± std & imp_time (s) & fit_time (s) \\\\\n",
      "\\midrule\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_default & 0.702 & 0.647 & 0.367 & 0.566 & 0.570 ± 0.127 & 2.5 ± 0.0 & 12.4 ± 0.7 \\\\\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor & 0.797 & 0.549 & 0.466 & 0.665 & 0.619 ± 0.125 & 2.5 ± 0.0 & 1.1 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & RandomForestRegressor & 0.816 & 0.520 & 0.431 & 0.742 & 0.627 ± 0.157 & 2.5 ± 0.0 & 39.8 ± 0.5 \\\\\n",
      "KNNImputer_5 & KNNImputer & GatedAdditiveTreeEnsembleConfig_tab & 0.755 & 0.602 & 0.494 & 0.744 & 0.649 ± 0.108 & 2.6 ± 0.1 & 18.8 ± 0.3 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & 0.940 & 0.617 & 0.480 & 0.738 & 0.694 ± 0.169 & nan ± nan & 0.8 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet_tuned & 0.892 & 0.546 & 0.523 & 0.815 & 0.694 ± 0.162 & 2.7 ± 0.1 & 1.4 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 0.907 & 0.626 & 0.474 & 0.803 & 0.703 ± 0.166 & nan ± nan & 32.5 ± 0.3 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso_tuned & 0.891 & 0.498 & 0.553 & 0.882 & 0.706 ± 0.181 & 2.6 ± 0.0 & 1.1 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & LinearRegression & 0.890 & 0.494 & 0.562 & 0.886 & 0.708 ± 0.181 & 2.7 ± 0.1 & 0.2 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & XGBoostRegressor_tuned & 0.902 & 0.581 & 0.389 & 1.086 & 0.739 ± 0.271 & 2.5 ± 0.0 & 5.0 ± 0.2 \\\\\n",
      "KNNImputer_5 & KNNImputer & PLSRegression_4_components & 0.986 & 0.656 & 0.502 & 0.852 & 0.749 ± 0.185 & 2.6 ± 0.0 & 0.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & 1.073 & 0.571 & 0.502 & 0.932 & 0.769 ± 0.239 & nan ± nan & 4.2 ± 0.3 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & 1.033 & 0.673 & 0.576 & 0.865 & 0.787 ± 0.176 & nan ± nan & 1.2 ± 0.1 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & 1.084 & 0.669 & 0.613 & 0.949 & 0.829 ± 0.195 & nan ± nan & 0.9 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & 1.095 & 0.668 & 0.615 & 0.963 & 0.835 ± 0.200 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & 1.076 & 0.784 & 0.569 & 0.940 & 0.843 ± 0.189 & nan ± nan & 0.1 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & 1.163 & 0.694 & 0.413 & 1.195 & 0.866 ± 0.328 & nan ± nan & 14.6 ± 0.6 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & 1.179 & 0.952 & 0.509 & 1.027 & 0.917 ± 0.249 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 1.162 & 0.967 & 0.529 & 1.026 & 0.921 ± 0.237 & nan ± nan & 15.2 ± 1.8 \\\\\n",
      "KNNImputer_5 & KNNImputer & DANetConfig_tab & 1.195 & 1.034 & 0.467 & 0.997 & 0.923 ± 0.274 & 2.6 ± 0.0 & 1.8 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskElasticNet & 1.205 & 0.947 & 0.503 & 1.043 & 0.924 ± 0.260 & 2.7 ± 0.1 & 0.0 ± 0.0 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & 1.392 & 1.041 & 0.490 & 1.237 & 1.040 ± 0.341 & nan ± nan & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & MultiTaskLasso & 1.392 & 1.041 & 0.490 & 1.237 & 1.040 ± 0.341 & 2.6 ± 0.0 & 0.0 ± 0.0 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetRegressor_custom & 1.364 & 1.114 & 0.941 & 0.883 & 1.075 ± 0.187 & 2.8 ± 0.2 & 16.4 ± 1.7 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabNetModelConfig_tab & 1.392 & 1.280 & 0.791 & 1.234 & 1.174 ± 0.229 & 2.6 ± 0.0 & 1.8 ± 0.1 \\\\\n",
      "KNNImputer_5 & KNNImputer & TabTransformerConfig_tab & 2.068 & 1.432 & 1.383 & 0.718 & 1.400 ± 0.478 & 2.6 ± 0.0 & 1.5 ± 0.1 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mse = generate_metric_table(\n",
    "    results_list=dict_results_loo_nona,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='mse',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/3_training_loonona_mse_adjusted_sorted.csv\",\n",
    "    sort_order=\"ascending\"\n",
    ")\n",
    "print(latex_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
