{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.serialization.safe_globals at 0x7aa605dc58b0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from itertools import product\n",
    "import warnings\n",
    "\n",
    "# System path modification\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning imports\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, Lasso, LassoCV, MultiTaskLasso, MultiTaskLassoCV,\n",
    "    ElasticNet, ElasticNetCV, MultiTaskElasticNet, MultiTaskElasticNetCV\n",
    ")\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Custom modules\n",
    "from src.train import *\n",
    "from src.functions import *\n",
    "from src.plots import *\n",
    "from src.dataset import *\n",
    "from src.multixgboost import *\n",
    "from src.wrapper import *\n",
    "from src.debug import *\n",
    "\n",
    "# Visualizatiokn \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning and machine learning specific \n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "from pytorch_tabular.config import DataConfig, TrainerConfig, OptimizerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "\n",
    "from pytorch_tabular.models import (\n",
    "    GatedAdditiveTreeEnsembleConfig,\n",
    "    DANetConfig,\n",
    "    TabTransformerConfig,\n",
    "    FTTransformerConfig,\n",
    "    TabNetModelConfig,\n",
    ")\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Print CUDA availability for PyTorch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "from omegaconf import DictConfig\n",
    "torch.serialization.safe_globals([DictConfig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_pickle_data_palettes()\n",
    "\n",
    "results_pickle_folder = \"../pickle/\"\n",
    "\n",
    "# Unpack data\n",
    "df_X, df_y, df_all, df_FinalCombination = data[\"df_X\"], data[\"df_y\"], data[\"df_all\"], data[\"df_FinalCombination\"]\n",
    "dict_select = data[\"dict_select\"]\n",
    "\n",
    "# Unpack colormaps\n",
    "full_palette, gender_palette, dx_palette = data[\"colormaps\"].values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = list(df_X.isna().any(axis=1))\n",
    "idx_test = list(~df_X.isna().any(axis=1))\n",
    "\n",
    "set_intersect_rid = set(df_all[idx_train].RID).intersection(set(df_all[idx_test].RID))\n",
    "intersect_rid_idx = df_all.RID.isin(set_intersect_rid)\n",
    "\n",
    "for i, bool_test in enumerate(idx_test): \n",
    "    if intersect_rid_idx.iloc[i] & bool_test:\n",
    "        idx_test[i] = False\n",
    "        idx_train[i] = True\n",
    "        \n",
    "df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]] = df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]].astype(\"int\", errors='ignore')\n",
    "\n",
    "df_X_train = df_X.loc[idx_train]\n",
    "df_X_test = df_X.loc[idx_test]\n",
    "\n",
    "df_y_train = df_y.loc[idx_train]\n",
    "df_y_test = df_y.loc[idx_test]\n",
    "\n",
    "c_train = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_train]\n",
    "c_test = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3609    128_S_2002\n",
       "5631    116_S_4167\n",
       "5662    033_S_4176\n",
       "5780    098_S_4215\n",
       "5950    018_S_4349\n",
       "6069    941_S_4292\n",
       "6077    116_S_4453\n",
       "6085    135_S_4489\n",
       "6224    033_S_4505\n",
       "6400    014_S_4576\n",
       "6429    073_S_4300\n",
       "7021    003_S_2374\n",
       "7192    033_S_4179\n",
       "Name: SubjectID, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.SubjectID.iloc[idx_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define all the models and combinations to try out with their hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42\n",
    "\n",
    "# Continuous Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "continuous_imputer_list = [\n",
    "    (\"KNNImputer_5\", KNNImputer(n_neighbors=5)),\n",
    "    (\"IterativeImputer_Niter=1\", IterativeImputer(max_iter=1, random_state=42)),\n",
    "]\n",
    "\n",
    "# Ordinal Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "ordinal_imputer_list = [\n",
    "    (\"KNNImputer1\", KNNImputer(n_neighbors=1)),\n",
    "]\n",
    "\n",
    "# Predictive Models List (list of tuples with unique strings and corresponding instances)\n",
    "predictive_models_list = [\n",
    "    (\"LinearRegression\", LinearRegression()),\n",
    "    (\"MultiTaskElasticNet\", MultiTaskElasticNet()),\n",
    "    (\"MultiTaskElasticNet_tuned\", MultiTaskElasticNet(**{'alpha': 0.1, 'l1_ratio': 0.1})),\n",
    "    (\"MultiTaskLasso\", MultiTaskLasso()),\n",
    "    (\"MultiTaskLasso_tuned\", MultiTaskLasso(**{'alpha': 0.001})),\n",
    "    (\"RandomForestRegressor\", RandomForestRegressor()),\n",
    "    (\"XGBoostRegressor\", XGBoostRegressor()),\n",
    "    (\"XGBoostRegressor_tuned\", XGBoostRegressor(**{'colsample_bytree': 0.8776807051588262, 'learning_rate': 0.13329520360246094, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.5924272277627636})),\n",
    "    (\"TabNetRegressor_default\", TabNetModelWrapper(n_a=8, n_d=8)),\n",
    "    (\"TabNetRegressor_custom\", TabNetModelWrapper(n_a=32, n_d=32)),\n",
    "    (\"PLSRegression_4_components\", PLSRegression(n_components=4))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['APOE_epsilon2', 'APOE_epsilon3', 'APOE_epsilon4']\n",
    "continuous_features = [col for col in df_X_train.columns if col not in ordinal_features]\n",
    "\n",
    "# Prepare Tabular configurations (shared for all PyTorch models)\n",
    "data_config = DataConfig(\n",
    "    target=df_y_train.columns.tolist(),\n",
    "    continuous_cols=continuous_features,\n",
    "    categorical_cols=ordinal_features\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024, max_epochs=10, auto_lr_find=False,\n",
    "    early_stopping=\"valid_loss\", early_stopping_mode=\"min\", early_stopping_patience=5,\n",
    "    checkpoints=\"valid_loss\", load_best=True, progress_bar=\"nones\",\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "head_config = LinearHeadConfig(dropout=0.1).__dict__\n",
    "\n",
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabNetModelConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['APOE_epsilon2', 'APOE_epsilon3', 'APOE_epsilon4']\n",
    "continuous_features = [col for col in df_X_train.columns if col not in ordinal_features]\n",
    "\n",
    "# Prepare Tabular configurations (shared for all PyTorch models)\n",
    "data_config = DataConfig(\n",
    "    target=df_y_train.columns.tolist(),\n",
    "    continuous_cols=continuous_features,\n",
    "    categorical_cols=ordinal_features\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024, max_epochs=250, auto_lr_find=False,\n",
    "    early_stopping=\"valid_loss\", early_stopping_mode=\"min\", early_stopping_patience=5,\n",
    "    checkpoints=\"valid_loss\", load_best=True, progress_bar=\"nones\",\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "head_config = LinearHeadConfig(dropout=0.1).__dict__\n",
    "\n",
    "\n",
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab_epochs\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab_epochs\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab_epochs\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabNetModelConfig_tab_epochs\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: LinearRegression\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskElasticNet\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskElasticNet_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskLasso\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskLasso_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: RandomForestRegressor\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: XGBoostRegressor\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: XGBoostRegressor_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabNetRegressor_default\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabNetRegressor_custom\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: PLSRegression_4_components\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: GatedAdditiveTreeEnsembleConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: DANetConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabTransformerConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabNetModelConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: GatedAdditiveTreeEnsembleConfig_tab_epochs\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: DANetConfig_tab_epochs\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabTransformerConfig_tab_epochs\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabNetModelConfig_tab_epochs\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: LinearRegression\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: MultiTaskElasticNet\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: MultiTaskElasticNet_tuned\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: MultiTaskLasso\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: MultiTaskLasso_tuned\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: RandomForestRegressor\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: XGBoostRegressor\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: XGBoostRegressor_tuned\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: TabNetRegressor_default\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: TabNetRegressor_custom\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: PLSRegression_4_components\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: GatedAdditiveTreeEnsembleConfig_tab\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: DANetConfig_tab\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: TabTransformerConfig_tab\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: TabNetModelConfig_tab\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: GatedAdditiveTreeEnsembleConfig_tab_epochs\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: DANetConfig_tab_epochs\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: TabTransformerConfig_tab_epochs\n",
      "Continuous Imputer: IterativeImputer_Niter=1, Ordinal Imputer: KNNImputer1, Model: TabNetModelConfig_tab_epochs\n",
      "Combinations of preprocessing and models to test : 38\n"
     ]
    }
   ],
   "source": [
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "# Display all combinations\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    print(f\"Continuous Imputer: {continuous_imputer[0]}, Ordinal Imputer: {ordinal_imputer[0]}, Model: {model[0]}\")\n",
    "\n",
    "print(f\"Combinations of preprocessing and models to test : {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HDF5 file\n",
    "results_file = '../pickle/training_2_dict_results.pickle'\n",
    "\n",
    "if os.path.exists(results_file): \n",
    "\n",
    "    with open(results_file, \"rb\") as input_file:\n",
    "        all_dict_results = pickle.load(input_file)\n",
    "\n",
    "else : \n",
    "    all_dict_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False : \n",
    "    for result in all_dict_results:\n",
    "        print(result[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False : \n",
    "    params_comb = []\n",
    "\n",
    "    for params in params_comb:\n",
    "        all_dict_results = clean_dict_list(all_dict_results, remove_if_none=False, remove_key_val={\"params\": params})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict_results = clean_dict_list(all_dict_results, remove_if_none=False, remove_key_val={'fitting_time':None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training :LinearRegression\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'LinearRegression', (2881, 256), (13, 256)])\n",
      "Training :MultiTaskElasticNet\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'MultiTaskElasticNet', (2881, 256), (13, 256)])\n",
      "Training :MultiTaskElasticNet_tuned\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'MultiTaskElasticNet_tuned', (2881, 256), (13, 256)])\n",
      "Training :MultiTaskLasso\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'MultiTaskLasso', (2881, 256), (13, 256)])\n",
      "Training :MultiTaskLasso_tuned\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'MultiTaskLasso_tuned', (2881, 256), (13, 256)])\n",
      "Training :RandomForestRegressor\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'RandomForestRegressor', (2881, 256), (13, 256)])\n",
      "Training :XGBoostRegressor\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'XGBoostRegressor', (2881, 256), (13, 256)])\n",
      "Training :XGBoostRegressor_tuned\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'XGBoostRegressor_tuned', (2881, 256), (13, 256)])\n",
      "Training :TabNetRegressor_default\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'TabNetRegressor_default', (2881, 256), (13, 256)])\n",
      "Training :TabNetRegressor_custom\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'TabNetRegressor_custom', (2881, 256), (13, 256)])\n",
      "Training :PLSRegression_4_components\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'PLSRegression_4_components', (2881, 256), (13, 256)])\n",
      "Training :GatedAdditiveTreeEnsembleConfig_tab\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'GatedAdditiveTreeEnsembleConfig_tab', (2881, 256), (13, 256)])\n",
      "Training :DANetConfig_tab\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'DANetConfig_tab', (2881, 256), (13, 256)])\n",
      "Training :TabTransformerConfig_tab\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'TabTransformerConfig_tab', (2881, 256), (13, 256)])\n",
      "Training :TabNetModelConfig_tab\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'TabNetModelConfig_tab', (2881, 256), (13, 256)])\n",
      "Training :GatedAdditiveTreeEnsembleConfig_tab_epochs\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'GatedAdditiveTreeEnsembleConfig_tab_epochs', (2881, 256), (13, 256)])\n",
      "Training :DANetConfig_tab_epochs\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'DANetConfig_tab_epochs', (2881, 256), (13, 256)])\n",
      "Training :TabTransformerConfig_tab_epochs\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'TabTransformerConfig_tab_epochs', (2881, 256), (13, 256)])\n",
      "Training :TabNetModelConfig_tab_epochs\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'KNNImputer_5', 'TabNetModelConfig_tab_epochs', (2881, 256), (13, 256)])\n",
      "Training :LinearRegression\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'LinearRegression', (2881, 256), (13, 256)])\n",
      "Training :MultiTaskElasticNet\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'MultiTaskElasticNet', (2881, 256), (13, 256)])\n",
      "Training :MultiTaskElasticNet_tuned\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'MultiTaskElasticNet_tuned', (2881, 256), (13, 256)])\n",
      "Training :MultiTaskLasso\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'MultiTaskLasso', (2881, 256), (13, 256)])\n",
      "Training :MultiTaskLasso_tuned\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'MultiTaskLasso_tuned', (2881, 256), (13, 256)])\n",
      "Training :RandomForestRegressor\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'RandomForestRegressor', (2881, 256), (13, 256)])\n",
      "Training :XGBoostRegressor\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'XGBoostRegressor', (2881, 256), (13, 256)])\n",
      "Training :XGBoostRegressor_tuned\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'XGBoostRegressor_tuned', (2881, 256), (13, 256)])\n",
      "Training :TabNetRegressor_default\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'TabNetRegressor_default', (2881, 256), (13, 256)])\n",
      "Training :TabNetRegressor_custom\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'TabNetRegressor_custom', (2881, 256), (13, 256)])\n",
      "Training :PLSRegression_4_components\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'PLSRegression_4_components', (2881, 256), (13, 256)])\n",
      "Training :GatedAdditiveTreeEnsembleConfig_tab\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'GatedAdditiveTreeEnsembleConfig_tab', (2881, 256), (13, 256)])\n",
      "Training :DANetConfig_tab\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'DANetConfig_tab', (2881, 256), (13, 256)])\n",
      "Training :TabTransformerConfig_tab\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'TabTransformerConfig_tab', (2881, 256), (13, 256)])\n",
      "Training :TabNetModelConfig_tab\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'TabNetModelConfig_tab', (2881, 256), (13, 256)])\n",
      "Training :GatedAdditiveTreeEnsembleConfig_tab_epochs\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'GatedAdditiveTreeEnsembleConfig_tab_epochs', (2881, 256), (13, 256)])\n",
      "Training :DANetConfig_tab_epochs\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'DANetConfig_tab_epochs', (2881, 256), (13, 256)])\n",
      "Training :TabTransformerConfig_tab_epochs\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'TabTransformerConfig_tab_epochs', (2881, 256), (13, 256)])\n",
      "Training :TabNetModelConfig_tab_epochs\n",
      "Skipping existing combination: dict_values(['KNNImputer1', 'IterativeImputer_Niter=1', 'TabNetModelConfig_tab_epochs', (2881, 256), (13, 256)])\n"
     ]
    }
   ],
   "source": [
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    name_continuous_imputer, continuous_imputer_instance = continuous_imputer\n",
    "    name_ordinal_imputer, ordinal_imputer_instance = ordinal_imputer\n",
    "    name_model, model_instance = model\n",
    "\n",
    "    params = {\n",
    "        \"ordinal_imputer\": name_ordinal_imputer, \n",
    "        \"continuous_imputer\": name_continuous_imputer, \n",
    "        \"model\": name_model, \"train_shape\" : df_X_train.shape, \n",
    "        \"test_shape\": df_X_test.shape\n",
    "    }\n",
    "    print(f\"Training :{name_model}\")\n",
    "\n",
    "    if any(result['params'] == params for result in all_dict_results):\n",
    "        # Skip this iteration if the combination exists\n",
    "        print(f\"Skipping existing combination: {params.values()}\")\n",
    "        \n",
    "        continue\n",
    "\n",
    "    try: \n",
    "        # Now you can call your `train_model` function with these components\n",
    "        dict_results = train_imputer_model(\n",
    "            df_X_train, df_X_test, df_y_train, df_y_test,\n",
    "            c_train, c_test,\n",
    "            ordinal_imputer_instance, name_ordinal_imputer,\n",
    "            continuous_imputer_instance, name_continuous_imputer,\n",
    "            model_instance, name_model,\n",
    "            separate_imputers=True,\n",
    "            save_model = True  # Or however you want to specify\n",
    "        )\n",
    "\n",
    "    except Exception as e:  \n",
    "\n",
    "        print(e)\n",
    "    \n",
    "        dict_results = {\n",
    "        \"params\": params, \n",
    "        \"imputation_time\": None,\n",
    "        \"fitting_time\": None, \n",
    "        \"results_adj\": None, \n",
    "        \"results_org\": None,\n",
    "    }\n",
    "        \n",
    "    # Optionally keep the all_dict_results list updated\n",
    "    all_dict_results.append(dict_results)\n",
    "\n",
    "        # Save the updated results back to the pickle file\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(all_dict_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open(results_file, 'wb') as handle:\n",
    "    pickle.dump(all_dict_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/training_2_dict_results.pickle', \"rb\") as input_file:\n",
    "    dict_results_split = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models only on MRI features to compare performances\n",
    "\n",
    "## Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = list(df_X.isna().any(axis=1))\n",
    "idx_test = list(~df_X.isna().any(axis=1))\n",
    "\n",
    "set_intersect_rid = set(df_all[idx_train].RID).intersection(set(df_all[idx_test].RID))\n",
    "intersect_rid_idx = df_all.RID.isin(set_intersect_rid)\n",
    "\n",
    "for i, bool_test in enumerate(idx_test): \n",
    "    if intersect_rid_idx.iloc[i] & bool_test:\n",
    "        idx_test[i] = False\n",
    "        idx_train[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]] = df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]].astype(\"int\", errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train = df_X[dict_select[\"MRIth\"]].loc[idx_train]\n",
    "df_X_test = df_X[dict_select[\"MRIth\"]].loc[idx_test]\n",
    "\n",
    "df_y_train = df_y.loc[idx_train]\n",
    "df_y_test = df_y.loc[idx_test]\n",
    "\n",
    "c_train = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_train]\n",
    "c_test = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42\n",
    "n_imputation_iter = 10\n",
    "\n",
    "# Continuous Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "continuous_imputer_list = [\n",
    "    (\"NoImputer\", KNNImputer(n_neighbors=1)),\n",
    "\n",
    "]\n",
    "\n",
    "# Ordinal Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "ordinal_imputer_list = [\n",
    "    (\"NoImputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "]\n",
    "\n",
    "# Predictive Models List (list of tuples with unique strings and corresponding instances)\n",
    "predictive_models_list = [\n",
    "    (\"LinearRegression\", LinearRegression()),\n",
    "    (\"MultiTaskElasticNet\", MultiTaskElasticNet()),\n",
    "    (\"MultiTaskElasticNet_tuned\", MultiTaskElasticNet(**{'alpha': 0.01, 'l1_ratio': 0.01})),\n",
    "    (\"MultiTaskLasso\", MultiTaskLasso()),\n",
    "    (\"MultiTaskLasso_tuned\", MultiTaskLasso(**{'alpha': 0.001})),\n",
    "    (\"RandomForestRegressor\", RandomForestRegressor()),\n",
    "    (\"XGBoostRegressor\", XGBoostRegressor()),\n",
    "    (\"XGBoostRegressor_tuned\", XGBoostRegressor(**{'colsample_bytree': 0.8776807051588262, 'learning_rate': 0.13329520360246094, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.5924272277627636})),\n",
    "    (\"TabNetRegressor_default\", TabNetModelWrapper(n_a=8, n_d=8)),\n",
    "    (\"TabNetRegressor_custom\", TabNetModelWrapper(n_a=32, n_d=32)),\n",
    "    (\"PLSRegression_4_components\", PLSRegression(n_components=4))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['APOE_epsilon2', 'APOE_epsilon3', 'APOE_epsilon4']\n",
    "continuous_features = [col for col in df_X_train.columns if col not in ordinal_features]\n",
    "\n",
    "# Prepare Tabular configurations (shared for all PyTorch models)\n",
    "data_config = DataConfig(\n",
    "    target=df_y_train.columns.tolist(),\n",
    "    continuous_cols=continuous_features,\n",
    "    categorical_cols=[]\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=256, max_epochs=250, auto_lr_find=False,\n",
    "    early_stopping=\"valid_loss\", early_stopping_mode=\"min\", early_stopping_patience=5,\n",
    "    checkpoints=\"valid_loss\", load_best=True, progress_bar=\"nones\",\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "head_config = LinearHeadConfig(dropout=0.1).__dict__\n",
    "\n",
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab_epochs\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab_epochs\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab_epochs\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabNetModelConfig_tab_epochs\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: LinearRegression\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskElasticNet\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskElasticNet_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskLasso\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskLasso_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: RandomForestRegressor\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: XGBoostRegressor\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: XGBoostRegressor_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetRegressor_default\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetRegressor_custom\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: PLSRegression_4_components\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: GatedAdditiveTreeEnsembleConfig_tab_epochs\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: DANetConfig_tab_epochs\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabTransformerConfig_tab_epochs\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetModelConfig_tab_epochs\n",
      "Combinations of preprocessing and models to test : 15\n"
     ]
    }
   ],
   "source": [
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "# Display all combinations\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    print(f\"Continuous Imputer: {continuous_imputer[0]}, Ordinal Imputer: {ordinal_imputer[0]}, Model: {model[0]}\")\n",
    "\n",
    "print(f\"Combinations of preprocessing and models to test : {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HDF5 file\n",
    "results_file = '../pickle/training_2_dict_results.pickle'\n",
    "\n",
    "with open(results_file, \"rb\") as input_file:\n",
    "    all_dict_results = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training :LinearRegression\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'LinearRegression', (2881, 200), (13, 200)])\n",
      "Training :MultiTaskElasticNet\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'MultiTaskElasticNet', (2881, 200), (13, 200)])\n",
      "Training :MultiTaskElasticNet_tuned\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'MultiTaskElasticNet_tuned', (2881, 200), (13, 200)])\n",
      "Training :MultiTaskLasso\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'MultiTaskLasso', (2881, 200), (13, 200)])\n",
      "Training :MultiTaskLasso_tuned\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'MultiTaskLasso_tuned', (2881, 200), (13, 200)])\n",
      "Training :RandomForestRegressor\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'RandomForestRegressor', (2881, 200), (13, 200)])\n",
      "Training :XGBoostRegressor\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'XGBoostRegressor', (2881, 200), (13, 200)])\n",
      "Training :XGBoostRegressor_tuned\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'XGBoostRegressor_tuned', (2881, 200), (13, 200)])\n",
      "Training :TabNetRegressor_default\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'TabNetRegressor_default', (2881, 200), (13, 200)])\n",
      "Training :TabNetRegressor_custom\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'TabNetRegressor_custom', (2881, 200), (13, 200)])\n",
      "Training :PLSRegression_4_components\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'PLSRegression_4_components', (2881, 200), (13, 200)])\n",
      "Training :GatedAdditiveTreeEnsembleConfig_tab_epochs\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'GatedAdditiveTreeEnsembleConfig_tab_epochs', (2881, 200), (13, 200)])\n",
      "Training :DANetConfig_tab_epochs\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'DANetConfig_tab_epochs', (2881, 200), (13, 200)])\n",
      "Training :TabTransformerConfig_tab_epochs\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'TabTransformerConfig_tab_epochs', (2881, 200), (13, 200)])\n",
      "Training :TabNetModelConfig_tab_epochs\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'TabNetModelConfig_tab_epochs', (2881, 200), (13, 200)])\n"
     ]
    }
   ],
   "source": [
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    name_continuous_imputer, continuous_imputer_instance = continuous_imputer\n",
    "    name_ordinal_imputer, ordinal_imputer_instance = ordinal_imputer\n",
    "    name_model, model_instance = model\n",
    "\n",
    "    print(f\"Training :{name_model}\")\n",
    "    params = {\n",
    "        \"ordinal_imputer\": name_ordinal_imputer, \n",
    "        \"continuous_imputer\": name_continuous_imputer, \n",
    "        \"model\": name_model, \"train_shape\" : df_X_train.shape, \n",
    "        \"test_shape\": df_X_test.shape\n",
    "    }\n",
    "\n",
    "    if any(result['params'] == params for result in all_dict_results):\n",
    "        # Skip this iteration if the combination exists\n",
    "        print(f\"Skipping existing combination: {params.values()}\")\n",
    "        \n",
    "        continue\n",
    "\n",
    "    try: \n",
    "    \n",
    "        # Now you can call your `train_model` function with these components\n",
    "        dict_results = train_imputer_model(\n",
    "            df_X_train, df_X_test, df_y_train, df_y_test,\n",
    "            c_train, c_test,\n",
    "            ordinal_imputer_instance, name_ordinal_imputer,\n",
    "            continuous_imputer_instance, name_continuous_imputer,\n",
    "            model_instance, name_model,\n",
    "            separate_imputers=True  # Or however you want to specify\n",
    "        )\n",
    "\n",
    "    except Exception as e:  \n",
    "\n",
    "        print(e)\n",
    "    \n",
    "\n",
    "        dict_results = {\n",
    "        \"params\": params, \n",
    "        \"imputation_time\": None,\n",
    "        \"fitting_time\": None, \n",
    "        \"results_adj\": None, \n",
    "        \"results_org\": None\n",
    "    }\n",
    "        \n",
    "    # Optionally keep the all_dict_results list updated\n",
    "    all_dict_results.append(dict_results)\n",
    "\n",
    "    # Save the updated results back to the pickle file\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(all_dict_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open(results_file, 'wb') as handle:\n",
    "    pickle.dump(all_dict_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Table for reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = \"../pickle/training_2_dict_results.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_file, \"rb\") as input_file:\n",
    "    all_dict_results = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metric_table(\n",
    "    results_list,\n",
    "    targets,\n",
    "    metric_name,\n",
    "    source=\"Adjusted\",\n",
    "    float_format=\"%.3f\",\n",
    "    csv_filename=None,\n",
    "    sort_order=\"ascending\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a LaTeX and CSV table for a single metric across targets, models, and imputers,\n",
    "    including mean ± std for performance, imputation time, and fitting time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results_list : list of dict\n",
    "        List of experiment results.\n",
    "    targets : list of str\n",
    "        Target names (e.g., ['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN']).\n",
    "    metric_name : str\n",
    "        Metric to extract (e.g., 'mae_score').\n",
    "    source : str\n",
    "        'Adjusted' or 'Original'.\n",
    "    float_format : str\n",
    "        Format for floats (e.g., '%.3f').\n",
    "    csv_filename : str or None\n",
    "        If provided, saves the table to CSV.\n",
    "    sort_order : str\n",
    "        'ascending' or 'descending' for sorting by mean.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        Final formatted DataFrame.\n",
    "    latex_table : str\n",
    "        LaTeX-formatted table string.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    version_key = \"results_adj\" if source.lower() == \"adjusted\" else \"results_org\"\n",
    "\n",
    "    for res in results_list:\n",
    "        result_block = res.get(version_key)\n",
    "        if result_block is None:\n",
    "            continue\n",
    "\n",
    "        metric_values = result_block.get(metric_name)\n",
    "        if metric_values is None:\n",
    "            continue\n",
    "\n",
    "        if len(metric_values) != len(targets):\n",
    "            continue\n",
    "\n",
    "        ordinal_imputer = res[\"params\"].get(\"ordinal_imputer\")\n",
    "        continuous_imputer = res[\"params\"].get(\"continuous_imputer\")\n",
    "        model = res[\"params\"].get(\"model\")\n",
    "\n",
    "        values = np.array(metric_values, dtype=np.float64)\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "\n",
    "        # Time metrics\n",
    "        imp_times = np.array(res.get(\"imputation_time\", []), dtype=np.float64)\n",
    "        fit_times = np.array(res.get(\"fitting_time\", []), dtype=np.float64)\n",
    "\n",
    "        row = {\n",
    "            \"Ordinal Imputer\": ordinal_imputer,\n",
    "            \"Continuous Imputer\": continuous_imputer,\n",
    "            \"Model\": model,\n",
    "            \"Mean\": mean_val,\n",
    "            \"Mean ± SD\": f\"{mean_val:.3f} ± {std_val:.3f}\",\n",
    "            \"Imputation Time\": f\"{imp_times.mean():.2f}\" if imp_times.size > 0 else \"N/A\",\n",
    "            \"Fitting Time\": f\"{fit_times.mean():.2f}\" if fit_times.size > 0 else \"N/A\"\n",
    "        }\n",
    "\n",
    "        row.update({target: val for target, val in zip(targets, values)})\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Reorder columns for display\n",
    "    display_cols = (\n",
    "        [\"Ordinal Imputer\", \"Continuous Imputer\", \"Model\"] +\n",
    "        targets +\n",
    "        [\"Mean ± SD\", \"Imputation Time\", \"Fitting Time\"]\n",
    "    )\n",
    "    df = df.sort_values(by=\"Mean\", ascending=(sort_order == \"ascending\"))\n",
    "    df = df[display_cols]\n",
    "\n",
    "    df.drop_duplicates(subset=[\"Ordinal Imputer\", \"Continuous Imputer\", \"Model\"] +\n",
    "        targets +\n",
    "        [\"Mean ± SD\",], inplace=True)\n",
    "\n",
    "    # Save CSV if requested\n",
    "    if csv_filename:\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    # Generate LaTeX table\n",
    "    latex_table = df.to_latex(\n",
    "        index=False,\n",
    "        escape=False,\n",
    "        float_format=float_format,\n",
    "        caption=f\"{metric_name.replace('_', ' ').upper()} across targets with timing info\",\n",
    "        label=f\"tab:{metric_name}\",\n",
    "        longtable=False\n",
    "    )\n",
    "\n",
    "    return df, latex_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{CORR across targets with timing info}\n",
      "\\label{tab:corr}\n",
      "\\begin{tabular}{lllrrrrlll}\n",
      "\\toprule\n",
      "Ordinal Imputer & Continuous Imputer & Model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & Mean ± SD & Imputation Time & Fitting Time \\\\\n",
      "\\midrule\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_custom & 0.745 & 0.795 & 0.659 & 0.594 & 0.698 ± 0.077 & 2.60 & 11.81 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_default & 0.749 & 0.626 & 0.391 & 0.739 & 0.626 ± 0.144 & 2.50 & 12.06 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetRegressor_custom & 0.683 & 0.700 & 0.529 & 0.553 & 0.616 ± 0.076 & 101.45 & 12.80 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & GatedAdditiveTreeEnsembleConfig_tab_epochs & 0.599 & 0.750 & 0.458 & 0.531 & 0.584 ± 0.108 & 2.61 & 128.53 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor_tuned & 0.706 & 0.732 & 0.179 & 0.717 & 0.584 ± 0.234 & 2.57 & 4.84 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & RandomForestRegressor & 0.617 & 0.690 & 0.352 & 0.671 & 0.583 ± 0.136 & 2.56 & 41.14 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & GatedAdditiveTreeEnsembleConfig_tab_epochs & 0.489 & 0.683 & 0.481 & 0.661 & 0.579 ± 0.094 & 105.27 & 150.23 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor & 0.592 & 0.752 & 0.300 & 0.654 & 0.575 ± 0.168 & 2.66 & 1.17 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & GatedAdditiveTreeEnsembleConfig_tab & 0.712 & 0.600 & 0.164 & 0.779 & 0.564 ± 0.240 & 158.45 & 19.35 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & XGBoostRegressor & 0.589 & 0.669 & 0.362 & 0.620 & 0.560 ± 0.118 & 102.82 & 1.11 \\\\\n",
      "NoImputer & NoImputer & GatedAdditiveTreeEnsembleConfig_tab_epochs & 0.707 & 0.527 & 0.341 & 0.615 & 0.548 ± 0.135 & nan & 316.09 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & GatedAdditiveTreeEnsembleConfig_tab & 0.684 & 0.574 & 0.147 & 0.767 & 0.543 ± 0.238 & 2.54 & 16.46 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & RandomForestRegressor & 0.525 & 0.660 & 0.333 & 0.615 & 0.533 ± 0.125 & 98.64 & 39.77 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 0.516 & 0.695 & 0.198 & 0.619 & 0.507 ± 0.189 & nan & 33.01 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & 0.522 & 0.698 & 0.212 & 0.566 & 0.500 ± 0.178 & nan & 0.88 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & LinearRegression & 0.515 & 0.699 & 0.236 & 0.519 & 0.492 ± 0.166 & 114.18 & 0.10 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 0.553 & 0.581 & 0.237 & 0.597 & 0.492 ± 0.148 & nan & 12.56 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & XGBoostRegressor_tuned & 0.460 & 0.628 & 0.143 & 0.701 & 0.483 ± 0.215 & 100.32 & 4.61 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskLasso_tuned & 0.509 & 0.676 & 0.204 & 0.528 & 0.480 ± 0.172 & 115.13 & 1.09 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetRegressor_default & 0.502 & 0.485 & 0.387 & 0.536 & 0.478 ± 0.056 & 124.55 & 13.82 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & 0.629 & 0.471 & 0.067 & 0.730 & 0.474 ± 0.253 & nan & 12.95 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskElasticNet_tuned & 0.542 & 0.635 & 0.111 & 0.580 & 0.467 ± 0.208 & 112.16 & 1.26 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & LinearRegression & 0.483 & 0.707 & 0.194 & 0.446 & 0.457 ± 0.182 & 2.61 & 0.05 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso_tuned & 0.482 & 0.708 & 0.186 & 0.450 & 0.456 ± 0.185 & 2.60 & 1.10 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet_tuned & 0.485 & 0.692 & 0.130 & 0.518 & 0.456 ± 0.204 & 2.65 & 1.20 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & 0.413 & 0.733 & 0.187 & 0.475 & 0.452 ± 0.194 & nan & 4.03 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & PLSRegression_4_components & 0.547 & 0.533 & 0.081 & 0.575 & 0.434 ± 0.204 & 139.04 & 0.14 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & PLSRegression_4_components & 0.460 & 0.567 & 0.115 & 0.499 & 0.410 ± 0.174 & 2.57 & 0.08 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabTransformerConfig_tab_epochs & 0.411 & 0.685 & 0.067 & 0.403 & 0.392 ± 0.219 & 2.63 & 30.44 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabTransformerConfig_tab_epochs & 0.395 & 0.611 & 0.029 & 0.452 & 0.372 ± 0.213 & 102.58 & 29.93 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & 0.340 & 0.549 & 0.014 & 0.391 & 0.324 ± 0.195 & nan & 0.85 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & 0.338 & 0.551 & 0.010 & 0.392 & 0.323 ± 0.197 & nan & 0.84 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & 0.433 & 0.445 & -0.054 & 0.457 & 0.321 ± 0.216 & nan & 0.05 \\\\\n",
      "NoImputer & NoImputer & TabTransformerConfig_tab_epochs & 0.352 & 0.538 & -0.033 & 0.422 & 0.320 ± 0.214 & nan & 17.10 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & 0.332 & 0.548 & 0.016 & 0.381 & 0.319 ± 0.192 & nan & 0.05 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskElasticNet & 0.515 & 0.261 & -0.111 & 0.508 & 0.293 ± 0.255 & 111.67 & 0.02 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & 0.422 & 0.179 & -0.163 & 0.446 & 0.221 ± 0.245 & nan & 0.02 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet & 0.369 & 0.212 & -0.123 & 0.425 & 0.221 ± 0.213 & 2.71 & 0.02 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & DANetConfig_tab & 0.084 & 0.275 & 0.309 & 0.178 & 0.211 ± 0.088 & 2.56 & 1.95 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & DANetConfig_tab_epochs & 0.084 & 0.275 & 0.309 & 0.178 & 0.211 ± 0.088 & 2.66 & 2.01 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & DANetConfig_tab & 0.083 & 0.236 & 0.297 & 0.201 & 0.204 ± 0.078 & 110.09 & 1.77 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & DANetConfig_tab_epochs & 0.083 & 0.236 & 0.297 & 0.201 & 0.204 ± 0.078 & 104.00 & 1.79 \\\\\n",
      "NoImputer & NoImputer & TabNetModelConfig_tab_epochs & 0.374 & 0.254 & 0.194 & -0.099 & 0.181 ± 0.174 & nan & 2.18 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabTransformerConfig_tab & 0.063 & 0.156 & -0.026 & 0.503 & 0.174 ± 0.201 & 106.87 & 1.54 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabTransformerConfig_tab & 0.032 & 0.167 & -0.032 & 0.514 & 0.170 ± 0.211 & 2.71 & 1.44 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetModelConfig_tab & -0.199 & 0.426 & 0.159 & -0.318 & 0.017 ± 0.294 & 2.69 & 1.70 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetModelConfig_tab_epochs & -0.199 & 0.426 & 0.159 & -0.318 & 0.017 ± 0.294 & 2.69 & 1.69 \\\\\n",
      "NoImputer & NoImputer & DANetConfig_tab_epochs & -0.015 & 0.457 & -0.463 & -0.037 & -0.015 ± 0.326 & nan & 6.86 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetModelConfig_tab & -0.197 & 0.045 & -0.143 & -0.276 & -0.143 ± 0.119 & 104.12 & 2.00 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetModelConfig_tab_epochs & -0.197 & 0.045 & -0.143 & -0.276 & -0.143 ± 0.119 & 99.94 & 2.11 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso & NaN & NaN & NaN & NaN & nan ± nan & 2.63 & 0.01 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskLasso & NaN & NaN & NaN & NaN & nan ± nan & 109.98 & 0.01 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & NaN & NaN & NaN & NaN & nan ± nan & nan & 0.01 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='corr',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_corr_adjusted_sorted.csv\",\n",
    "    sort_order=\"descending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{R2 across targets with timing info}\n",
      "\\label{tab:r2}\n",
      "\\begin{tabular}{lllrrrrlll}\n",
      "\\toprule\n",
      "Ordinal Imputer & Continuous Imputer & Model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & Mean ± SD & Imputation Time & Fitting Time \\\\\n",
      "\\midrule\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_custom & 0.326 & 0.572 & 0.433 & 0.170 & 0.375 ± 0.147 & 2.60 & 11.81 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor_tuned & 0.362 & 0.476 & -0.098 & 0.376 & 0.279 ± 0.222 & 2.57 & 4.84 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & GatedAdditiveTreeEnsembleConfig_tab_epochs & 0.122 & 0.541 & 0.201 & 0.147 & 0.253 ± 0.169 & 2.61 & 128.53 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & GatedAdditiveTreeEnsembleConfig_tab & 0.344 & 0.358 & 0.005 & 0.188 & 0.224 ± 0.143 & 158.45 & 19.35 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor & 0.126 & 0.461 & 0.030 & 0.175 & 0.198 ± 0.161 & 2.66 & 1.17 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & XGBoostRegressor & 0.175 & 0.382 & 0.109 & 0.106 & 0.193 ± 0.113 & 102.82 & 1.11 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & GatedAdditiveTreeEnsembleConfig_tab & 0.275 & 0.324 & -0.004 & 0.116 & 0.178 ± 0.130 & 2.54 & 16.46 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & GatedAdditiveTreeEnsembleConfig_tab_epochs & -0.113 & 0.400 & 0.174 & 0.242 & 0.176 ± 0.186 & 105.27 & 150.23 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & RandomForestRegressor & 0.121 & 0.323 & 0.105 & 0.115 & 0.166 ± 0.091 & 2.56 & 41.14 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetRegressor_default & 0.113 & 0.229 & 0.114 & 0.133 & 0.147 ± 0.048 & 124.55 & 13.82 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskElasticNet_tuned & 0.180 & 0.358 & -0.099 & 0.138 & 0.144 ± 0.163 & 112.16 & 1.26 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetRegressor_custom & 0.228 & 0.351 & 0.081 & -0.093 & 0.142 ± 0.166 & 101.45 & 12.80 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & LinearRegression & 0.142 & 0.475 & -0.091 & 0.041 & 0.142 ± 0.209 & 114.18 & 0.10 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskLasso_tuned & 0.131 & 0.437 & -0.092 & 0.054 & 0.133 ± 0.193 & 115.13 & 1.09 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & RandomForestRegressor & 0.022 & 0.313 & 0.102 & 0.044 & 0.120 ± 0.115 & 98.64 & 39.77 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & -0.008 & 0.373 & -0.040 & 0.092 & 0.104 ± 0.162 & nan & 0.88 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 0.018 & 0.343 & -0.040 & 0.074 & 0.099 ± 0.147 & nan & 33.01 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & PLSRegression_4_components & 0.131 & 0.243 & -0.082 & 0.091 & 0.096 ± 0.117 & 139.04 & 0.14 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet_tuned & 0.082 & 0.373 & -0.084 & -0.008 & 0.091 ± 0.173 & 2.65 & 1.20 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & XGBoostRegressor_tuned & -0.006 & 0.364 & -0.243 & 0.198 & 0.078 ± 0.227 & 100.32 & 4.61 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso_tuned & 0.083 & 0.430 & -0.138 & -0.095 & 0.070 ± 0.224 & 2.60 & 1.10 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & LinearRegression & 0.085 & 0.435 & -0.158 & -0.099 & 0.066 ± 0.232 & 2.61 & 0.05 \\\\\n",
      "NoImputer & NoImputer & GatedAdditiveTreeEnsembleConfig_tab_epochs & 0.392 & 0.139 & -0.328 & 0.003 & 0.052 ± 0.260 & nan & 316.09 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_default & 0.170 & 0.046 & -0.086 & 0.069 & 0.050 ± 0.091 & 2.50 & 12.06 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & PLSRegression_4_components & -0.001 & 0.254 & -0.046 & -0.043 & 0.041 ± 0.124 & 2.57 & 0.08 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & -0.076 & 0.429 & -0.232 & 0.039 & 0.040 ± 0.244 & nan & 4.03 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabTransformerConfig_tab_epochs & 0.018 & 0.380 & -0.245 & -0.126 & 0.007 ± 0.235 & 2.63 & 30.44 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabTransformerConfig_tab_epochs & -0.035 & 0.329 & -0.298 & -0.060 & -0.016 ± 0.224 & 102.58 & 29.93 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 0.064 & 0.133 & -0.277 & -0.064 & -0.036 ± 0.156 & nan & 12.56 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & -0.011 & 0.033 & -0.301 & 0.042 & -0.059 ± 0.141 & nan & 12.95 \\\\\n",
      "NoImputer & NoImputer & TabTransformerConfig_tab_epochs & -0.094 & 0.235 & -0.392 & -0.059 & -0.077 ± 0.222 & nan & 17.10 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & -0.093 & 0.106 & -0.189 & -0.151 & -0.082 ± 0.114 & nan & 0.05 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & -0.109 & 0.238 & -0.289 & -0.168 & -0.082 ± 0.196 & nan & 0.84 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & -0.112 & 0.232 & -0.289 & -0.172 & -0.085 ± 0.194 & nan & 0.85 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & -0.124 & 0.232 & -0.295 & -0.189 & -0.094 ± 0.198 & nan & 0.05 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskElasticNet & -0.150 & -0.043 & -0.046 & -0.220 & -0.115 ± 0.074 & 111.67 & 0.02 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & DANetConfig_tab & -0.205 & -0.182 & 0.029 & -0.205 & -0.141 ± 0.099 & 110.09 & 1.77 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & DANetConfig_tab_epochs & -0.205 & -0.182 & 0.029 & -0.205 & -0.141 ± 0.099 & 104.00 & 1.79 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & DANetConfig_tab & -0.214 & -0.172 & 0.031 & -0.223 & -0.145 ± 0.103 & 2.56 & 1.95 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & DANetConfig_tab_epochs & -0.214 & -0.172 & 0.031 & -0.223 & -0.145 ± 0.103 & 2.66 & 2.01 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & -0.193 & -0.078 & -0.059 & -0.252 & -0.146 ± 0.080 & nan & 0.02 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet & -0.222 & -0.072 & -0.047 & -0.273 & -0.154 ± 0.096 & 2.71 & 0.02 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & -0.409 & -0.181 & -0.020 & -0.508 & -0.279 ± 0.191 & nan & 0.01 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskLasso & -0.409 & -0.181 & -0.020 & -0.508 & -0.279 ± 0.191 & 109.98 & 0.01 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso & -0.409 & -0.181 & -0.020 & -0.508 & -0.279 ± 0.191 & 2.63 & 0.01 \\\\\n",
      "NoImputer & NoImputer & TabNetModelConfig_tab_epochs & -0.424 & -0.186 & -0.125 & -0.615 & -0.337 ± 0.195 & nan & 2.18 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetModelConfig_tab & -0.483 & -0.338 & -0.371 & -0.648 & -0.460 ± 0.121 & 2.69 & 1.70 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetModelConfig_tab_epochs & -0.483 & -0.338 & -0.371 & -0.648 & -0.460 ± 0.121 & 2.69 & 1.69 \\\\\n",
      "NoImputer & NoImputer & DANetConfig_tab_epochs & -0.626 & 0.140 & -0.684 & -0.745 & -0.479 ± 0.360 & nan & 6.86 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetModelConfig_tab_epochs & -0.649 & -0.662 & -0.788 & -0.817 & -0.729 ± 0.074 & 99.94 & 2.11 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetModelConfig_tab & -0.649 & -0.662 & -0.788 & -0.817 & -0.729 ± 0.074 & 104.12 & 2.00 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabTransformerConfig_tab & -1.064 & -0.675 & -1.883 & 0.079 & -0.886 ± 0.708 & 2.71 & 1.44 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabTransformerConfig_tab & -1.277 & -0.728 & -2.053 & 0.067 & -0.998 ± 0.774 & 106.87 & 1.54 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='r2',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_r2_adjusted_sorted.csv\",\n",
    "    sort_order=\"descending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{MSE SCORE across targets with timing info}\n",
      "\\label{tab:mse_score}\n",
      "\\begin{tabular}{lllrrrrlll}\n",
      "\\toprule\n",
      "Ordinal Imputer & Continuous Imputer & Model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & Mean ± SD & Imputation Time & Fitting Time \\\\\n",
      "\\midrule\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_custom & 0.667 & 0.377 & 0.271 & 0.682 & 0.499 ± 0.179 & 2.60 & 11.81 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor_tuned & 0.631 & 0.462 & 0.526 & 0.513 & 0.533 ± 0.061 & 2.57 & 4.84 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & GatedAdditiveTreeEnsembleConfig_tab_epochs & 0.869 & 0.405 & 0.383 & 0.702 & 0.589 ± 0.205 & 2.61 & 128.53 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & GatedAdditiveTreeEnsembleConfig_tab & 0.649 & 0.566 & 0.477 & 0.667 & 0.590 ± 0.076 & 158.45 & 19.35 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor & 0.864 & 0.475 & 0.465 & 0.678 & 0.621 ± 0.165 & 2.66 & 1.17 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & GatedAdditiveTreeEnsembleConfig_tab & 0.718 & 0.595 & 0.481 & 0.727 & 0.630 ± 0.101 & 2.54 & 16.46 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & XGBoostRegressor & 0.816 & 0.545 & 0.427 & 0.735 & 0.631 ± 0.154 & 102.82 & 1.11 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskElasticNet_tuned & 0.811 & 0.565 & 0.526 & 0.709 & 0.653 ± 0.114 & 112.16 & 1.26 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & RandomForestRegressor & 0.869 & 0.597 & 0.429 & 0.728 & 0.656 ± 0.163 & 2.56 & 41.14 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & LinearRegression & 0.849 & 0.463 & 0.522 & 0.788 & 0.656 ± 0.166 & 114.18 & 0.10 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & GatedAdditiveTreeEnsembleConfig_tab_epochs & 1.102 & 0.528 & 0.396 & 0.623 & 0.662 ± 0.266 & 105.27 & 150.23 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskLasso_tuned & 0.860 & 0.496 & 0.523 & 0.777 & 0.664 ± 0.158 & 115.13 & 1.09 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetRegressor_custom & 0.764 & 0.572 & 0.440 & 0.898 & 0.668 ± 0.176 & 101.45 & 12.80 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetRegressor_default & 0.878 & 0.679 & 0.425 & 0.713 & 0.674 ± 0.162 & 124.55 & 13.82 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & RandomForestRegressor & 0.968 & 0.605 & 0.430 & 0.786 & 0.697 ± 0.201 & 98.64 & 39.77 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & PLSRegression_4_components & 0.860 & 0.667 & 0.518 & 0.747 & 0.698 ± 0.124 & 139.04 & 0.14 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & 0.997 & 0.553 & 0.498 & 0.746 & 0.699 ± 0.196 & nan & 0.88 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet_tuned & 0.908 & 0.553 & 0.519 & 0.829 & 0.702 ± 0.169 & 2.65 & 1.20 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 0.971 & 0.579 & 0.498 & 0.761 & 0.702 ± 0.182 & nan & 33.01 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & XGBoostRegressor_tuned & 0.995 & 0.561 & 0.595 & 0.660 & 0.703 ± 0.172 & 100.32 & 4.61 \\\\\n",
      "NoImputer & NoImputer & GatedAdditiveTreeEnsembleConfig_tab_epochs & 0.602 & 0.759 & 0.636 & 0.819 & 0.704 ± 0.088 & nan & 316.09 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso_tuned & 0.907 & 0.502 & 0.545 & 0.900 & 0.713 ± 0.191 & 2.60 & 1.10 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & LinearRegression & 0.905 & 0.498 & 0.555 & 0.904 & 0.715 ± 0.190 & 2.61 & 0.05 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_default & 0.822 & 0.840 & 0.520 & 0.765 & 0.737 ± 0.128 & 2.50 & 12.06 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & 1.065 & 0.503 & 0.590 & 0.790 & 0.737 ± 0.216 & nan & 4.03 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & PLSRegression_4_components & 0.990 & 0.658 & 0.501 & 0.857 & 0.752 ± 0.187 & 2.57 & 0.08 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabTransformerConfig_tab_epochs & 0.971 & 0.546 & 0.596 & 0.926 & 0.760 ± 0.190 & 2.63 & 30.44 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabTransformerConfig_tab_epochs & 1.024 & 0.592 & 0.621 & 0.872 & 0.777 ± 0.179 & 102.58 & 29.93 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 0.926 & 0.764 & 0.612 & 0.875 & 0.794 ± 0.121 & nan & 12.56 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & 1.000 & 0.852 & 0.623 & 0.787 & 0.816 ± 0.135 & nan & 12.95 \\\\\n",
      "NoImputer & NoImputer & TabTransformerConfig_tab_epochs & 1.082 & 0.674 & 0.666 & 0.871 & 0.823 ± 0.171 & nan & 17.10 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & 1.098 & 0.672 & 0.617 & 0.960 & 0.837 ± 0.199 & nan & 0.84 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & 1.100 & 0.677 & 0.617 & 0.963 & 0.839 ± 0.199 & nan & 0.85 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & 1.081 & 0.788 & 0.569 & 0.946 & 0.846 ± 0.191 & nan & 0.05 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & 1.112 & 0.677 & 0.620 & 0.978 & 0.847 ± 0.205 & nan & 0.05 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskElasticNet & 1.138 & 0.919 & 0.501 & 1.003 & 0.890 ± 0.238 & 111.67 & 0.02 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & 1.180 & 0.950 & 0.507 & 1.029 & 0.917 ± 0.250 & nan & 0.02 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & DANetConfig_tab & 1.193 & 1.042 & 0.465 & 0.990 & 0.922 ± 0.274 & 110.09 & 1.77 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & DANetConfig_tab_epochs & 1.193 & 1.042 & 0.465 & 0.990 & 0.922 ± 0.274 & 104.00 & 1.79 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet & 1.209 & 0.945 & 0.502 & 1.047 & 0.926 ± 0.262 & 2.71 & 0.02 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & DANetConfig_tab & 1.202 & 1.033 & 0.464 & 1.005 & 0.926 ± 0.277 & 2.56 & 1.95 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & DANetConfig_tab_epochs & 1.202 & 1.033 & 0.464 & 1.005 & 0.926 ± 0.277 & 2.66 & 2.01 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & 1.394 & 1.041 & 0.489 & 1.240 & 1.041 ± 0.342 & nan & 0.01 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso & 1.394 & 1.041 & 0.489 & 1.240 & 1.041 ± 0.342 & 2.63 & 0.01 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskLasso & 1.394 & 1.041 & 0.489 & 1.240 & 1.041 ± 0.342 & 109.98 & 0.01 \\\\\n",
      "NoImputer & NoImputer & TabNetModelConfig_tab_epochs & 1.408 & 1.045 & 0.539 & 1.327 & 1.080 ± 0.340 & nan & 2.18 \\\\\n",
      "NoImputer & NoImputer & DANetConfig_tab_epochs & 1.609 & 0.758 & 0.807 & 1.434 & 1.152 ± 0.375 & nan & 6.86 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetModelConfig_tab & 1.468 & 1.179 & 0.657 & 1.355 & 1.165 ± 0.311 & 2.69 & 1.70 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetModelConfig_tab_epochs & 1.468 & 1.179 & 0.657 & 1.355 & 1.165 ± 0.311 & 2.69 & 1.69 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetModelConfig_tab_epochs & 1.631 & 1.465 & 0.856 & 1.494 & 1.361 ± 0.298 & 99.94 & 2.11 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetModelConfig_tab & 1.631 & 1.465 & 0.856 & 1.494 & 1.361 ± 0.298 & 104.12 & 2.00 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabTransformerConfig_tab & 2.042 & 1.476 & 1.381 & 0.757 & 1.414 ± 0.456 & 2.71 & 1.44 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabTransformerConfig_tab & 2.253 & 1.523 & 1.462 & 0.767 & 1.501 ± 0.526 & 106.87 & 1.54 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mse = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='mse_score',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_mse_adjusted_sorted.csv\",\n",
    "    sort_order=\"ascending\"\n",
    ")\n",
    "print(latex_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{MAE SCORE across targets with timing info}\n",
      "\\label{tab:mae_score}\n",
      "\\begin{tabular}{lllrrrrlll}\n",
      "\\toprule\n",
      "Ordinal Imputer & Continuous Imputer & Model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & Mean ± SD & Imputation Time & Fitting Time \\\\\n",
      "\\midrule\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_custom & 0.608 & 0.518 & 0.410 & 0.668 & 0.551 ± 0.097 & 2.60 & 11.81 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor_tuned & 0.599 & 0.588 & 0.655 & 0.562 & 0.601 ± 0.034 & 2.57 & 4.84 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & GatedAdditiveTreeEnsembleConfig_tab_epochs & 0.706 & 0.522 & 0.539 & 0.700 & 0.617 ± 0.087 & 2.61 & 128.53 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & GatedAdditiveTreeEnsembleConfig_tab_epochs & 0.777 & 0.601 & 0.552 & 0.586 & 0.629 ± 0.087 & 105.27 & 150.23 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor & 0.675 & 0.589 & 0.627 & 0.628 & 0.630 ± 0.031 & 2.66 & 1.17 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetRegressor_default & 0.655 & 0.720 & 0.590 & 0.564 & 0.632 ± 0.061 & 124.55 & 13.82 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & GatedAdditiveTreeEnsembleConfig_tab & 0.600 & 0.655 & 0.639 & 0.640 & 0.633 ± 0.020 & 158.45 & 19.35 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetRegressor_custom & 0.682 & 0.652 & 0.479 & 0.752 & 0.641 ± 0.100 & 101.45 & 12.80 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & RandomForestRegressor & 0.687 & 0.650 & 0.616 & 0.612 & 0.641 ± 0.030 & 98.64 & 39.77 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & 0.801 & 0.516 & 0.658 & 0.626 & 0.650 ± 0.102 & nan & 4.03 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & RandomForestRegressor & 0.691 & 0.672 & 0.623 & 0.618 & 0.651 ± 0.031 & 2.56 & 41.14 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & GatedAdditiveTreeEnsembleConfig_tab & 0.623 & 0.679 & 0.641 & 0.663 & 0.652 ± 0.021 & 2.54 & 16.46 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & XGBoostRegressor & 0.711 & 0.650 & 0.595 & 0.662 & 0.655 ± 0.041 & 102.82 & 1.11 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & LinearRegression & 0.705 & 0.554 & 0.626 & 0.748 & 0.658 ± 0.074 & 114.18 & 0.10 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & LinearRegression & 0.699 & 0.541 & 0.631 & 0.765 & 0.659 ± 0.083 & 2.61 & 0.05 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskLasso_tuned & 0.701 & 0.577 & 0.644 & 0.729 & 0.663 ± 0.058 & 115.13 & 1.09 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso_tuned & 0.701 & 0.554 & 0.634 & 0.766 & 0.664 ± 0.078 & 2.60 & 1.10 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 0.742 & 0.658 & 0.648 & 0.615 & 0.666 ± 0.047 & nan & 33.01 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskElasticNet_tuned & 0.634 & 0.686 & 0.694 & 0.655 & 0.667 ± 0.024 & 112.16 & 1.26 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & 0.754 & 0.635 & 0.643 & 0.644 & 0.669 ± 0.049 & nan & 0.88 \\\\\n",
      "NoImputer & NoImputer & GatedAdditiveTreeEnsembleConfig_tab_epochs & 0.595 & 0.807 & 0.628 & 0.695 & 0.681 ± 0.081 & nan & 316.09 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & XGBoostRegressor_tuned & 0.755 & 0.652 & 0.686 & 0.651 & 0.686 ± 0.042 & 100.32 & 4.61 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet_tuned & 0.709 & 0.662 & 0.687 & 0.738 & 0.699 ± 0.028 & 2.65 & 1.20 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabTransformerConfig_tab_epochs & 0.752 & 0.608 & 0.693 & 0.759 & 0.703 ± 0.061 & 2.63 & 30.44 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & 0.724 & 0.705 & 0.713 & 0.706 & 0.712 ± 0.008 & nan & 0.85 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & 0.727 & 0.703 & 0.714 & 0.708 & 0.713 ± 0.009 & nan & 0.84 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & 0.728 & 0.702 & 0.710 & 0.712 & 0.713 ± 0.010 & nan & 0.05 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 0.713 & 0.758 & 0.671 & 0.724 & 0.717 ± 0.031 & nan & 12.56 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabTransformerConfig_tab_epochs & 0.752 & 0.650 & 0.724 & 0.751 & 0.719 ± 0.042 & 102.58 & 29.93 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & PLSRegression_4_components & 0.749 & 0.739 & 0.692 & 0.707 & 0.722 ± 0.023 & 139.04 & 0.14 \\\\\n",
      "NoImputer & NoImputer & TabTransformerConfig_tab_epochs & 0.747 & 0.724 & 0.725 & 0.712 & 0.727 ± 0.012 & nan & 17.10 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & 0.781 & 0.801 & 0.680 & 0.672 & 0.733 ± 0.058 & nan & 12.95 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_default & 0.745 & 0.801 & 0.654 & 0.737 & 0.734 ± 0.052 & 2.50 & 12.06 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & PLSRegression_4_components & 0.808 & 0.725 & 0.682 & 0.768 & 0.746 ± 0.047 & 2.57 & 0.08 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & 0.792 & 0.791 & 0.722 & 0.735 & 0.760 ± 0.032 & nan & 0.05 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskElasticNet & 0.871 & 0.772 & 0.650 & 0.817 & 0.777 ± 0.081 & 111.67 & 0.02 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & DANetConfig_tab_epochs & 0.909 & 0.790 & 0.602 & 0.830 & 0.783 ± 0.113 & 104.00 & 1.79 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & DANetConfig_tab & 0.909 & 0.790 & 0.602 & 0.830 & 0.783 ± 0.113 & 110.09 & 1.77 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & DANetConfig_tab & 0.910 & 0.787 & 0.602 & 0.836 & 0.784 ± 0.114 & 2.56 & 1.95 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & DANetConfig_tab_epochs & 0.910 & 0.787 & 0.602 & 0.836 & 0.784 ± 0.114 & 2.66 & 2.01 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & 0.884 & 0.787 & 0.654 & 0.827 & 0.788 ± 0.085 & nan & 0.02 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet & 0.900 & 0.781 & 0.651 & 0.841 & 0.793 ± 0.092 & 2.71 & 0.02 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & 0.991 & 0.785 & 0.621 & 0.934 & 0.833 ± 0.144 & nan & 0.01 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso & 0.991 & 0.785 & 0.621 & 0.934 & 0.833 ± 0.144 & 2.63 & 0.01 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & MultiTaskLasso & 0.991 & 0.785 & 0.621 & 0.934 & 0.833 ± 0.144 & 109.98 & 0.01 \\\\\n",
      "NoImputer & NoImputer & TabNetModelConfig_tab_epochs & 0.997 & 0.842 & 0.656 & 1.012 & 0.877 ± 0.144 & nan & 2.18 \\\\\n",
      "NoImputer & NoImputer & DANetConfig_tab_epochs & 1.052 & 0.762 & 0.772 & 0.988 & 0.893 ± 0.128 & nan & 6.86 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetModelConfig_tab & 1.113 & 0.921 & 0.747 & 0.984 & 0.941 ± 0.132 & 2.69 & 1.70 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetModelConfig_tab_epochs & 1.113 & 0.921 & 0.747 & 0.984 & 0.941 ± 0.132 & 2.69 & 1.69 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabTransformerConfig_tab & 1.190 & 1.050 & 0.997 & 0.768 & 1.001 ± 0.152 & 2.71 & 1.44 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetModelConfig_tab_epochs & 1.154 & 1.035 & 0.770 & 1.065 & 1.006 ± 0.143 & 99.94 & 2.11 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabNetModelConfig_tab & 1.154 & 1.035 & 0.770 & 1.065 & 1.006 ± 0.143 & 104.12 & 2.00 \\\\\n",
      "KNNImputer1 & IterativeImputer_Niter=1 & TabTransformerConfig_tab & 1.224 & 1.073 & 1.017 & 0.772 & 1.021 ± 0.163 & 106.87 & 1.54 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='mae_score',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_mae_adjusted_sorted.csv\",\n",
    "    sort_order=\"ascending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
