{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from itertools import product\n",
    "import warnings\n",
    "\n",
    "# System path modification\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning imports\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, Lasso, LassoCV, MultiTaskLasso, MultiTaskLassoCV,\n",
    "    ElasticNet, ElasticNetCV, MultiTaskElasticNet, MultiTaskElasticNetCV\n",
    ")\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Custom modules\n",
    "from src.train import *\n",
    "from src.functions import *\n",
    "from src.plots import *\n",
    "from src.dataset import *\n",
    "from src.multixgboost import *\n",
    "from src.wrapper import *\n",
    "from src.debug import *\n",
    "\n",
    "# Visualizatiokn \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning and machine learning specific \n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "from pytorch_tabular.config import DataConfig, TrainerConfig, OptimizerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "\n",
    "from pytorch_tabular.models import (\n",
    "    GatedAdditiveTreeEnsembleConfig,\n",
    "    DANetConfig,\n",
    "    TabTransformerConfig,\n",
    "    FTTransformerConfig,\n",
    "    TabNetModelConfig,\n",
    ")\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Print CUDA availability for PyTorch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_pickle_data_palettes()\n",
    "\n",
    "results_pickle_folder = \"../pickle/\"\n",
    "\n",
    "# Unpack data\n",
    "df_X, df_y, df_all, df_FinalCombination = data[\"df_X\"], data[\"df_y\"], data[\"df_all\"], data[\"df_FinalCombination\"]\n",
    "dict_select = data[\"dict_select\"]\n",
    "\n",
    "# Unpack colormaps\n",
    "full_palette, gender_palette, dx_palette = data[\"colormaps\"].values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = list(df_X.isna().any(axis=1))\n",
    "idx_test = list(~df_X.isna().any(axis=1))\n",
    "\n",
    "set_intersect_rid = set(df_all[idx_train].RID).intersection(set(df_all[idx_test].RID))\n",
    "intersect_rid_idx = df_all.RID.isin(set_intersect_rid)\n",
    "\n",
    "for i, bool_test in enumerate(idx_test): \n",
    "    if intersect_rid_idx.iloc[i] & bool_test:\n",
    "        idx_test[i] = False\n",
    "        idx_train[i] = True\n",
    "        \n",
    "df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]] = df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]].astype(\"category\")\n",
    "\n",
    "df_X_train = df_X.loc[idx_train]\n",
    "df_X_test = df_X.loc[idx_test]\n",
    "\n",
    "df_y_train = df_y.loc[idx_train]\n",
    "df_y_test = df_y.loc[idx_test]\n",
    "\n",
    "c_train = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_train]\n",
    "c_test = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3609    128_S_2002\n",
       "5631    116_S_4167\n",
       "5662    033_S_4176\n",
       "5780    098_S_4215\n",
       "5950    018_S_4349\n",
       "6069    941_S_4292\n",
       "6077    116_S_4453\n",
       "6085    135_S_4489\n",
       "6224    033_S_4505\n",
       "6400    014_S_4576\n",
       "6429    073_S_4300\n",
       "7021    003_S_2374\n",
       "7192    033_S_4179\n",
       "Name: SubjectID, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.SubjectID.iloc[idx_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define all the models and combinations to try out with their hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42\n",
    "\n",
    "# Continuous Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "continuous_imputer_list = [\n",
    "    (\"KNNImputer\", KNNImputer(n_neighbors=1)),\n",
    "]\n",
    "\n",
    "# Ordinal Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "ordinal_imputer_list = [\n",
    "    (\"SimpleImputer_most_frequent\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "]\n",
    "\n",
    "# Predictive Models List (list of tuples with unique strings and corresponding instances)\n",
    "predictive_models_list = [\n",
    "    (\"LinearRegression\", LinearRegression()),\n",
    "    (\"MultiTaskElasticNet\", MultiTaskElasticNet()),\n",
    "    (\"MultiTaskElasticNet_tuned\", MultiTaskElasticNet(**{'alpha': 0.01, 'l1_ratio': 0.01})),\n",
    "    (\"MultiTaskLasso\", MultiTaskLasso()),\n",
    "    (\"MultiTaskLasso_tuned\", MultiTaskLasso(**{'alpha': 0.001})),\n",
    "    (\"RandomForestRegressor\", RandomForestRegressor()),\n",
    "    (\"XGBoostRegressor\", XGBoostRegressor()),\n",
    "    (\"XGBoostRegressor_tuned\", XGBoostRegressor(**{'colsample_bytree': 0.5079831261101071, 'learning_rate': 0.0769592094304232, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.8049983288913105})),\n",
    "    (\"TabNetRegressor_default\", TabNetModelWrapper(n_a=8, n_d=8)),\n",
    "    (\"TabNetRegressor_custom\", TabNetModelWrapper(n_a=32, n_d=32)),\n",
    "    (\"PLSRegression_4_components\", PLSRegression(n_components=4))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['APOE_epsilon2', 'APOE_epsilon3', 'APOE_epsilon4']\n",
    "continuous_features = [col for col in df_X_train.columns if col not in ordinal_features]\n",
    "\n",
    "# Prepare Tabular configurations (shared for all PyTorch models)\n",
    "data_config = DataConfig(\n",
    "    target=df_y_train.columns.tolist(),\n",
    "    continuous_cols=continuous_features,\n",
    "    categorical_cols=ordinal_features\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024, max_epochs=1, auto_lr_find=False,\n",
    "    early_stopping=\"valid_loss\", early_stopping_mode=\"min\", early_stopping_patience=5,\n",
    "    checkpoints=\"valid_loss\", load_best=True, progress_bar=\"nones\",\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "head_config = LinearHeadConfig(dropout=0.1).__dict__\n",
    "\n",
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabNetModelConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: LinearRegression\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: MultiTaskElasticNet\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: MultiTaskElasticNet_tuned\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: MultiTaskLasso\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: MultiTaskLasso_tuned\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: RandomForestRegressor\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: XGBoostRegressor\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: XGBoostRegressor_tuned\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: TabNetRegressor_default\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: TabNetRegressor_custom\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: PLSRegression_4_components\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: GatedAdditiveTreeEnsembleConfig_tab\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: DANetConfig_tab\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: TabTransformerConfig_tab\n",
      "Continuous Imputer: KNNImputer, Ordinal Imputer: SimpleImputer_most_frequent, Model: TabNetModelConfig_tab\n",
      "Combinations of preprocessing and models to test : 15\n"
     ]
    }
   ],
   "source": [
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "# Display all combinations\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    print(f\"Continuous Imputer: {continuous_imputer[0]}, Ordinal Imputer: {ordinal_imputer[0]}, Model: {model[0]}\")\n",
    "\n",
    "print(f\"Combinations of preprocessing and models to test : {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HDF5 file\n",
    "results_file = '../pickle/training_2_dict_results.pickle'\n",
    "\n",
    "if os.path.exists(results_file): \n",
    "\n",
    "    with open(results_file, \"rb\") as input_file:\n",
    "        all_dict_results = pickle.load(input_file)\n",
    "\n",
    "else : \n",
    "    all_dict_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'LinearRegression',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.744856119155884,\n",
       "  'fitting_time': 0.10365915298461914,\n",
       "  'results_adj': {'mse_score': array([0.82472937, 0.40934318, 0.49734881, 0.66807641]),\n",
       "   'mae_score': array([0.68760248, 0.52230642, 0.60995161, 0.64498316]),\n",
       "   'r2': array([ 0.16646421,  0.53550172, -0.0384381 ,  0.18733798]),\n",
       "   'explained_variance': array([ 0.25451649,  0.5631066 , -0.02406892,  0.44316425]),\n",
       "   'corr': array([0.51351669, 0.76426752, 0.27239804, 0.67696079])},\n",
       "  'results_org': {'mse_score': array([0.82472936, 0.40934317, 0.49734882, 0.66807639]),\n",
       "   'mae_score': array([0.68760248, 0.52230642, 0.60995162, 0.64498315]),\n",
       "   'r2': array([0.12270048, 0.54142269, 0.03132258, 0.21889061]),\n",
       "   'explained_variance': array([0.21537583, 0.56867569, 0.04472644, 0.4647841 ]),\n",
       "   'corr': array([0.48070093, 0.766383  , 0.32875308, 0.69790843])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskElasticNet',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.7833592891693115,\n",
       "  'fitting_time': 0.10404586791992188,\n",
       "  'results_adj': {'mse_score': array([1.18012248, 0.95041535, 0.50741149, 1.02939714]),\n",
       "   'mae_score': array([0.88414168, 0.78683573, 0.65378091, 0.82689555]),\n",
       "   'r2': array([-0.19272377, -0.07847478, -0.05944846, -0.25218006]),\n",
       "   'explained_variance': array([ 0.11229868,  0.03189858, -0.05332468,  0.12857136]),\n",
       "   'corr': array([ 0.42176385,  0.17864276, -0.16306812,  0.44631446])},\n",
       "  'results_org': {'mse_score': array([1.18012249, 0.95041535, 0.50741151, 1.02939712]),\n",
       "   'mae_score': array([0.88414168, 0.78683573, 0.65378092, 0.82689554]),\n",
       "   'r2': array([-0.25534622, -0.06472746,  0.01172365, -0.20356259]),\n",
       "   'explained_variance': array([0.06569104, 0.04423898, 0.01743605, 0.16240568]),\n",
       "   'corr': array([0.25863754, 0.21083052, 0.14561963, 0.49623359])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskLasso',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.7112746238708496,\n",
       "  'fitting_time': 0.08121681213378906,\n",
       "  'results_adj': {'mse_score': array([1.39363767, 1.04056339, 0.48866937, 1.24000841]),\n",
       "   'mae_score': array([0.99127575, 0.78457157, 0.62110666, 0.93446712]),\n",
       "   'r2': array([-0.40851885, -0.18076941, -0.0203159 , -0.50837198]),\n",
       "   'explained_variance': array([-2.22044605e-16, -2.22044605e-16,  0.00000000e+00,  1.11022302e-16]),\n",
       "   'corr': array([nan, nan, nan, nan])},\n",
       "  'results_org': {'mse_score': array([1.39363768, 1.04056339, 0.48866939, 1.24000838]),\n",
       "   'mae_score': array([0.99127576, 0.78457157, 0.62110667, 0.93446711]),\n",
       "   'r2': array([-0.48247136, -0.16571814,  0.04822734, -0.44980754]),\n",
       "   'explained_variance': array([-0.05250375,  0.01274701,  0.06717846,  0.03882626]),\n",
       "   'corr': array([-0.0848666 ,  0.11455326,  0.2721653 ,  0.20679355])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'RandomForestRegressor',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.7485666275024414,\n",
       "  'fitting_time': 67.38400149345398,\n",
       "  'results_adj': {'mse_score': array([0.93516431, 0.60987938, 0.48373246, 0.73967155]),\n",
       "   'mae_score': array([0.72023031, 0.69289891, 0.64639813, 0.64977933]),\n",
       "   'r2': array([ 0.05485005,  0.30794518, -0.01000789,  0.10024816]),\n",
       "   'explained_variance': array([0.28799052, 0.41918165, 0.01167835, 0.42601789]),\n",
       "   'corr': array([0.53665908, 0.65072073, 0.23452541, 0.66706269])},\n",
       "  'results_org': {'mse_score': array([0.93516431, 0.60987938, 0.48373248, 0.73967153]),\n",
       "   'mae_score': array([0.72023032, 0.69289891, 0.64639814, 0.64977933]),\n",
       "   'r2': array([0.00522616, 0.3167668 , 0.05784287, 0.13518216]),\n",
       "   'explained_variance': array([0.25060737, 0.42658535, 0.07807226, 0.44830347]),\n",
       "   'corr': array([0.50099892, 0.65724581, 0.30160564, 0.69747695])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'XGBoostRegressor',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.745192766189575,\n",
       "  'fitting_time': 1.0849308967590332,\n",
       "  'results_adj': {'mse_score': array([1.08198741, 0.6258951 , 0.45479146, 0.72340423]),\n",
       "   'mae_score': array([0.79331063, 0.70007167, 0.61286059, 0.64196585]),\n",
       "   'r2': array([-0.09354081,  0.28977149,  0.0504194 ,  0.12003607]),\n",
       "   'explained_variance': array([0.19887639, 0.36176601, 0.05873422, 0.34309181]),\n",
       "   'corr': array([0.46652906, 0.62159198, 0.302092  , 0.58940565])},\n",
       "  'results_org': {'mse_score': array([1.08198741, 0.6258951 , 0.45479148, 0.72340422]),\n",
       "   'mae_score': array([0.79331064, 0.70007167, 0.61286061, 0.64196585]),\n",
       "   'r2': array([-0.15095578,  0.29882477,  0.11421074,  0.15420177]),\n",
       "   'explained_variance': array([0.15681441, 0.36990158, 0.12196699, 0.3685971 ]),\n",
       "   'corr': array([0.4402507 , 0.63642601, 0.37694423, 0.6168053 ])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'TabNetRegressor_default',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.7878646850585938,\n",
       "  'fitting_time': 44.291431188583374,\n",
       "  'results_adj': {'mse_score': array([0.62673865, 0.71159396, 0.50173545, 0.43361105]),\n",
       "   'mae_score': array([0.62344847, 0.67573399, 0.6440961 , 0.54813842]),\n",
       "   'r2': array([ 0.36656906,  0.19252552, -0.04759718,  0.47254652]),\n",
       "   'explained_variance': array([ 0.52729521,  0.21139474, -0.04282409,  0.64696861]),\n",
       "   'corr': array([0.73623638, 0.4955735 , 0.24623757, 0.8318294 ])},\n",
       "  'results_org': {'mse_score': array([0.62673866, 0.71159396, 0.50173547, 0.43361103]),\n",
       "   'mae_score': array([0.62344848, 0.67573399, 0.64409611, 0.54813841]),\n",
       "   'r2': array([0.33331157, 0.20281839, 0.02277877, 0.49302557]),\n",
       "   'explained_variance': array([0.50247645, 0.2214471 , 0.02723122, 0.66067551]),\n",
       "   'corr': array([0.72175009, 0.5069382 , 0.30287545, 0.85086829])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'TabNetRegressor_custom',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.7673544883728027,\n",
       "  'fitting_time': 55.80815625190735,\n",
       "  'results_adj': {'mse_score': array([0.99634811, 0.73215349, 0.72365533, 0.87102995]),\n",
       "   'mae_score': array([0.81995591, 0.72930294, 0.62457022, 0.78716116]),\n",
       "   'r2': array([-0.00698706,  0.16919579, -0.51095419, -0.05953891]),\n",
       "   'explained_variance': array([ 0.35887226,  0.27807197, -0.46299565,  0.27315957]),\n",
       "   'corr': array([0.61110808, 0.66843114, 0.28964944, 0.59783536])},\n",
       "  'results_org': {'mse_score': array([0.9963481 , 0.7321535 , 0.72365535, 0.87102992]),\n",
       "   'mae_score': array([0.81995591, 0.72930294, 0.62457023, 0.78716116]),\n",
       "   'r2': array([-0.05985763,  0.17978604, -0.40945062, -0.01840098]),\n",
       "   'explained_variance': array([ 0.32521066,  0.28727438, -0.36471385,  0.30138007]),\n",
       "   'corr': array([0.59075397, 0.68883704, 0.32658025, 0.61117884])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'PLSRegression_4_components',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.751939296722412,\n",
       "  'fitting_time': 0.13132381439208984,\n",
       "  'results_adj': {'mse_score': array([0.96359206, 0.68072896, 0.52439295, 0.85177318]),\n",
       "   'mae_score': array([0.79102389, 0.74489711, 0.69564783, 0.75222709]),\n",
       "   'r2': array([ 0.02611876,  0.22754929, -0.09490485, -0.03611458]),\n",
       "   'explained_variance': array([ 0.25042147,  0.28673673, -0.0943435 ,  0.26687517]),\n",
       "   'corr': array([0.50112866, 0.53938435, 0.0434805 , 0.51829909])},\n",
       "  'results_org': {'mse_score': array([0.96359206, 0.68072895, 0.52439297, 0.85177315]),\n",
       "   'mae_score': array([0.7910239 , 0.74489711, 0.69564784, 0.75222708]),\n",
       "   'r2': array([-0.02501364,  0.23739572, -0.02135084,  0.00411387]),\n",
       "   'explained_variance': array([ 0.2110658 ,  0.2958287 , -0.0208272 ,  0.29533967]),\n",
       "   'corr': array([0.45945465, 0.55347491, 0.14768074, 0.56007422])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'LinearRegression',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.111734628677368,\n",
       "  'fitting_time': 0.060724496841430664,\n",
       "  'results_adj': {'mse_score': array([0.83152276, 0.40742247, 0.49417873, 0.66840295]),\n",
       "   'mae_score': array([0.6831901 , 0.52110401, 0.60572493, 0.64518569]),\n",
       "   'r2': array([ 0.15959829,  0.53768122, -0.03181915,  0.18694077]),\n",
       "   'explained_variance': array([ 0.2496287 ,  0.56516972, -0.01674853,  0.44286189]),\n",
       "   'corr': array([0.50824349, 0.76582926, 0.28285126, 0.67676748])},\n",
       "  'results_org': {'mse_score': array([0.83152275, 0.40742247, 0.49417874, 0.66840294]),\n",
       "   'mae_score': array([0.6831901 , 0.52110402, 0.60572494, 0.64518568]),\n",
       "   'r2': array([0.11547407, 0.54357441, 0.03749688, 0.21850881]),\n",
       "   'explained_variance': array([0.21023141, 0.57071252, 0.05155506, 0.46449348]),\n",
       "   'corr': array([0.47485832, 0.76786132, 0.33838854, 0.69775213])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskElasticNet',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.075192213058472,\n",
       "  'fitting_time': 0.03054642677307129,\n",
       "  'results_adj': {'mse_score': array([1.18012248, 0.95041535, 0.50741149, 1.02939714]),\n",
       "   'mae_score': array([0.88414168, 0.78683573, 0.65378091, 0.82689555]),\n",
       "   'r2': array([-0.19272377, -0.07847478, -0.05944846, -0.25218006]),\n",
       "   'explained_variance': array([ 0.11229868,  0.03189858, -0.05332468,  0.12857136]),\n",
       "   'corr': array([ 0.42176385,  0.17864276, -0.16306812,  0.44631446])},\n",
       "  'results_org': {'mse_score': array([1.18012249, 0.95041535, 0.50741151, 1.02939712]),\n",
       "   'mae_score': array([0.88414168, 0.78683573, 0.65378092, 0.82689554]),\n",
       "   'r2': array([-0.25534622, -0.06472746,  0.01172365, -0.20356259]),\n",
       "   'explained_variance': array([0.06569104, 0.04423898, 0.01743605, 0.16240568]),\n",
       "   'corr': array([0.25863754, 0.21083052, 0.14561963, 0.49623359])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskLasso',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.120155334472656,\n",
       "  'fitting_time': 0.013368368148803711,\n",
       "  'results_adj': {'mse_score': array([1.39363767, 1.04056339, 0.48866937, 1.24000841]),\n",
       "   'mae_score': array([0.99127575, 0.78457157, 0.62110666, 0.93446712]),\n",
       "   'r2': array([-0.40851885, -0.18076941, -0.0203159 , -0.50837198]),\n",
       "   'explained_variance': array([-2.22044605e-16, -2.22044605e-16,  0.00000000e+00,  1.11022302e-16]),\n",
       "   'corr': array([nan, nan, nan, nan])},\n",
       "  'results_org': {'mse_score': array([1.39363768, 1.04056339, 0.48866939, 1.24000838]),\n",
       "   'mae_score': array([0.99127576, 0.78457157, 0.62110667, 0.93446711]),\n",
       "   'r2': array([-0.48247136, -0.16571814,  0.04822734, -0.44980754]),\n",
       "   'explained_variance': array([-0.05250375,  0.01274701,  0.06717846,  0.03882626]),\n",
       "   'corr': array([-0.0848666 ,  0.11455326,  0.2721653 ,  0.20679355])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'RandomForestRegressor',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.133652925491333,\n",
       "  'fitting_time': 67.60348629951477,\n",
       "  'results_adj': {'mse_score': array([0.90432518, 0.58784823, 0.44198369, 0.74514782]),\n",
       "   'mae_score': array([0.73007467, 0.65858349, 0.61250059, 0.66338718]),\n",
       "   'r2': array([0.08601848, 0.33294481, 0.07716134, 0.09358672]),\n",
       "   'explained_variance': array([0.37003259, 0.45528696, 0.09823408, 0.42472059]),\n",
       "   'corr': array([0.61506801, 0.68512731, 0.32235053, 0.66968034])},\n",
       "  'results_org': {'mse_score': array([0.90432518, 0.58784823, 0.44198371, 0.7451478 ]),\n",
       "   'mae_score': array([0.73007468, 0.6585835 , 0.61250061, 0.66338717]),\n",
       "   'r2': array([0.03803104, 0.34144776, 0.1391562 , 0.12877936]),\n",
       "   'explained_variance': array([0.33695695, 0.46223042, 0.15881332, 0.44705654]),\n",
       "   'corr': array([0.58498819, 0.69137792, 0.39855316, 0.70330331])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'XGBoostRegressor',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.157229900360107,\n",
       "  'fitting_time': 1.046581745147705,\n",
       "  'results_adj': {'mse_score': array([1.08198741, 0.6258951 , 0.45479146, 0.72340423]),\n",
       "   'mae_score': array([0.79331063, 0.70007167, 0.61286059, 0.64196585]),\n",
       "   'r2': array([-0.09354081,  0.28977149,  0.0504194 ,  0.12003607]),\n",
       "   'explained_variance': array([0.19887639, 0.36176601, 0.05873422, 0.34309181]),\n",
       "   'corr': array([0.46652906, 0.62159198, 0.302092  , 0.58940565])},\n",
       "  'results_org': {'mse_score': array([1.08198741, 0.6258951 , 0.45479148, 0.72340422]),\n",
       "   'mae_score': array([0.79331064, 0.70007167, 0.61286061, 0.64196585]),\n",
       "   'r2': array([-0.15095578,  0.29882477,  0.11421074,  0.15420177]),\n",
       "   'explained_variance': array([0.15681441, 0.36990158, 0.12196699, 0.3685971 ]),\n",
       "   'corr': array([0.4402507 , 0.63642601, 0.37694423, 0.6168053 ])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'TabNetRegressor_default',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.0794525146484375,\n",
       "  'fitting_time': 48.432860374450684,\n",
       "  'results_adj': {'mse_score': array([0.88322647, 0.90536713, 0.6128396 , 0.70514789]),\n",
       "   'mae_score': array([0.69284928, 0.7544037 , 0.71075386, 0.6065298 ]),\n",
       "   'r2': array([ 0.10734248, -0.02735674, -0.27957678,  0.14224347]),\n",
       "   'explained_variance': array([ 0.24585955, -0.00184071, -0.27790016,  0.33487172]),\n",
       "   'corr': array([ 0.50973865,  0.30946279, -0.10368377,  0.58013384])},\n",
       "  'results_org': {'mse_score': array([0.88322647, 0.90536713, 0.61283961, 0.70514787]),\n",
       "   'mae_score': array([0.69284929, 0.7544037 , 0.71075387, 0.60652979]),\n",
       "   'r2': array([ 0.06047464, -0.01426103, -0.19361679,  0.17554694]),\n",
       "   'explained_variance': array([ 0.20626437,  0.01092975, -0.1920528 ,  0.36069616]),\n",
       "   'corr': array([ 0.47833919,  0.31626439, -0.00215573,  0.60063822])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'TabNetRegressor_custom',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.124400615692139,\n",
       "  'fitting_time': 61.361088037490845,\n",
       "  'results_adj': {'mse_score': array([0.74534355, 0.50953234, 0.56392793, 0.51790228]),\n",
       "   'mae_score': array([0.72766492, 0.57930005, 0.69067853, 0.55274338]),\n",
       "   'r2': array([ 0.24669771,  0.42181302, -0.1774518 ,  0.37001291]),\n",
       "   'explained_variance': array([ 0.35079887,  0.44932562, -0.17329128,  0.46231783]),\n",
       "   'corr': array([0.59259251, 0.71246864, 0.03159857, 0.68009604])},\n",
       "  'results_org': {'mse_score': array([0.74534356, 0.50953235, 0.56392795, 0.51790227]),\n",
       "   'mae_score': array([0.72766492, 0.57930005, 0.69067855, 0.55274337]),\n",
       "   'r2': array([ 0.20714653,  0.42918316, -0.09835241,  0.39447295]),\n",
       "   'explained_variance': array([ 0.31671339,  0.45634507, -0.09447138,  0.48319402]),\n",
       "   'corr': array([0.56412998, 0.7155368 , 0.1458956 , 0.69658267])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'PLSRegression_4_components',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.099794149398804,\n",
       "  'fitting_time': 0.0523989200592041,\n",
       "  'results_adj': {'mse_score': array([0.95167369, 0.67404247, 0.52180648, 0.84272932]),\n",
       "   'mae_score': array([0.78564547, 0.74050827, 0.69406437, 0.7473522 ]),\n",
       "   'r2': array([ 0.03816439,  0.23513672, -0.08950443, -0.02511344]),\n",
       "   'explained_variance': array([ 0.25207463,  0.28978638, -0.0886349 ,  0.26627048]),\n",
       "   'corr': array([0.50274165, 0.54241405, 0.05183709, 0.51755784])},\n",
       "  'results_org': {'mse_score': array([0.95167369, 0.67404247, 0.5218065 , 0.84272929]),\n",
       "   'mae_score': array([0.78564547, 0.74050827, 0.69406438, 0.7473522 ]),\n",
       "   'r2': array([-0.01233557,  0.24488643, -0.01631321,  0.01468788]),\n",
       "   'explained_variance': array([ 0.21280575,  0.29883948, -0.01550209,  0.29475846]),\n",
       "   'corr': array([0.46132625, 0.55644962, 0.15478153, 0.55884153])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'LinearRegression',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.9046692848205566,\n",
       "  'fitting_time': 0.11030983924865723,\n",
       "  'results_adj': {'mse_score': array([0.82662897, 0.41040109, 0.49417054, 0.65062459]),\n",
       "   'mae_score': array([0.68468492, 0.52270277, 0.6071832 , 0.64062299]),\n",
       "   'r2': array([ 0.16454433,  0.53430126, -0.03180204,  0.20856674]),\n",
       "   'explained_variance': array([ 0.24814673,  0.56097665, -0.01848011,  0.44191497]),\n",
       "   'corr': array([0.50745239, 0.7624086 , 0.27912167, 0.67662725])},\n",
       "  'results_org': {'mse_score': array([0.82662896, 0.41040108, 0.49417055, 0.65062457]),\n",
       "   'mae_score': array([0.68468492, 0.52270277, 0.60718321, 0.64062298]),\n",
       "   'r2': array([0.1206798 , 0.54023753, 0.03751283, 0.23929513]),\n",
       "   'explained_variance': array([0.20867163, 0.5665729 , 0.04993981, 0.46358333]),\n",
       "   'corr': array([0.47427754, 0.76459556, 0.33515766, 0.69781724])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskElasticNet',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.756998300552368,\n",
       "  'fitting_time': 0.0963444709777832,\n",
       "  'results_adj': {'mse_score': array([1.18012248, 0.95041535, 0.50741149, 1.02939714]),\n",
       "   'mae_score': array([0.88414168, 0.78683573, 0.65378091, 0.82689555]),\n",
       "   'r2': array([-0.19272377, -0.07847478, -0.05944846, -0.25218006]),\n",
       "   'explained_variance': array([ 0.11229868,  0.03189858, -0.05332468,  0.12857136]),\n",
       "   'corr': array([ 0.42176385,  0.17864276, -0.16306812,  0.44631446])},\n",
       "  'results_org': {'mse_score': array([1.18012249, 0.95041535, 0.50741151, 1.02939712]),\n",
       "   'mae_score': array([0.88414168, 0.78683573, 0.65378092, 0.82689554]),\n",
       "   'r2': array([-0.25534622, -0.06472746,  0.01172365, -0.20356259]),\n",
       "   'explained_variance': array([0.06569104, 0.04423898, 0.01743605, 0.16240568]),\n",
       "   'corr': array([0.25863754, 0.21083052, 0.14561963, 0.49623359])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskLasso',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.8953819274902344,\n",
       "  'fitting_time': 0.0822443962097168,\n",
       "  'results_adj': {'mse_score': array([1.39363767, 1.04056339, 0.48866937, 1.24000841]),\n",
       "   'mae_score': array([0.99127575, 0.78457157, 0.62110666, 0.93446712]),\n",
       "   'r2': array([-0.40851885, -0.18076941, -0.0203159 , -0.50837198]),\n",
       "   'explained_variance': array([-2.22044605e-16, -2.22044605e-16,  0.00000000e+00,  1.11022302e-16]),\n",
       "   'corr': array([nan, nan, nan, nan])},\n",
       "  'results_org': {'mse_score': array([1.39363768, 1.04056339, 0.48866939, 1.24000838]),\n",
       "   'mae_score': array([0.99127576, 0.78457157, 0.62110667, 0.93446711]),\n",
       "   'r2': array([-0.48247136, -0.16571814,  0.04822734, -0.44980754]),\n",
       "   'explained_variance': array([-0.05250375,  0.01274701,  0.06717846,  0.03882626]),\n",
       "   'corr': array([-0.0848666 ,  0.11455326,  0.2721653 ,  0.20679355])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'RandomForestRegressor',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.9819116592407227,\n",
       "  'fitting_time': 67.81606650352478,\n",
       "  'results_adj': {'mse_score': array([0.7648862 , 0.5716211 , 0.44900701, 0.67655055]),\n",
       "   'mae_score': array([0.65641173, 0.63251287, 0.62086552, 0.62960106]),\n",
       "   'r2': array([0.22694639, 0.3513584 , 0.06249703, 0.17702987]),\n",
       "   'explained_variance': array([0.46878946, 0.49442208, 0.08056601, 0.47256951]),\n",
       "   'corr': array([0.69862011, 0.71432319, 0.30246693, 0.70591375])},\n",
       "  'results_org': {'mse_score': array([0.7648862 , 0.5716211 , 0.44900703, 0.67655053]),\n",
       "   'mae_score': array([0.65641173, 0.63251288, 0.62086554, 0.62960106]),\n",
       "   'r2': array([0.18635819, 0.35962663, 0.12547702, 0.20898272]),\n",
       "   'explained_variance': array([0.44089893, 0.50086669, 0.14233216, 0.49304767]),\n",
       "   'corr': array([0.67833377, 0.72040926, 0.37810084, 0.73546464])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'XGBoostRegressor',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.8475077152252197,\n",
       "  'fitting_time': 1.0305569171905518,\n",
       "  'results_adj': {'mse_score': array([0.93282595, 0.6258951 , 0.45479146, 0.90023607]),\n",
       "   'mae_score': array([0.70895317, 0.70007167, 0.61286059, 0.70546871]),\n",
       "   'r2': array([ 0.05721338,  0.28977149,  0.0504194 , -0.09506585]),\n",
       "   'explained_variance': array([0.31919675, 0.36176601, 0.05873422, 0.17723241]),\n",
       "   'corr': array([0.56888492, 0.62159198, 0.302092  , 0.44245158])},\n",
       "  'results_org': {'mse_score': array([0.93282594, 0.6258951 , 0.45479148, 0.90023605]),\n",
       "   'mae_score': array([0.70895318, 0.70007167, 0.61286061, 0.70546871]),\n",
       "   'r2': array([ 0.00771358,  0.29882477,  0.11421074, -0.05254855]),\n",
       "   'explained_variance': array([0.28345204, 0.36990158, 0.12196699, 0.2091774 ]),\n",
       "   'corr': array([0.54326357, 0.63642601, 0.37694423, 0.46477601])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'TabNetRegressor_default',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.839387893676758,\n",
       "  'fitting_time': 48.1419403553009,\n",
       "  'results_adj': {'mse_score': array([0.55846976, 0.56469357, 0.38481532, 0.41510672]),\n",
       "   'mae_score': array([0.61983694, 0.59271985, 0.54868694, 0.47612314]),\n",
       "   'r2': array([0.43556693, 0.35921935, 0.19652589, 0.49505557]),\n",
       "   'explained_variance': array([0.5342236 , 0.37768977, 0.19703449, 0.58173494]),\n",
       "   'corr': array([0.75431159, 0.61914812, 0.44566313, 0.7799989 ])},\n",
       "  'results_org': {'mse_score': array([0.55846976, 0.56469356, 0.38481533, 0.4151067 ]),\n",
       "   'mae_score': array([0.61983695, 0.59271985, 0.54868695, 0.47612314]),\n",
       "   'r2': array([0.40593208, 0.36738738, 0.25050204, 0.51466068]),\n",
       "   'explained_variance': array([0.5097686 , 0.38562237, 0.25097648, 0.59797462]),\n",
       "   'corr': array([0.7384432 , 0.62183988, 0.50329104, 0.78761319])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'TabNetRegressor_custom',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.848728895187378,\n",
       "  'fitting_time': 60.64380240440369,\n",
       "  'results_adj': {'mse_score': array([0.9872231 , 0.52271067, 0.64640227, 0.69711304]),\n",
       "   'mae_score': array([0.78545749, 0.61728937, 0.61841674, 0.67290543]),\n",
       "   'r2': array([ 0.00223538,  0.40685904, -0.34965387,  0.15201722]),\n",
       "   'explained_variance': array([ 0.25434189,  0.41733798, -0.31649448,  0.35500798]),\n",
       "   'corr': array([0.56038552, 0.66011165, 0.21820755, 0.61243913])},\n",
       "  'results_org': {'mse_score': array([0.98722309, 0.52271068, 0.64640229, 0.69711302]),\n",
       "   'mae_score': array([0.78545749, 0.61728937, 0.61841676, 0.67290542]),\n",
       "   'r2': array([-0.05015097,  0.41441979, -0.25898621,  0.18494123]),\n",
       "   'explained_variance': array([ 0.21519206,  0.42476516, -0.22805442,  0.38005061]),\n",
       "   'corr': array([0.54607882, 0.66492001, 0.29270205, 0.63124031])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'PLSRegression_4_components',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 3.8977012634277344,\n",
       "  'fitting_time': 0.10444402694702148,\n",
       "  'results_adj': {'mse_score': array([0.91995234, 0.67388733, 0.52706955, 0.81300549]),\n",
       "   'mae_score': array([0.76334583, 0.74008762, 0.69512295, 0.72870007]),\n",
       "   'r2': array([ 0.07022446,  0.23531276, -0.10049344,  0.01104324]),\n",
       "   'explained_variance': array([ 0.2529569 ,  0.27887649, -0.09829452,  0.26759866]),\n",
       "   'corr': array([0.50445735, 0.53203515, 0.0342803 , 0.51973565])},\n",
       "  'results_org': {'mse_score': array([0.91995234, 0.67388733, 0.52706957, 0.81300547]),\n",
       "   'mae_score': array([0.76334583, 0.74008762, 0.69512296, 0.72870006]),\n",
       "   'r2': array([ 0.02140777,  0.24506023, -0.026564  ,  0.04944073]),\n",
       "   'explained_variance': array([ 0.21373435,  0.28806865, -0.0245128 ,  0.29603507]),\n",
       "   'corr': array([0.46269068, 0.54649586, 0.14010648, 0.56356218])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'LinearRegression',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.330004692077637,\n",
       "  'fitting_time': 0.09419584274291992,\n",
       "  'results_adj': {'mse_score': array([0.81048429, 0.37727505, 0.49112849, 0.64061096]),\n",
       "   'mae_score': array([0.65589708, 0.47007749, 0.61660063, 0.62910357]),\n",
       "   'r2': array([ 0.1808614 ,  0.57189073, -0.0254504 ,  0.22074752]),\n",
       "   'explained_variance': array([ 0.28371254,  0.6040801 , -0.01360095,  0.48555839]),\n",
       "   'corr': array([0.54668923, 0.7829105 , 0.30840753, 0.70409177])},\n",
       "  'results_org': {'mse_score': array([0.81048428, 0.37727504, 0.4911285 , 0.64061094]),\n",
       "   'mae_score': array([0.65589707, 0.47007749, 0.61660064, 0.62910356]),\n",
       "   'r2': array([0.13785358, 0.57734785, 0.04343778, 0.25100299]),\n",
       "   'explained_variance': array([0.24610478, 0.60912691, 0.0544912 , 0.50553224]),\n",
       "   'corr': array([0.5165533 , 0.78466151, 0.35991082, 0.72226304])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'MultiTaskElasticNet',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.369287967681885,\n",
       "  'fitting_time': 0.09032583236694336,\n",
       "  'results_adj': {'mse_score': array([1.18012258, 0.95041541, 0.50741152, 1.02939721]),\n",
       "   'mae_score': array([0.88414168, 0.78683575, 0.65378092, 0.82689556]),\n",
       "   'r2': array([-0.19272386, -0.07847485, -0.0594485 , -0.25218014]),\n",
       "   'explained_variance': array([ 0.11229865,  0.03189856, -0.05332472,  0.12857137]),\n",
       "   'corr': array([ 0.42176382,  0.1786427 , -0.16306839,  0.44631452])},\n",
       "  'results_org': {'mse_score': array([1.18012259, 0.95041541, 0.50741153, 1.02939718]),\n",
       "   'mae_score': array([0.88414169, 0.78683576, 0.65378093, 0.82689555]),\n",
       "   'r2': array([-0.25534633, -0.06472753,  0.01172361, -0.20356267]),\n",
       "   'explained_variance': array([0.06569101, 0.04423896, 0.01743601, 0.16240569]),\n",
       "   'corr': array([0.25863749, 0.21083047, 0.14561953, 0.49623364])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'MultiTaskLasso',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.328822612762451,\n",
       "  'fitting_time': 0.07589173316955566,\n",
       "  'results_adj': {'mse_score': array([1.39363767, 1.04056339, 0.48866937, 1.24000841]),\n",
       "   'mae_score': array([0.99127575, 0.78457157, 0.62110666, 0.93446712]),\n",
       "   'r2': array([-0.40851885, -0.18076941, -0.0203159 , -0.50837198]),\n",
       "   'explained_variance': array([-2.22044605e-16, -2.22044605e-16,  0.00000000e+00,  1.11022302e-16]),\n",
       "   'corr': array([nan, nan, nan, nan])},\n",
       "  'results_org': {'mse_score': array([1.39363768, 1.04056339, 0.48866939, 1.24000838]),\n",
       "   'mae_score': array([0.99127576, 0.78457157, 0.62110667, 0.93446711]),\n",
       "   'r2': array([-0.48247136, -0.16571814,  0.04822734, -0.44980754]),\n",
       "   'explained_variance': array([-0.05250375,  0.01274701,  0.06717846,  0.03882626]),\n",
       "   'corr': array([-0.0848666 ,  0.11455326,  0.2721653 ,  0.20679355])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'RandomForestRegressor',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.246447563171387,\n",
       "  'fitting_time': 70.82872891426086,\n",
       "  'results_adj': {'mse_score': array([0.91270925, 0.63963515, 0.50144223, 0.71697974]),\n",
       "   'mae_score': array([0.69319628, 0.68302695, 0.66108972, 0.60020152]),\n",
       "   'r2': array([ 0.07754489,  0.2741801 , -0.04698496,  0.12785095]),\n",
       "   'explained_variance': array([ 0.36576053,  0.38525551, -0.02355943,  0.46872553]),\n",
       "   'corr': array([0.60890593, 0.62755506, 0.1889929 , 0.69914107])},\n",
       "  'results_org': {'mse_score': array([0.91270925, 0.63963515, 0.50144226, 0.71697973]),\n",
       "   'mae_score': array([0.69319629, 0.68302695, 0.66108974, 0.60020152]),\n",
       "   'r2': array([0.02911256, 0.28343212, 0.02334986, 0.16171323]),\n",
       "   'explained_variance': array([0.33246059, 0.39309167, 0.04520171, 0.48935294]),\n",
       "   'corr': array([0.57903574, 0.63465983, 0.26873352, 0.72718785])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'XGBoostRegressor',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.200603246688843,\n",
       "  'fitting_time': 1.0566906929016113,\n",
       "  'results_adj': {'mse_score': array([1.07272323, 0.68904286, 0.28127899, 0.91724204]),\n",
       "   'mae_score': array([0.8126614 , 0.69629806, 0.4580846 , 0.73520871]),\n",
       "   'r2': array([-0.08417771,  0.21811517,  0.41270429, -0.11575227]),\n",
       "   'explained_variance': array([0.20032089, 0.31421814, 0.41751105, 0.24404689]),\n",
       "   'corr': array([0.46964804, 0.58371649, 0.65331834, 0.5071496 ])},\n",
       "  'results_org': {'mse_score': array([1.07272323, 0.68904285, 0.28127901, 0.91724203]),\n",
       "   'mae_score': array([0.81266141, 0.69629807, 0.45808461, 0.7352087 ]),\n",
       "   'r2': array([-0.14110109,  0.22808186,  0.45215789, -0.07243179]),\n",
       "   'explained_variance': array([0.15833475, 0.32295981, 0.45664175, 0.27339771]),\n",
       "   'corr': array([0.43327096, 0.580726  , 0.68275018, 0.52715055])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'TabNetRegressor_default',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.274345874786377,\n",
       "  'fitting_time': 48.89788365364075,\n",
       "  'results_adj': {'mse_score': array([0.81176328, 0.9232563 , 0.53269936, 0.5814455 ]),\n",
       "   'mae_score': array([0.80026617, 0.76125812, 0.64183157, 0.63951195]),\n",
       "   'r2': array([ 0.17956875, -0.0476563 , -0.11224819,  0.29271762]),\n",
       "   'explained_variance': array([ 0.32749891, -0.03740227, -0.09963687,  0.39816767]),\n",
       "   'corr': array([0.57835326, 0.2763594 , 0.18236466, 0.63104854])},\n",
       "  'results_org': {'mse_score': array([0.81176329, 0.92325629, 0.53269937, 0.58144548]),\n",
       "   'mae_score': array([0.80026618, 0.76125812, 0.64183158, 0.63951195]),\n",
       "   'r2': array([ 0.13649305, -0.03430182, -0.03752907,  0.32017875]),\n",
       "   'explained_variance': array([ 0.29219009, -0.02417849, -0.02576497,  0.42153457]),\n",
       "   'corr': array([0.54953825, 0.29819729, 0.25481839, 0.6499623 ])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'TabNetRegressor_custom',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.322273254394531,\n",
       "  'fitting_time': 61.155187368392944,\n",
       "  'results_adj': {'mse_score': array([0.75642257, 0.7641566 , 0.60110608, 1.16841797]),\n",
       "   'mae_score': array([0.67425298, 0.69018805, 0.66658878, 0.80277912]),\n",
       "   'r2': array([ 0.23550039,  0.13288057, -0.25507782, -0.42128788]),\n",
       "   'explained_variance': array([ 0.60598351,  0.46465823, -0.02273888,  0.16750731]),\n",
       "   'corr': array([0.78108922, 0.72583956, 0.4534265 , 0.59359943])},\n",
       "  'results_org': {'mse_score': array([0.75642256, 0.76415659, 0.60110611, 1.16841793]),\n",
       "   'mae_score': array([0.67425298, 0.69018805, 0.6665888 , 0.80277912]),\n",
       "   'r2': array([ 0.19536132,  0.14393374, -0.17076365, -0.36610458]),\n",
       "   'explained_variance': array([0.58529618, 0.47148225, 0.04596714, 0.19982992]),\n",
       "   'corr': array([0.76952137, 0.73431482, 0.49448244, 0.61178547])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'PLSRegression_4_components',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.390494108200073,\n",
       "  'fitting_time': 0.09732913970947266,\n",
       "  'results_adj': {'mse_score': array([0.96893751, 0.656857  , 0.51459647, 0.85455038]),\n",
       "   'mae_score': array([0.80120523, 0.73278536, 0.68920855, 0.76144007]),\n",
       "   'r2': array([ 0.02071623,  0.25463777, -0.0744503 , -0.03949283]),\n",
       "   'explained_variance': array([ 0.24334323,  0.31194062, -0.07367967,  0.26278738]),\n",
       "   'corr': array([0.49333443, 0.56450524, 0.07675799, 0.51337007])},\n",
       "  'results_org': {'mse_score': array([0.96893751, 0.656857  , 0.51459648, 0.85455036]),\n",
       "   'mae_score': array([0.80120524, 0.73278536, 0.68920857, 0.76144006]),\n",
       "   'r2': array([-0.03069982,  0.2641389 , -0.00227039,  0.00086679]),\n",
       "   'explained_variance': array([ 0.20361593,  0.32071132, -0.00155153,  0.29141059]),\n",
       "   'corr': array([0.45153476, 0.57824152, 0.17723945, 0.55208502])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'LinearRegression',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.730252504348755,\n",
       "  'fitting_time': 0.058013200759887695,\n",
       "  'results_adj': {'mse_score': array([0.81863983, 0.37644684, 0.48664733, 0.64033786]),\n",
       "   'mae_score': array([0.65103309, 0.46950199, 0.6115642 , 0.62897297]),\n",
       "   'r2': array([ 0.17261877,  0.57283053, -0.01609398,  0.22107973]),\n",
       "   'explained_variance': array([ 0.27812825,  0.60493752, -0.00321673,  0.48578115]),\n",
       "   'corr': array([0.54199935, 0.78352178, 0.3194207 , 0.70424558])},\n",
       "  'results_org': {'mse_score': array([0.81863983, 0.37644683, 0.48664734, 0.64033784]),\n",
       "   'mae_score': array([0.65103308, 0.469502  , 0.61156421, 0.62897296]),\n",
       "   'r2': array([0.12917818, 0.57827567, 0.05216565, 0.25132229]),\n",
       "   'explained_variance': array([0.2402273 , 0.6099734 , 0.06417782, 0.50574635]),\n",
       "   'corr': array([0.5115134 , 0.78524414, 0.37021182, 0.72239696])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'MultiTaskElasticNet',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.6521830558776855,\n",
       "  'fitting_time': 0.033573150634765625,\n",
       "  'results_adj': {'mse_score': array([1.18012258, 0.95041541, 0.50741152, 1.02939721]),\n",
       "   'mae_score': array([0.88414168, 0.78683575, 0.65378092, 0.82689556]),\n",
       "   'r2': array([-0.19272386, -0.07847485, -0.0594485 , -0.25218014]),\n",
       "   'explained_variance': array([ 0.11229865,  0.03189856, -0.05332472,  0.12857137]),\n",
       "   'corr': array([ 0.42176382,  0.1786427 , -0.16306839,  0.44631452])},\n",
       "  'results_org': {'mse_score': array([1.18012259, 0.95041541, 0.50741153, 1.02939718]),\n",
       "   'mae_score': array([0.88414169, 0.78683576, 0.65378093, 0.82689555]),\n",
       "   'r2': array([-0.25534633, -0.06472753,  0.01172361, -0.20356267]),\n",
       "   'explained_variance': array([0.06569101, 0.04423896, 0.01743601, 0.16240569]),\n",
       "   'corr': array([0.25863749, 0.21083047, 0.14561953, 0.49623364])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'MultiTaskLasso',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.5813071727752686,\n",
       "  'fitting_time': 0.018026351928710938,\n",
       "  'results_adj': {'mse_score': array([1.39363767, 1.04056339, 0.48866937, 1.24000841]),\n",
       "   'mae_score': array([0.99127575, 0.78457157, 0.62110666, 0.93446712]),\n",
       "   'r2': array([-0.40851885, -0.18076941, -0.0203159 , -0.50837198]),\n",
       "   'explained_variance': array([-2.22044605e-16, -2.22044605e-16,  0.00000000e+00,  1.11022302e-16]),\n",
       "   'corr': array([nan, nan, nan, nan])},\n",
       "  'results_org': {'mse_score': array([1.39363768, 1.04056339, 0.48866939, 1.24000838]),\n",
       "   'mae_score': array([0.99127576, 0.78457157, 0.62110667, 0.93446711]),\n",
       "   'r2': array([-0.48247136, -0.16571814,  0.04822734, -0.44980754]),\n",
       "   'explained_variance': array([-0.05250375,  0.01274701,  0.06717846,  0.03882626]),\n",
       "   'corr': array([-0.0848666 ,  0.11455326,  0.2721653 ,  0.20679355])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'RandomForestRegressor',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.6908276081085205,\n",
       "  'fitting_time': 70.75959205627441,\n",
       "  'results_adj': {'mse_score': array([0.86054074, 0.56611509, 0.43466597, 0.76486018]),\n",
       "   'mae_score': array([0.68035228, 0.62453322, 0.61929453, 0.64957315]),\n",
       "   'r2': array([0.13027045, 0.35760629, 0.09244036, 0.06960819]),\n",
       "   'explained_variance': array([0.3613913 , 0.45849311, 0.11113109, 0.39081604]),\n",
       "   'corr': array([0.60926405, 0.68725687, 0.34564343, 0.64041827])},\n",
       "  'results_org': {'mse_score': array([0.86054074, 0.56611509, 0.43466599, 0.76486016]),\n",
       "   'mae_score': array([0.68035228, 0.62453322, 0.61929454, 0.64957314]),\n",
       "   'r2': array([0.0846064 , 0.36579487, 0.1534088 , 0.10573183]),\n",
       "   'explained_variance': array([0.32786196, 0.4653957 , 0.17084392, 0.41446838]),\n",
       "   'corr': array([0.57822198, 0.69304436, 0.41411341, 0.67381864])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'XGBoostRegressor',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.46377420425415,\n",
       "  'fitting_time': 1.089108943939209,\n",
       "  'results_adj': {'mse_score': array([1.07272323, 0.68904286, 0.28127899, 0.91724204]),\n",
       "   'mae_score': array([0.8126614 , 0.69629806, 0.4580846 , 0.73520871]),\n",
       "   'r2': array([-0.08417771,  0.21811517,  0.41270429, -0.11575227]),\n",
       "   'explained_variance': array([0.20032089, 0.31421814, 0.41751105, 0.24404689]),\n",
       "   'corr': array([0.46964804, 0.58371649, 0.65331834, 0.5071496 ])},\n",
       "  'results_org': {'mse_score': array([1.07272323, 0.68904285, 0.28127901, 0.91724203]),\n",
       "   'mae_score': array([0.81266141, 0.69629807, 0.45808461, 0.7352087 ]),\n",
       "   'r2': array([-0.14110109,  0.22808186,  0.45215789, -0.07243179]),\n",
       "   'explained_variance': array([0.15833475, 0.32295981, 0.45664175, 0.27339771]),\n",
       "   'corr': array([0.43327096, 0.580726  , 0.68275018, 0.52715055])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'TabNetRegressor_default',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.563253164291382,\n",
       "  'fitting_time': 48.19717001914978,\n",
       "  'results_adj': {'mse_score': array([0.85830172, 0.54258827, 0.42545194, 0.91968852]),\n",
       "   'mae_score': array([0.70812123, 0.64736806, 0.57244405, 0.75514948]),\n",
       "   'r2': array([ 0.13253338,  0.38430313,  0.11167877, -0.11872822]),\n",
       "   'explained_variance': array([0.51235191, 0.56900905, 0.1425801 , 0.35747827]),\n",
       "   'corr': array([0.71689358, 0.774069  , 0.49858545, 0.65210265])},\n",
       "  'results_org': {'mse_score': array([0.85830172, 0.54258827, 0.42545197, 0.9196885 ]),\n",
       "   'mae_score': array([0.70812122, 0.64736807, 0.57244407, 0.75514948]),\n",
       "   'r2': array([ 0.08698815,  0.39215141,  0.17135479, -0.07529218]),\n",
       "   'explained_variance': array([0.48674857, 0.57450289, 0.20018023, 0.382425  ]),\n",
       "   'corr': array([0.69848392, 0.77451362, 0.5256542 , 0.65697843])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'TabNetRegressor_custom',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.647438287734985,\n",
       "  'fitting_time': 60.603052854537964,\n",
       "  'results_adj': {'mse_score': array([0.83273916, 0.3889441 , 0.33730824, 0.68276993]),\n",
       "   'mae_score': array([0.73474234, 0.51926794, 0.48464679, 0.64940162]),\n",
       "   'r2': array([0.1583689 , 0.55864938, 0.29571818, 0.16946448]),\n",
       "   'explained_variance': array([0.59150138, 0.77113636, 0.29776492, 0.4677038 ]),\n",
       "   'corr': array([0.80331183, 0.87876644, 0.56948955, 0.68407541])},\n",
       "  'results_org': {'mse_score': array([0.83273916, 0.38894411, 0.33730825, 0.6827699 ]),\n",
       "   'mae_score': array([0.73474234, 0.51926795, 0.4846468 , 0.64940162]),\n",
       "   'r2': array([0.11418012, 0.56427527, 0.34303073, 0.20171108]),\n",
       "   'explained_variance': array([0.57005368, 0.77405369, 0.34493998, 0.48837089]),\n",
       "   'corr': array([0.78520546, 0.88027421, 0.60958533, 0.70148986])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'PLSRegression_4_components',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.601892471313477,\n",
       "  'fitting_time': 0.05086708068847656,\n",
       "  'results_adj': {'mse_score': array([0.95734743, 0.6507307 , 0.51205314, 0.84566624]),\n",
       "   'mae_score': array([0.7956327 , 0.72857883, 0.68759767, 0.75641817]),\n",
       "   'r2': array([ 0.03243007,  0.26158952, -0.06913998, -0.02868597]),\n",
       "   'explained_variance': array([ 0.2448082 ,  0.31446083, -0.06801471,  0.26218832]),\n",
       "   'corr': array([0.49481059, 0.56690135, 0.08498668, 0.51269862])},\n",
       "  'results_org': {'mse_score': array([0.95734743, 0.6507307 , 0.51205316, 0.84566621]),\n",
       "   'mae_score': array([0.79563271, 0.72857883, 0.68759768, 0.75641816]),\n",
       "   'r2': array([-0.01837097,  0.27100204,  0.00268319,  0.01125406]),\n",
       "   'explained_variance': array([0.20515781, 0.3231994 , 0.00373287, 0.2908348 ]),\n",
       "   'corr': array([0.45329802, 0.58054749, 0.18433316, 0.55102952])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'LinearRegression',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.320513010025024,\n",
       "  'fitting_time': 0.10823988914489746,\n",
       "  'results_adj': {'mse_score': array([0.81385665, 0.3796557 , 0.48661832, 0.62605385]),\n",
       "   'mae_score': array([0.6517172 , 0.47208447, 0.61341437, 0.62383275]),\n",
       "   'r2': array([ 0.17745303,  0.56918931, -0.01603341,  0.2384551 ]),\n",
       "   'explained_variance': array([ 0.27652142,  0.60176437, -0.00398979,  0.48412726]),\n",
       "   'corr': array([0.54137403, 0.78135458, 0.31740288, 0.70274458])},\n",
       "  'results_org': {'mse_score': array([0.81385664, 0.37965568, 0.48661833, 0.62605383]),\n",
       "   'mae_score': array([0.65171719, 0.47208447, 0.61341438, 0.62383274]),\n",
       "   'r2': array([0.13426626, 0.57468087, 0.05222215, 0.26802304]),\n",
       "   'explained_variance': array([0.23853611, 0.6068407 , 0.06345669, 0.50415667]),\n",
       "   'corr': array([0.51110415, 0.7831683 , 0.36832373, 0.72092578])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'MultiTaskElasticNet',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.262490510940552,\n",
       "  'fitting_time': 0.09371542930603027,\n",
       "  'results_adj': {'mse_score': array([1.18012258, 0.95041541, 0.50741152, 1.02939721]),\n",
       "   'mae_score': array([0.88414168, 0.78683575, 0.65378092, 0.82689556]),\n",
       "   'r2': array([-0.19272386, -0.07847485, -0.0594485 , -0.25218014]),\n",
       "   'explained_variance': array([ 0.11229865,  0.03189856, -0.05332472,  0.12857137]),\n",
       "   'corr': array([ 0.42176382,  0.1786427 , -0.16306839,  0.44631452])},\n",
       "  'results_org': {'mse_score': array([1.18012259, 0.95041541, 0.50741153, 1.02939718]),\n",
       "   'mae_score': array([0.88414169, 0.78683576, 0.65378093, 0.82689555]),\n",
       "   'r2': array([-0.25534633, -0.06472753,  0.01172361, -0.20356267]),\n",
       "   'explained_variance': array([0.06569101, 0.04423896, 0.01743601, 0.16240569]),\n",
       "   'corr': array([0.25863749, 0.21083047, 0.14561953, 0.49623364])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'MultiTaskLasso',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.268090486526489,\n",
       "  'fitting_time': 0.07982349395751953,\n",
       "  'results_adj': {'mse_score': array([1.39363767, 1.04056339, 0.48866937, 1.24000841]),\n",
       "   'mae_score': array([0.99127575, 0.78457157, 0.62110666, 0.93446712]),\n",
       "   'r2': array([-0.40851885, -0.18076941, -0.0203159 , -0.50837198]),\n",
       "   'explained_variance': array([-2.22044605e-16, -2.22044605e-16,  0.00000000e+00,  1.11022302e-16]),\n",
       "   'corr': array([nan, nan, nan, nan])},\n",
       "  'results_org': {'mse_score': array([1.39363768, 1.04056339, 0.48866939, 1.24000838]),\n",
       "   'mae_score': array([0.99127576, 0.78457157, 0.62110667, 0.93446711]),\n",
       "   'r2': array([-0.48247136, -0.16571814,  0.04822734, -0.44980754]),\n",
       "   'explained_variance': array([-0.05250375,  0.01274701,  0.06717846,  0.03882626]),\n",
       "   'corr': array([-0.0848666 ,  0.11455326,  0.2721653 ,  0.20679355])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'RandomForestRegressor',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.414134740829468,\n",
       "  'fitting_time': 73.83078718185425,\n",
       "  'results_adj': {'mse_score': array([0.82211723, 0.60584436, 0.44012532, 0.69870305]),\n",
       "   'mae_score': array([0.6634487 , 0.67389037, 0.62500426, 0.60712466]),\n",
       "   'r2': array([0.16910425, 0.31252388, 0.08104152, 0.1500831 ]),\n",
       "   'explained_variance': array([0.42760208, 0.4309486 , 0.08685309, 0.50789862]),\n",
       "   'corr': array([0.66918387, 0.66599809, 0.30486755, 0.73344775])},\n",
       "  'results_org': {'mse_score': array([0.82211723, 0.60584436, 0.44012534, 0.69870303]),\n",
       "   'mae_score': array([0.6634487 , 0.67389037, 0.62500427, 0.60712466]),\n",
       "   'r2': array([0.12547912, 0.32128713, 0.14277572, 0.1830822 ]),\n",
       "   'explained_variance': array([0.39754906, 0.43820231, 0.14819688, 0.52700508]),\n",
       "   'corr': array([0.64441007, 0.67193812, 0.38498874, 0.76222886])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'XGBoostRegressor',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.287079095840454,\n",
       "  'fitting_time': 1.0720291137695312,\n",
       "  'results_adj': {'mse_score': array([0.99004624, 0.71240804, 0.28127899, 0.9199078 ]),\n",
       "   'mae_score': array([0.7833916 , 0.70447981, 0.4580846 , 0.7620918 ]),\n",
       "   'r2': array([-0.00061791,  0.19160176,  0.41270429, -0.11899496]),\n",
       "   'explained_variance': array([0.27879057, 0.27255507, 0.41751105, 0.24729249]),\n",
       "   'corr': array([0.53107181, 0.53449332, 0.65331834, 0.49978871])},\n",
       "  'results_org': {'mse_score': array([0.99004624, 0.71240803, 0.28127901, 0.91990779]),\n",
       "   'mae_score': array([0.7833916 , 0.70447981, 0.45808461, 0.76209179]),\n",
       "   'r2': array([-0.05315408,  0.20190641,  0.45215789, -0.07554858]),\n",
       "   'explained_variance': array([0.24092439, 0.28182782, 0.45664175, 0.2765173 ]),\n",
       "   'corr': array([0.50298481, 0.54078423, 0.68275018, 0.52611063])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'TabNetRegressor_default',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.310622453689575,\n",
       "  'fitting_time': 49.13913035392761,\n",
       "  'results_adj': {'mse_score': array([0.71085341, 0.76201508, 0.53921646, 0.81864719]),\n",
       "   'mae_score': array([0.7519538 , 0.71936832, 0.65255263, 0.77134314]),\n",
       "   'r2': array([ 0.28155614,  0.13531063, -0.12585556,  0.00418055]),\n",
       "   'explained_variance': array([ 0.35899234,  0.1513197 , -0.10471893,  0.16110378]),\n",
       "   'corr': array([0.6351365 , 0.47951748, 0.11005474, 0.53247918])},\n",
       "  'results_org': {'mse_score': array([0.7108534 , 0.76201507, 0.53921647, 0.81864716]),\n",
       "   'mae_score': array([0.7519538 , 0.71936831, 0.65255265, 0.77134313]),\n",
       "   'r2': array([ 0.24383516,  0.14633284, -0.05022231,  0.04284451]),\n",
       "   'explained_variance': array([ 0.32533704,  0.16213784, -0.03050561,  0.193675  ]),\n",
       "   'corr': array([0.61748662, 0.48228133, 0.14897684, 0.53456421])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'TabNetRegressor_custom',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.431665420532227,\n",
       "  'fitting_time': 61.63265609741211,\n",
       "  'results_adj': {'mse_score': array([0.94269564, 0.76040794, 0.48967338, 0.72092557]),\n",
       "   'mae_score': array([0.77868363, 0.73632988, 0.58859802, 0.75154707]),\n",
       "   'r2': array([ 0.0472383 ,  0.13713432, -0.02241221,  0.12305117]),\n",
       "   'explained_variance': array([ 0.08526729,  0.17892985, -0.01520576,  0.17998317]),\n",
       "   'corr': array([0.4271153 , 0.43720125, 0.24100718, 0.46332624])},\n",
       "  'results_org': {'mse_score': array([0.94269563, 0.76040794, 0.48967339, 0.72092555]),\n",
       "   'mae_score': array([0.77868362, 0.73632988, 0.58859804, 0.75154706]),\n",
       "   'r2': array([-0.00278523,  0.14813326,  0.04627188,  0.15709981]),\n",
       "   'explained_variance': array([0.03724042, 0.18939603, 0.0529942 , 0.21182136]),\n",
       "   'corr': array([0.39781087, 0.44903422, 0.32733618, 0.4708255 ])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_constant',\n",
       "   'continuous_imputer': 'KNNImputer_2',\n",
       "   'model': 'PLSRegression_4_components',\n",
       "   'train_shape': (2881, 276),\n",
       "   'test_shape': (13, 276)},\n",
       "  'imputation_time': 4.333852291107178,\n",
       "  'fitting_time': 0.10361194610595703,\n",
       "  'results_adj': {'mse_score': array([0.92583961, 0.65042523, 0.51742301, 0.81656015]),\n",
       "   'mae_score': array([0.77389782, 0.72848023, 0.68878244, 0.73848884]),\n",
       "   'r2': array([ 0.06427433,  0.26193615, -0.08035198,  0.00671928]),\n",
       "   'explained_variance': array([ 0.24663757,  0.30431198, -0.07784287,  0.26417575]),\n",
       "   'corr': array([0.49702283, 0.557909  , 0.06742836, 0.51532931])},\n",
       "  'results_org': {'mse_score': array([0.92583961, 0.65042523, 0.51742303, 0.81656013]),\n",
       "   'mae_score': array([0.77389783, 0.72848024, 0.68878245, 0.73848884]),\n",
       "   'r2': array([ 0.01514524,  0.27134425, -0.0077756 ,  0.04528465]),\n",
       "   'explained_variance': array([ 0.20708323,  0.31317992, -0.00543505,  0.29274506]),\n",
       "   'corr': array([0.45506754, 0.57208571, 0.16966812, 0.55609741])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'LinearRegression',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 8.421263217926025,\n",
       "  'fitting_time': 0.1636190414428711,\n",
       "  'results_adj': {'mse_score': array([0.65983176, 0.48974311, 0.40951464, 0.56684282]),\n",
       "   'mae_score': array([0.63965764, 0.55144938, 0.56535002, 0.59999667]),\n",
       "   'r2': array([0.33312259, 0.44426866, 0.144955  , 0.31048062]),\n",
       "   'explained_variance': array([0.36730884, 0.47760179, 0.14545957, 0.43985495]),\n",
       "   'corr': array([0.60633336, 0.69220668, 0.4020632 , 0.66605104])},\n",
       "  'results_org': {'mse_score': array([0.65983176, 0.4897431 , 0.40951466, 0.56684279]),\n",
       "   'mae_score': array([0.63965764, 0.55144938, 0.56535003, 0.59999666]),\n",
       "   'r2': array([0.29810904, 0.45135258, 0.20239561, 0.33725209]),\n",
       "   'explained_variance': array([0.33409019, 0.48426081, 0.20286628, 0.46160331]),\n",
       "   'corr': array([0.57814397, 0.69816204, 0.46213839, 0.68191102])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskElasticNet',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 6.582948446273804,\n",
       "  'fitting_time': 0.1412639617919922,\n",
       "  'results_adj': {'mse_score': array([1.18012248, 0.95041535, 0.50741149, 1.02939714]),\n",
       "   'mae_score': array([0.88414168, 0.78683573, 0.65378091, 0.82689555]),\n",
       "   'r2': array([-0.19272377, -0.07847478, -0.05944846, -0.25218006]),\n",
       "   'explained_variance': array([ 0.11229868,  0.03189858, -0.05332468,  0.12857136]),\n",
       "   'corr': array([ 0.42176385,  0.17864276, -0.16306812,  0.44631446])},\n",
       "  'results_org': {'mse_score': array([1.18012249, 0.95041535, 0.50741151, 1.02939711]),\n",
       "   'mae_score': array([0.88414168, 0.78683573, 0.65378092, 0.82689554]),\n",
       "   'r2': array([-0.25534622, -0.06472746,  0.01172365, -0.20356259]),\n",
       "   'explained_variance': array([0.06569104, 0.04423898, 0.01743605, 0.16240568]),\n",
       "   'corr': array([0.25863755, 0.21083052, 0.14561963, 0.49623359])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskElasticNet_tuned',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 6.899693727493286,\n",
       "  'fitting_time': 2.5698063373565674,\n",
       "  'results_adj': {'mse_score': array([0.66791342, 0.47856617, 0.41412878, 0.59264981]),\n",
       "   'mae_score': array([0.63043587, 0.55392437, 0.58019171, 0.59956285]),\n",
       "   'r2': array([0.32495464, 0.45695159, 0.13532092, 0.27908847]),\n",
       "   'explained_variance': array([0.3700506 , 0.49637797, 0.13598028, 0.44010284]),\n",
       "   'corr': array([0.60831821, 0.70457467, 0.38152442, 0.66946516])},\n",
       "  'results_org': {'mse_score': array([0.66791342, 0.47856617, 0.4141288 , 0.59264978]),\n",
       "   'mae_score': array([0.63043586, 0.55392437, 0.58019172, 0.59956284]),\n",
       "   'r2': array([0.28951224, 0.46387383, 0.19340873, 0.30707878]),\n",
       "   'explained_variance': array([0.33697591, 0.50279765, 0.19402379, 0.46184157]),\n",
       "   'corr': array([0.58049709, 0.70936568, 0.44690586, 0.68551862])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskLasso',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 7.6002771854400635,\n",
       "  'fitting_time': 0.10144400596618652,\n",
       "  'results_adj': {'mse_score': array([1.39363767, 1.04056339, 0.48866937, 1.24000841]),\n",
       "   'mae_score': array([0.99127575, 0.78457157, 0.62110666, 0.93446712]),\n",
       "   'r2': array([-0.40851885, -0.18076941, -0.0203159 , -0.50837198]),\n",
       "   'explained_variance': array([-2.22044605e-16, -2.22044605e-16,  0.00000000e+00,  1.11022302e-16]),\n",
       "   'corr': array([nan, nan, nan, nan])},\n",
       "  'results_org': {'mse_score': array([1.39363768, 1.04056339, 0.48866939, 1.24000838]),\n",
       "   'mae_score': array([0.99127576, 0.78457157, 0.62110667, 0.93446711]),\n",
       "   'r2': array([-0.48247136, -0.16571814,  0.04822734, -0.44980754]),\n",
       "   'explained_variance': array([-0.05250375,  0.01274701,  0.06717846,  0.03882626]),\n",
       "   'corr': array([-0.0848666 ,  0.11455326,  0.2721653 ,  0.20679355])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskLasso_tuned',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 6.8049633502960205,\n",
       "  'fitting_time': 2.4062068462371826,\n",
       "  'results_adj': {'mse_score': array([0.6555347 , 0.47602153, 0.41898635, 0.58247095]),\n",
       "   'mae_score': array([0.62193632, 0.55058805, 0.57780272, 0.59499437]),\n",
       "   'r2': array([0.33746553, 0.45983909, 0.12517858, 0.29147024]),\n",
       "   'explained_variance': array([0.38303248, 0.49996522, 0.12605199, 0.44788336]),\n",
       "   'corr': array([0.61892446, 0.70715313, 0.37654024, 0.67491708])},\n",
       "  'results_org': {'mse_score': array([0.6555347 , 0.47602153, 0.41898636, 0.58247092]),\n",
       "   'mae_score': array([0.62193631, 0.55058805, 0.57780274, 0.59499436]),\n",
       "   'r2': array([0.30268   , 0.46672453, 0.18394773, 0.31897981]),\n",
       "   'explained_variance': array([0.35063939, 0.50633917, 0.18476246, 0.46932   ]),\n",
       "   'corr': array([0.59223356, 0.71197064, 0.44079738, 0.69050252])}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dict_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing combination: dict_values(['SimpleImputer_most_frequent', 'KNNImputer', 'LinearRegression', (2881, 348), (13, 348)])\n",
      "Skipping existing combination: dict_values(['SimpleImputer_most_frequent', 'KNNImputer', 'MultiTaskElasticNet', (2881, 348), (13, 348)])\n",
      "Skipping existing combination: dict_values(['SimpleImputer_most_frequent', 'KNNImputer', 'MultiTaskElasticNet_tuned', (2881, 348), (13, 348)])\n",
      "Skipping existing combination: dict_values(['SimpleImputer_most_frequent', 'KNNImputer', 'MultiTaskLasso', (2881, 348), (13, 348)])\n",
      "Skipping existing combination: dict_values(['SimpleImputer_most_frequent', 'KNNImputer', 'MultiTaskLasso_tuned', (2881, 348), (13, 348)])\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:APOE_epsilon2: object, APOE_epsilon3: object, APOE_epsilon4: object\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:APOE_epsilon2: object, APOE_epsilon3: object, APOE_epsilon4: object\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "epoch 0  | loss: 2.93417 |  0:00:00s\n",
      "epoch 1  | loss: 1.74774 |  0:00:00s\n",
      "epoch 2  | loss: 1.30609 |  0:00:00s\n",
      "epoch 3  | loss: 1.11534 |  0:00:01s\n",
      "epoch 4  | loss: 1.03865 |  0:00:01s\n",
      "epoch 5  | loss: 0.97673 |  0:00:01s\n",
      "epoch 6  | loss: 0.94595 |  0:00:02s\n",
      "epoch 7  | loss: 0.90509 |  0:00:02s\n",
      "epoch 8  | loss: 0.89141 |  0:00:02s\n",
      "epoch 9  | loss: 0.88195 |  0:00:02s\n",
      "epoch 10 | loss: 0.85832 |  0:00:03s\n",
      "epoch 11 | loss: 0.8406  |  0:00:03s\n",
      "epoch 12 | loss: 0.81405 |  0:00:03s\n",
      "epoch 13 | loss: 0.79361 |  0:00:04s\n",
      "epoch 14 | loss: 0.78379 |  0:00:04s\n",
      "epoch 15 | loss: 0.77289 |  0:00:04s\n",
      "epoch 16 | loss: 0.78232 |  0:00:05s\n",
      "epoch 17 | loss: 0.77523 |  0:00:05s\n",
      "epoch 18 | loss: 0.77527 |  0:00:05s\n",
      "epoch 19 | loss: 0.74905 |  0:00:05s\n",
      "epoch 20 | loss: 0.74385 |  0:00:06s\n",
      "epoch 21 | loss: 0.73698 |  0:00:06s\n",
      "epoch 22 | loss: 0.74113 |  0:00:06s\n",
      "epoch 23 | loss: 0.72469 |  0:00:06s\n",
      "epoch 24 | loss: 0.73297 |  0:00:07s\n",
      "epoch 25 | loss: 0.70808 |  0:00:07s\n",
      "epoch 26 | loss: 0.7005  |  0:00:07s\n",
      "epoch 27 | loss: 0.69933 |  0:00:08s\n",
      "epoch 28 | loss: 0.69535 |  0:00:08s\n",
      "epoch 29 | loss: 0.68354 |  0:00:08s\n",
      "epoch 30 | loss: 0.68443 |  0:00:09s\n",
      "epoch 31 | loss: 0.68763 |  0:00:09s\n",
      "epoch 32 | loss: 0.67315 |  0:00:09s\n",
      "epoch 33 | loss: 0.66557 |  0:00:09s\n",
      "epoch 34 | loss: 0.66459 |  0:00:10s\n",
      "epoch 35 | loss: 0.65609 |  0:00:10s\n",
      "epoch 36 | loss: 0.65737 |  0:00:10s\n",
      "epoch 37 | loss: 0.65475 |  0:00:11s\n",
      "epoch 38 | loss: 0.65325 |  0:00:11s\n",
      "epoch 39 | loss: 0.65498 |  0:00:11s\n",
      "epoch 40 | loss: 0.64804 |  0:00:11s\n",
      "epoch 41 | loss: 0.64046 |  0:00:12s\n",
      "epoch 42 | loss: 0.641   |  0:00:12s\n",
      "epoch 43 | loss: 0.63652 |  0:00:12s\n",
      "epoch 44 | loss: 0.63722 |  0:00:12s\n",
      "epoch 45 | loss: 0.63336 |  0:00:13s\n",
      "epoch 46 | loss: 0.62929 |  0:00:13s\n",
      "epoch 47 | loss: 0.62443 |  0:00:13s\n",
      "epoch 48 | loss: 0.61957 |  0:00:14s\n",
      "epoch 49 | loss: 0.62234 |  0:00:14s\n",
      "epoch 50 | loss: 0.61733 |  0:00:14s\n",
      "epoch 51 | loss: 0.62662 |  0:00:14s\n",
      "epoch 52 | loss: 0.62798 |  0:00:15s\n",
      "epoch 53 | loss: 0.61528 |  0:00:15s\n",
      "epoch 54 | loss: 0.61877 |  0:00:15s\n",
      "epoch 55 | loss: 0.61573 |  0:00:15s\n",
      "epoch 56 | loss: 0.62112 |  0:00:16s\n",
      "epoch 57 | loss: 0.6198  |  0:00:16s\n",
      "epoch 58 | loss: 0.61167 |  0:00:16s\n",
      "epoch 59 | loss: 0.60908 |  0:00:17s\n",
      "epoch 60 | loss: 0.61015 |  0:00:17s\n",
      "epoch 61 | loss: 0.6095  |  0:00:17s\n",
      "epoch 62 | loss: 0.60123 |  0:00:17s\n",
      "epoch 63 | loss: 0.60575 |  0:00:18s\n",
      "epoch 64 | loss: 0.60008 |  0:00:18s\n",
      "epoch 65 | loss: 0.59448 |  0:00:18s\n",
      "epoch 66 | loss: 0.59518 |  0:00:18s\n",
      "epoch 67 | loss: 0.5972  |  0:00:19s\n",
      "epoch 68 | loss: 0.59691 |  0:00:19s\n",
      "epoch 69 | loss: 0.59486 |  0:00:19s\n",
      "epoch 70 | loss: 0.58162 |  0:00:20s\n",
      "epoch 71 | loss: 0.59056 |  0:00:20s\n",
      "epoch 72 | loss: 0.58044 |  0:00:20s\n",
      "epoch 73 | loss: 0.57702 |  0:00:21s\n",
      "epoch 74 | loss: 0.58173 |  0:00:21s\n",
      "epoch 75 | loss: 0.58203 |  0:00:21s\n",
      "epoch 76 | loss: 0.5707  |  0:00:22s\n",
      "epoch 77 | loss: 0.57001 |  0:00:22s\n",
      "epoch 78 | loss: 0.57232 |  0:00:22s\n",
      "epoch 79 | loss: 0.58243 |  0:00:23s\n",
      "epoch 80 | loss: 0.58812 |  0:00:23s\n",
      "epoch 81 | loss: 0.58635 |  0:00:23s\n",
      "epoch 82 | loss: 0.58342 |  0:00:23s\n",
      "epoch 83 | loss: 0.58055 |  0:00:24s\n",
      "epoch 84 | loss: 0.5794  |  0:00:24s\n",
      "epoch 85 | loss: 0.58179 |  0:00:24s\n",
      "epoch 86 | loss: 0.58218 |  0:00:25s\n",
      "epoch 87 | loss: 0.5784  |  0:00:25s\n",
      "epoch 88 | loss: 0.57363 |  0:00:25s\n",
      "epoch 89 | loss: 0.57396 |  0:00:25s\n",
      "epoch 90 | loss: 0.5686  |  0:00:26s\n",
      "epoch 91 | loss: 0.57256 |  0:00:26s\n",
      "epoch 92 | loss: 0.57221 |  0:00:26s\n",
      "epoch 93 | loss: 0.56053 |  0:00:27s\n",
      "epoch 94 | loss: 0.55118 |  0:00:27s\n",
      "epoch 95 | loss: 0.55328 |  0:00:27s\n",
      "epoch 96 | loss: 0.55268 |  0:00:28s\n",
      "epoch 97 | loss: 0.55494 |  0:00:28s\n",
      "epoch 98 | loss: 0.54789 |  0:00:28s\n",
      "epoch 99 | loss: 0.54554 |  0:00:28s\n",
      "epoch 100| loss: 0.54637 |  0:00:29s\n",
      "epoch 101| loss: 0.53919 |  0:00:29s\n",
      "epoch 102| loss: 0.53304 |  0:00:29s\n",
      "epoch 103| loss: 0.52388 |  0:00:29s\n",
      "epoch 104| loss: 0.52574 |  0:00:30s\n",
      "epoch 105| loss: 0.51954 |  0:00:30s\n",
      "epoch 106| loss: 0.52908 |  0:00:30s\n",
      "epoch 107| loss: 0.53297 |  0:00:31s\n",
      "epoch 108| loss: 0.51874 |  0:00:31s\n",
      "epoch 109| loss: 0.52364 |  0:00:31s\n",
      "epoch 110| loss: 0.52845 |  0:00:31s\n",
      "epoch 111| loss: 0.53193 |  0:00:32s\n",
      "epoch 112| loss: 0.52809 |  0:00:32s\n"
     ]
    }
   ],
   "source": [
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    name_continuous_imputer, continuous_imputer_instance = continuous_imputer\n",
    "    name_ordinal_imputer, ordinal_imputer_instance = ordinal_imputer\n",
    "    name_model, model_instance = model\n",
    "\n",
    "    params = {\n",
    "        \"ordinal_imputer\": name_ordinal_imputer, \n",
    "        \"continuous_imputer\": name_continuous_imputer, \n",
    "        \"model\": name_model, \"train_shape\" : df_X_train.shape, \n",
    "        \"test_shape\": df_X_test.shape\n",
    "    }\n",
    "\n",
    "    if any(result['params'] == params for result in all_dict_results):\n",
    "        # Skip this iteration if the combination exists\n",
    "        print(f\"Skipping existing combination: {params.values()}\")\n",
    "        \n",
    "        continue\n",
    "\n",
    "    try: \n",
    "    \n",
    "        # Now you can call your `train_model` function with these components\n",
    "        dict_results = train_imputer_model(\n",
    "            df_X_train, df_X_test, df_y_train, df_y_test,\n",
    "            c_train, c_test,\n",
    "            ordinal_imputer_instance, name_ordinal_imputer,\n",
    "            continuous_imputer_instance, name_continuous_imputer,\n",
    "            model_instance, name_model,\n",
    "            separate_imputers=True  # Or however you want to specify\n",
    "        )\n",
    "\n",
    "    except Exception as e:  \n",
    "\n",
    "        print(e)\n",
    "    \n",
    "        dict_results = {\n",
    "        \"params\": params, \n",
    "        \"imputation_time\": None,\n",
    "        \"fitting_time\": None, \n",
    "        \"results_adj\": None, \n",
    "        \"results_org\": None\n",
    "    }\n",
    "        \n",
    "    # Optionally keep the all_dict_results list updated\n",
    "    all_dict_results.append(dict_results)\n",
    "\n",
    "        # Save the updated results back to the pickle file\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(all_dict_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open(results_file, 'wb') as handle:\n",
    "    pickle.dump(all_dict_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/training_2_dict_results.pickle', \"rb\") as input_file:\n",
    "    dict_results_split = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'LinearRegression',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.2466392517089844,\n",
       "  'fitting_time': 0.22939062118530273,\n",
       "  'results_adj': {'mse_score': array([0.65983176, 0.48974311, 0.40951464, 0.56684282]),\n",
       "   'mae_score': array([0.63965764, 0.55144938, 0.56535002, 0.59999667]),\n",
       "   'r2': array([0.33312259, 0.44426866, 0.144955  , 0.31048062]),\n",
       "   'explained_variance': array([0.36730884, 0.47760179, 0.14545957, 0.43985495]),\n",
       "   'corr': array([0.60633336, 0.69220668, 0.4020632 , 0.66605104])},\n",
       "  'results_org': {'mse_score': array([0.65983176, 0.4897431 , 0.40951466, 0.56684279]),\n",
       "   'mae_score': array([0.63965764, 0.55144938, 0.56535003, 0.59999666]),\n",
       "   'r2': array([0.29810904, 0.45135258, 0.20239561, 0.33725209]),\n",
       "   'explained_variance': array([0.33409019, 0.48426081, 0.20286628, 0.46160331]),\n",
       "   'corr': array([0.57814397, 0.69816204, 0.46213839, 0.68191102])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskElasticNet',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.283444404602051,\n",
       "  'fitting_time': 0.09822368621826172,\n",
       "  'results_adj': {'mse_score': array([1.18012248, 0.95041535, 0.50741149, 1.02939714]),\n",
       "   'mae_score': array([0.88414168, 0.78683573, 0.65378091, 0.82689555]),\n",
       "   'r2': array([-0.19272377, -0.07847478, -0.05944846, -0.25218006]),\n",
       "   'explained_variance': array([ 0.11229868,  0.03189858, -0.05332468,  0.12857136]),\n",
       "   'corr': array([ 0.42176385,  0.17864276, -0.16306812,  0.44631446])},\n",
       "  'results_org': {'mse_score': array([1.18012249, 0.95041535, 0.50741151, 1.02939711]),\n",
       "   'mae_score': array([0.88414168, 0.78683573, 0.65378092, 0.82689554]),\n",
       "   'r2': array([-0.25534622, -0.06472746,  0.01172365, -0.20356259]),\n",
       "   'explained_variance': array([0.06569104, 0.04423898, 0.01743605, 0.16240568]),\n",
       "   'corr': array([0.25863755, 0.21083052, 0.14561963, 0.49623359])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskElasticNet_tuned',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.2664968967437744,\n",
       "  'fitting_time': 1.4926152229309082,\n",
       "  'results_adj': {'mse_score': array([0.66791342, 0.47856617, 0.41412878, 0.59264981]),\n",
       "   'mae_score': array([0.63043587, 0.55392437, 0.58019171, 0.59956285]),\n",
       "   'r2': array([0.32495464, 0.45695159, 0.13532092, 0.27908847]),\n",
       "   'explained_variance': array([0.3700506 , 0.49637797, 0.13598028, 0.44010284]),\n",
       "   'corr': array([0.60831821, 0.70457467, 0.38152442, 0.66946516])},\n",
       "  'results_org': {'mse_score': array([0.66791342, 0.47856617, 0.4141288 , 0.59264978]),\n",
       "   'mae_score': array([0.63043586, 0.55392437, 0.58019172, 0.59956284]),\n",
       "   'r2': array([0.28951224, 0.46387383, 0.19340873, 0.30707878]),\n",
       "   'explained_variance': array([0.33697591, 0.50279765, 0.19402379, 0.46184157]),\n",
       "   'corr': array([0.58049709, 0.70936568, 0.44690586, 0.68551862])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskLasso',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.283153772354126,\n",
       "  'fitting_time': 0.07776927947998047,\n",
       "  'results_adj': {'mse_score': array([1.39363767, 1.04056339, 0.48866937, 1.24000841]),\n",
       "   'mae_score': array([0.99127575, 0.78457157, 0.62110666, 0.93446712]),\n",
       "   'r2': array([-0.40851885, -0.18076941, -0.0203159 , -0.50837198]),\n",
       "   'explained_variance': array([-2.22044605e-16,  0.00000000e+00,  0.00000000e+00,  1.11022302e-16]),\n",
       "   'corr': array([nan, nan, nan, nan])},\n",
       "  'results_org': {'mse_score': array([1.39363768, 1.04056339, 0.48866939, 1.24000838]),\n",
       "   'mae_score': array([0.99127576, 0.78457157, 0.62110667, 0.93446711]),\n",
       "   'r2': array([-0.48247136, -0.16571814,  0.04822734, -0.44980754]),\n",
       "   'explained_variance': array([-0.05250375,  0.01274701,  0.06717846,  0.03882626]),\n",
       "   'corr': array([-0.0848666 ,  0.11455326,  0.2721653 ,  0.20679355])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskLasso_tuned',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.3114430904388428,\n",
       "  'fitting_time': 1.4922456741333008,\n",
       "  'results_adj': {'mse_score': array([0.6555347 , 0.47602153, 0.41898635, 0.58247095]),\n",
       "   'mae_score': array([0.62193632, 0.55058805, 0.57780272, 0.59499437]),\n",
       "   'r2': array([0.33746553, 0.45983909, 0.12517858, 0.29147024]),\n",
       "   'explained_variance': array([0.38303248, 0.49996522, 0.12605199, 0.44788336]),\n",
       "   'corr': array([0.61892446, 0.70715313, 0.37654024, 0.67491708])},\n",
       "  'results_org': {'mse_score': array([0.6555347 , 0.47602153, 0.41898636, 0.58247092]),\n",
       "   'mae_score': array([0.62193631, 0.55058805, 0.57780274, 0.59499436]),\n",
       "   'r2': array([0.30268   , 0.46672453, 0.18394773, 0.31897981]),\n",
       "   'explained_variance': array([0.35063939, 0.50633917, 0.18476246, 0.46932   ]),\n",
       "   'corr': array([0.59223356, 0.71197064, 0.44079738, 0.69050252])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'RandomForestRegressor',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.289330244064331,\n",
       "  'fitting_time': 51.79721212387085,\n",
       "  'results_adj': {'mse_score': array([0.81204962, 0.55738872, 0.42447239, 0.76265381]),\n",
       "   'mae_score': array([0.66916949, 0.63959102, 0.60835909, 0.64774379]),\n",
       "   'r2': array([0.17927936, 0.36750845, 0.11372402, 0.07229206]),\n",
       "   'explained_variance': array([0.38575368, 0.43668934, 0.11735442, 0.37009751]),\n",
       "   'corr': array([0.63471399, 0.67665811, 0.34287971, 0.62716925])},\n",
       "  'results_org': {'mse_score': array([0.81204962, 0.55738872, 0.42447241, 0.76265379]),\n",
       "   'mae_score': array([0.6691695 , 0.63959102, 0.6083591 , 0.64774379]),\n",
       "   'r2': array([0.13618846, 0.37557082, 0.17326266, 0.10831149]),\n",
       "   'explained_variance': array([0.35350346, 0.44386986, 0.17664918, 0.39455427]),\n",
       "   'corr': array([0.60552878, 0.68293217, 0.42214619, 0.66388455])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'PLSRegression_4_components',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.3004002571105957,\n",
       "  'fitting_time': 0.15016818046569824,\n",
       "  'results_adj': {'mse_score': array([0.99283749, 0.68320591, 0.51129344, 0.88042711]),\n",
       "   'mae_score': array([0.8049879 , 0.73842664, 0.68894711, 0.76406833]),\n",
       "   'r2': array([-0.00343896,  0.22473859, -0.06755375, -0.07096982]),\n",
       "   'explained_variance': array([ 0.25778331,  0.29950329, -0.06753554,  0.2736962 ]),\n",
       "   'corr': array([0.50966098, 0.55561882, 0.0742507 , 0.52674345])},\n",
       "  'results_org': {'mse_score': array([0.99283749, 0.68320591, 0.51129345, 0.88042708]),\n",
       "   'mae_score': array([0.80498791, 0.73842664, 0.68894712, 0.76406832]),\n",
       "   'r2': array([-0.05612325,  0.23462085,  0.00416286, -0.02938806]),\n",
       "   'explained_variance': array([0.21881416, 0.30843253, 0.00417985, 0.30189586]),\n",
       "   'corr': array([0.46922857, 0.57093376, 0.17716915, 0.57292837])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'TabNetRegressor_default',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.3759474754333496,\n",
       "  'fitting_time': 13.77210783958435,\n",
       "  'results_adj': {'mse_score': array([0.61824897, 0.61184618, 0.36866036, 0.57763236]),\n",
       "   'mae_score': array([0.69107406, 0.60773177, 0.5361999 , 0.59462053]),\n",
       "   'r2': array([0.3751494 , 0.30571336, 0.23025659, 0.297356  ]),\n",
       "   'explained_variance': array([0.56567234, 0.38915553, 0.23426406, 0.55584824]),\n",
       "   'corr': array([0.77300748, 0.67628222, 0.58077844, 0.81923406])},\n",
       "  'results_org': {'mse_score': array([0.61824897, 0.61184618, 0.36866037, 0.57763234]),\n",
       "   'mae_score': array([0.69107407, 0.60773177, 0.53619991, 0.59462053]),\n",
       "   'r2': array([0.34234241, 0.31456344, 0.28196676, 0.32463705]),\n",
       "   'explained_variance': array([0.54286851, 0.39694198, 0.28570502, 0.57309301]),\n",
       "   'corr': array([0.76293555, 0.67836772, 0.73113403, 0.85040194])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'TabNetRegressor_custom',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.4543991088867188,\n",
       "  'fitting_time': 13.39520812034607,\n",
       "  'results_adj': {'mse_score': array([1.07617402, 1.31252905, 0.77527955, 1.0442195 ]),\n",
       "   'mae_score': array([0.76465789, 0.96862147, 0.76452422, 0.76252167]),\n",
       "   'r2': array([-0.08766535, -0.48937986, -0.61874284, -0.27021028]),\n",
       "   'explained_variance': array([ 0.20827438, -0.34330108, -0.60463007,  0.30404738]),\n",
       "   'corr': array([ 0.54009087,  0.30700851, -0.06850123,  0.58642515])},\n",
       "  'results_org': {'mse_score': array([1.07617403, 1.31252906, 0.77527957, 1.04421947]),\n",
       "   'mae_score': array([0.76465789, 0.96862147, 0.76452423, 0.76252167]),\n",
       "   'r2': array([-0.14477185, -0.47039474, -0.5099982 , -0.22089277]),\n",
       "   'explained_variance': array([ 0.16670582, -0.32617802, -0.4968335 ,  0.33106863]),\n",
       "   'corr': array([0.50999118, 0.31151104, 0.0452715 , 0.59746408])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'XGBoostRegressor',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': None,\n",
       "  'results_adj': None,\n",
       "  'results_org': None},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'XGBoostRegressor_tuned',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': None,\n",
       "  'results_adj': None,\n",
       "  'results_org': None}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_results_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models only on MRI features to compare performances\n",
    "\n",
    "## Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = list(df_X.isna().any(axis=1))\n",
    "idx_test = list(~df_X.isna().any(axis=1))\n",
    "\n",
    "set_intersect_rid = set(df_all[idx_train].RID).intersection(set(df_all[idx_test].RID))\n",
    "intersect_rid_idx = df_all.RID.isin(set_intersect_rid)\n",
    "\n",
    "for i, bool_test in enumerate(idx_test): \n",
    "    if intersect_rid_idx.iloc[i] & bool_test:\n",
    "        idx_test[i] = False\n",
    "        idx_train[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]] = df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train = df_X[dict_select[\"MRIth\"]].loc[idx_train]\n",
    "df_X_test = df_X[dict_select[\"MRIth\"]].loc[idx_test]\n",
    "\n",
    "df_y_train = df_y.loc[idx_train]\n",
    "df_y_test = df_y.loc[idx_test]\n",
    "\n",
    "c_train = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_train]\n",
    "c_test = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: LinearRegression\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskElasticNet\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskElasticNet_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskLasso\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskLasso_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: RandomForestRegressor\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: XGBoostRegressor\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: XGBoostRegressor_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetRegressor_default\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetRegressor_custom\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: PLSRegression_4_components\n",
      "Combinations of preprocessing and models to test : 11\n"
     ]
    }
   ],
   "source": [
    "random_state=42\n",
    "n_imputation_iter = 10\n",
    "\n",
    "# Continuous Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "continuous_imputer_list = [\n",
    "    (\"NoImputer\", KNNImputer(n_neighbors=1)),\n",
    "\n",
    "]\n",
    "\n",
    "# Ordinal Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "ordinal_imputer_list = [\n",
    "    (\"NoImputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "]\n",
    "\n",
    "# Predictive Models List (list of tuples with unique strings and corresponding instances)\n",
    "predictive_models_list = [\n",
    "    (\"LinearRegression\", LinearRegression()),\n",
    "    (\"MultiTaskElasticNet\", MultiTaskElasticNet()),\n",
    "    (\"MultiTaskElasticNet_tuned\", MultiTaskElasticNet(**{'alpha': 0.01, 'l1_ratio': 0.01})),\n",
    "    (\"MultiTaskLasso\", MultiTaskLasso()),\n",
    "    (\"MultiTaskLasso_tuned\", MultiTaskLasso(**{'alpha': 0.001})),\n",
    "    (\"RandomForestRegressor\", RandomForestRegressor()),\n",
    "    (\"XGBoostRegressor\", XGBoostRegressor()),\n",
    "    (\"XGBoostRegressor_tuned\", XGBoostRegressor(**{'colsample_bytree': 0.5079831261101071, 'learning_rate': 0.0769592094304232, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.8049983288913105})),\n",
    "    (\"TabNetRegressor_default\", TabNetModelWrapper(n_a=8, n_d=8)),\n",
    "    (\"TabNetRegressor_custom\", TabNetModelWrapper(n_a=32, n_d=32)),\n",
    "    (\"PLSRegression_4_components\", PLSRegression(n_components=4))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['APOE_epsilon2', 'APOE_epsilon3', 'APOE_epsilon4']\n",
    "continuous_features = [col for col in df_X_train.columns if col not in ordinal_features]\n",
    "\n",
    "# Prepare Tabular configurations (shared for all PyTorch models)\n",
    "data_config = DataConfig(\n",
    "    target=df_y_train.columns.tolist(),\n",
    "    continuous_cols=continuous_features,\n",
    "    categorical_cols=[]\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024, max_epochs=1, auto_lr_find=False,\n",
    "    early_stopping=\"valid_loss\", early_stopping_mode=\"min\", early_stopping_patience=5,\n",
    "    checkpoints=\"valid_loss\", load_best=True, progress_bar=\"nones\",\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "head_config = LinearHeadConfig(dropout=0.1).__dict__\n",
    "\n",
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabNetModelConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "# Display all combinations\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    print(f\"Continuous Imputer: {continuous_imputer[0]}, Ordinal Imputer: {ordinal_imputer[0]}, Model: {model[0]}\")\n",
    "\n",
    "print(f\"Combinations of preprocessing and models to test : {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HDF5 file\n",
    "results_file = '../pickle/training_2_dict_results.pickle'\n",
    "\n",
    "with open(results_file, \"rb\") as input_file:\n",
    "    all_dict_results = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "epoch 0  | loss: 3.13311 |  0:00:00s\n",
      "epoch 1  | loss: 1.67434 |  0:00:00s\n",
      "epoch 2  | loss: 1.25121 |  0:00:00s\n",
      "epoch 3  | loss: 1.15286 |  0:00:00s\n",
      "epoch 4  | loss: 1.05784 |  0:00:00s\n",
      "epoch 5  | loss: 0.96523 |  0:00:00s\n",
      "epoch 6  | loss: 0.92765 |  0:00:00s\n",
      "epoch 7  | loss: 0.89131 |  0:00:00s\n",
      "epoch 8  | loss: 0.86607 |  0:00:00s\n",
      "epoch 9  | loss: 0.82915 |  0:00:00s\n",
      "epoch 10 | loss: 0.83506 |  0:00:00s\n",
      "epoch 11 | loss: 0.7886  |  0:00:00s\n",
      "epoch 12 | loss: 0.75816 |  0:00:00s\n",
      "epoch 13 | loss: 0.76323 |  0:00:00s\n",
      "epoch 14 | loss: 0.76212 |  0:00:00s\n",
      "epoch 15 | loss: 0.75083 |  0:00:00s\n",
      "epoch 16 | loss: 0.72542 |  0:00:00s\n",
      "epoch 17 | loss: 0.71856 |  0:00:00s\n",
      "epoch 18 | loss: 0.71925 |  0:00:01s\n",
      "epoch 19 | loss: 0.70533 |  0:00:01s\n",
      "epoch 20 | loss: 0.70061 |  0:00:01s\n",
      "epoch 21 | loss: 0.69113 |  0:00:01s\n",
      "epoch 22 | loss: 0.67685 |  0:00:01s\n",
      "epoch 23 | loss: 0.67698 |  0:00:01s\n",
      "epoch 24 | loss: 0.67197 |  0:00:01s\n",
      "epoch 25 | loss: 0.66981 |  0:00:01s\n",
      "epoch 26 | loss: 0.66185 |  0:00:01s\n",
      "epoch 27 | loss: 0.65994 |  0:00:01s\n",
      "epoch 28 | loss: 0.65575 |  0:00:01s\n",
      "epoch 29 | loss: 0.65478 |  0:00:01s\n",
      "epoch 30 | loss: 0.64765 |  0:00:01s\n",
      "epoch 31 | loss: 0.64554 |  0:00:01s\n",
      "epoch 32 | loss: 0.63432 |  0:00:01s\n",
      "epoch 33 | loss: 0.62939 |  0:00:01s\n",
      "epoch 34 | loss: 0.62534 |  0:00:01s\n",
      "epoch 35 | loss: 0.62469 |  0:00:01s\n",
      "epoch 36 | loss: 0.62174 |  0:00:01s\n",
      "epoch 37 | loss: 0.61922 |  0:00:01s\n",
      "epoch 38 | loss: 0.62018 |  0:00:02s\n",
      "epoch 39 | loss: 0.62086 |  0:00:02s\n",
      "epoch 40 | loss: 0.60617 |  0:00:02s\n",
      "epoch 41 | loss: 0.60947 |  0:00:02s\n",
      "epoch 42 | loss: 0.59172 |  0:00:02s\n",
      "epoch 43 | loss: 0.58443 |  0:00:02s\n",
      "epoch 44 | loss: 0.58781 |  0:00:02s\n",
      "epoch 45 | loss: 0.57683 |  0:00:02s\n",
      "epoch 46 | loss: 0.57306 |  0:00:02s\n",
      "epoch 47 | loss: 0.57694 |  0:00:02s\n",
      "epoch 48 | loss: 0.56855 |  0:00:02s\n",
      "epoch 49 | loss: 0.56316 |  0:00:02s\n",
      "epoch 50 | loss: 0.56719 |  0:00:02s\n",
      "epoch 51 | loss: 0.56633 |  0:00:02s\n",
      "epoch 52 | loss: 0.55997 |  0:00:02s\n",
      "epoch 53 | loss: 0.56786 |  0:00:02s\n",
      "epoch 54 | loss: 0.55522 |  0:00:02s\n",
      "epoch 55 | loss: 0.55718 |  0:00:02s\n",
      "epoch 56 | loss: 0.55059 |  0:00:02s\n",
      "epoch 57 | loss: 0.55296 |  0:00:02s\n",
      "epoch 58 | loss: 0.55163 |  0:00:03s\n",
      "epoch 59 | loss: 0.54834 |  0:00:03s\n",
      "epoch 60 | loss: 0.55297 |  0:00:03s\n",
      "epoch 61 | loss: 0.5449  |  0:00:03s\n",
      "epoch 62 | loss: 0.5401  |  0:00:03s\n",
      "epoch 63 | loss: 0.53168 |  0:00:03s\n",
      "epoch 64 | loss: 0.52247 |  0:00:03s\n",
      "epoch 65 | loss: 0.52582 |  0:00:03s\n",
      "epoch 66 | loss: 0.51292 |  0:00:03s\n",
      "epoch 67 | loss: 0.51423 |  0:00:03s\n",
      "epoch 68 | loss: 0.50964 |  0:00:03s\n",
      "epoch 69 | loss: 0.50876 |  0:00:03s\n",
      "epoch 70 | loss: 0.50005 |  0:00:03s\n",
      "epoch 71 | loss: 0.50396 |  0:00:03s\n",
      "epoch 72 | loss: 0.49637 |  0:00:03s\n",
      "epoch 73 | loss: 0.49309 |  0:00:03s\n",
      "epoch 74 | loss: 0.48867 |  0:00:03s\n",
      "epoch 75 | loss: 0.48842 |  0:00:03s\n",
      "epoch 76 | loss: 0.48183 |  0:00:03s\n",
      "epoch 77 | loss: 0.48301 |  0:00:04s\n",
      "epoch 78 | loss: 0.48205 |  0:00:04s\n",
      "epoch 79 | loss: 0.48052 |  0:00:04s\n",
      "epoch 80 | loss: 0.47403 |  0:00:04s\n",
      "epoch 81 | loss: 0.48338 |  0:00:04s\n",
      "epoch 82 | loss: 0.47462 |  0:00:04s\n",
      "epoch 83 | loss: 0.47119 |  0:00:04s\n",
      "epoch 84 | loss: 0.47134 |  0:00:04s\n",
      "epoch 85 | loss: 0.4746  |  0:00:04s\n",
      "epoch 86 | loss: 0.47936 |  0:00:04s\n",
      "epoch 87 | loss: 0.48048 |  0:00:04s\n",
      "epoch 88 | loss: 0.46815 |  0:00:04s\n",
      "epoch 89 | loss: 0.47599 |  0:00:04s\n",
      "epoch 90 | loss: 0.46779 |  0:00:04s\n",
      "epoch 91 | loss: 0.46429 |  0:00:04s\n",
      "epoch 92 | loss: 0.46651 |  0:00:04s\n",
      "epoch 93 | loss: 0.46411 |  0:00:04s\n",
      "epoch 94 | loss: 0.45887 |  0:00:04s\n",
      "epoch 95 | loss: 0.46711 |  0:00:04s\n",
      "epoch 96 | loss: 0.45915 |  0:00:04s\n",
      "epoch 97 | loss: 0.46154 |  0:00:04s\n",
      "epoch 98 | loss: 0.45802 |  0:00:04s\n",
      "epoch 99 | loss: 0.45159 |  0:00:04s\n",
      "epoch 100| loss: 0.45073 |  0:00:05s\n",
      "epoch 101| loss: 0.45322 |  0:00:05s\n",
      "epoch 102| loss: 0.44542 |  0:00:05s\n",
      "epoch 103| loss: 0.44681 |  0:00:05s\n",
      "epoch 104| loss: 0.44443 |  0:00:05s\n",
      "epoch 105| loss: 0.44417 |  0:00:05s\n",
      "epoch 106| loss: 0.44086 |  0:00:05s\n",
      "epoch 107| loss: 0.44396 |  0:00:05s\n",
      "epoch 108| loss: 0.43298 |  0:00:05s\n",
      "epoch 109| loss: 0.44147 |  0:00:05s\n",
      "epoch 110| loss: 0.42825 |  0:00:05s\n",
      "epoch 111| loss: 0.43181 |  0:00:05s\n",
      "epoch 112| loss: 0.43651 |  0:00:05s\n",
      "epoch 113| loss: 0.42791 |  0:00:05s\n",
      "epoch 114| loss: 0.43285 |  0:00:05s\n",
      "epoch 115| loss: 0.43182 |  0:00:05s\n",
      "epoch 116| loss: 0.4306  |  0:00:05s\n",
      "epoch 117| loss: 0.42956 |  0:00:05s\n",
      "epoch 118| loss: 0.42473 |  0:00:05s\n",
      "epoch 119| loss: 0.42655 |  0:00:05s\n",
      "epoch 120| loss: 0.42597 |  0:00:05s\n",
      "epoch 121| loss: 0.41854 |  0:00:05s\n",
      "epoch 122| loss: 0.41561 |  0:00:06s\n",
      "epoch 123| loss: 0.41897 |  0:00:06s\n",
      "epoch 124| loss: 0.41393 |  0:00:06s\n",
      "epoch 125| loss: 0.41506 |  0:00:06s\n",
      "epoch 126| loss: 0.4127  |  0:00:06s\n",
      "epoch 127| loss: 0.41012 |  0:00:06s\n",
      "epoch 128| loss: 0.42201 |  0:00:06s\n",
      "epoch 129| loss: 0.41418 |  0:00:06s\n",
      "epoch 130| loss: 0.4124  |  0:00:06s\n",
      "epoch 131| loss: 0.40676 |  0:00:06s\n",
      "epoch 132| loss: 0.40992 |  0:00:06s\n",
      "epoch 133| loss: 0.41542 |  0:00:06s\n",
      "epoch 134| loss: 0.411   |  0:00:06s\n",
      "epoch 135| loss: 0.40383 |  0:00:06s\n",
      "epoch 136| loss: 0.40702 |  0:00:06s\n",
      "epoch 137| loss: 0.41123 |  0:00:06s\n",
      "epoch 138| loss: 0.40235 |  0:00:06s\n",
      "epoch 139| loss: 0.41131 |  0:00:06s\n",
      "epoch 140| loss: 0.40156 |  0:00:06s\n",
      "epoch 141| loss: 0.40275 |  0:00:06s\n",
      "epoch 142| loss: 0.40435 |  0:00:06s\n",
      "epoch 143| loss: 0.39838 |  0:00:06s\n",
      "epoch 144| loss: 0.39697 |  0:00:07s\n",
      "epoch 145| loss: 0.40627 |  0:00:07s\n",
      "epoch 146| loss: 0.39956 |  0:00:07s\n",
      "epoch 147| loss: 0.39254 |  0:00:07s\n",
      "epoch 148| loss: 0.39673 |  0:00:07s\n",
      "epoch 149| loss: 0.39021 |  0:00:07s\n",
      "epoch 150| loss: 0.38701 |  0:00:07s\n",
      "epoch 151| loss: 0.39155 |  0:00:07s\n",
      "epoch 152| loss: 0.38715 |  0:00:07s\n",
      "epoch 153| loss: 0.38539 |  0:00:07s\n",
      "epoch 154| loss: 0.3805  |  0:00:07s\n",
      "epoch 155| loss: 0.38658 |  0:00:07s\n",
      "epoch 156| loss: 0.38244 |  0:00:07s\n",
      "epoch 157| loss: 0.38939 |  0:00:07s\n",
      "epoch 158| loss: 0.38604 |  0:00:07s\n",
      "epoch 159| loss: 0.38263 |  0:00:07s\n",
      "epoch 160| loss: 0.383   |  0:00:07s\n",
      "epoch 161| loss: 0.38275 |  0:00:07s\n",
      "epoch 162| loss: 0.3747  |  0:00:07s\n",
      "epoch 163| loss: 0.38457 |  0:00:08s\n",
      "epoch 164| loss: 0.38214 |  0:00:08s\n",
      "epoch 165| loss: 0.38842 |  0:00:08s\n",
      "epoch 166| loss: 0.37563 |  0:00:08s\n",
      "epoch 167| loss: 0.38946 |  0:00:08s\n",
      "epoch 168| loss: 0.39004 |  0:00:08s\n",
      "epoch 169| loss: 0.38555 |  0:00:08s\n",
      "epoch 170| loss: 0.38699 |  0:00:08s\n",
      "epoch 171| loss: 0.38251 |  0:00:08s\n",
      "epoch 172| loss: 0.37322 |  0:00:08s\n",
      "epoch 173| loss: 0.37461 |  0:00:08s\n",
      "epoch 174| loss: 0.37934 |  0:00:08s\n",
      "epoch 175| loss: 0.37561 |  0:00:08s\n",
      "epoch 176| loss: 0.37233 |  0:00:08s\n",
      "epoch 177| loss: 0.36703 |  0:00:08s\n",
      "epoch 178| loss: 0.36985 |  0:00:08s\n",
      "epoch 179| loss: 0.37102 |  0:00:08s\n",
      "epoch 180| loss: 0.37611 |  0:00:08s\n",
      "epoch 181| loss: 0.36982 |  0:00:08s\n",
      "epoch 182| loss: 0.37385 |  0:00:08s\n",
      "epoch 183| loss: 0.36204 |  0:00:08s\n",
      "epoch 184| loss: 0.36449 |  0:00:08s\n",
      "epoch 185| loss: 0.36274 |  0:00:09s\n",
      "epoch 186| loss: 0.3675  |  0:00:09s\n",
      "epoch 187| loss: 0.37158 |  0:00:09s\n",
      "epoch 188| loss: 0.36024 |  0:00:09s\n",
      "epoch 189| loss: 0.36222 |  0:00:09s\n",
      "epoch 190| loss: 0.36547 |  0:00:09s\n",
      "epoch 191| loss: 0.35913 |  0:00:09s\n",
      "epoch 192| loss: 0.37019 |  0:00:09s\n",
      "epoch 193| loss: 0.3661  |  0:00:09s\n",
      "epoch 194| loss: 0.36435 |  0:00:09s\n",
      "epoch 195| loss: 0.3665  |  0:00:09s\n",
      "epoch 196| loss: 0.36435 |  0:00:09s\n",
      "epoch 197| loss: 0.36708 |  0:00:09s\n",
      "epoch 198| loss: 0.37635 |  0:00:09s\n",
      "epoch 199| loss: 0.36185 |  0:00:09s\n",
      "epoch 200| loss: 0.372   |  0:00:09s\n",
      "epoch 201| loss: 0.36781 |  0:00:09s\n",
      "epoch 202| loss: 0.37538 |  0:00:09s\n",
      "epoch 203| loss: 0.39584 |  0:00:09s\n",
      "epoch 204| loss: 0.40129 |  0:00:09s\n",
      "epoch 205| loss: 0.39697 |  0:00:09s\n",
      "epoch 206| loss: 0.39629 |  0:00:09s\n",
      "epoch 207| loss: 0.38705 |  0:00:10s\n",
      "epoch 208| loss: 0.38361 |  0:00:10s\n",
      "epoch 209| loss: 0.37977 |  0:00:10s\n",
      "epoch 210| loss: 0.3787  |  0:00:10s\n",
      "epoch 211| loss: 0.37001 |  0:00:10s\n",
      "epoch 212| loss: 0.3723  |  0:00:10s\n",
      "epoch 213| loss: 0.37208 |  0:00:10s\n",
      "epoch 214| loss: 0.36534 |  0:00:10s\n",
      "epoch 215| loss: 0.37599 |  0:00:10s\n",
      "epoch 216| loss: 0.35701 |  0:00:10s\n",
      "epoch 217| loss: 0.36111 |  0:00:10s\n",
      "epoch 218| loss: 0.35919 |  0:00:10s\n",
      "epoch 219| loss: 0.36595 |  0:00:10s\n",
      "epoch 220| loss: 0.35637 |  0:00:10s\n",
      "epoch 221| loss: 0.36044 |  0:00:10s\n",
      "epoch 222| loss: 0.34806 |  0:00:10s\n",
      "epoch 223| loss: 0.35702 |  0:00:10s\n",
      "epoch 224| loss: 0.35781 |  0:00:10s\n",
      "epoch 225| loss: 0.35377 |  0:00:10s\n",
      "epoch 226| loss: 0.35655 |  0:00:10s\n",
      "epoch 227| loss: 0.35704 |  0:00:10s\n",
      "epoch 228| loss: 0.34493 |  0:00:10s\n",
      "epoch 229| loss: 0.35773 |  0:00:10s\n",
      "epoch 230| loss: 0.34637 |  0:00:11s\n",
      "epoch 231| loss: 0.34904 |  0:00:11s\n",
      "epoch 232| loss: 0.34231 |  0:00:11s\n",
      "epoch 233| loss: 0.34362 |  0:00:11s\n",
      "epoch 234| loss: 0.34797 |  0:00:11s\n",
      "epoch 235| loss: 0.34678 |  0:00:11s\n",
      "epoch 236| loss: 0.34557 |  0:00:11s\n",
      "epoch 237| loss: 0.34948 |  0:00:11s\n",
      "epoch 238| loss: 0.34857 |  0:00:11s\n",
      "epoch 239| loss: 0.35335 |  0:00:11s\n",
      "epoch 240| loss: 0.34921 |  0:00:11s\n",
      "epoch 241| loss: 0.34684 |  0:00:11s\n",
      "epoch 242| loss: 0.34874 |  0:00:11s\n",
      "epoch 243| loss: 0.3433  |  0:00:11s\n",
      "epoch 244| loss: 0.34147 |  0:00:11s\n",
      "epoch 245| loss: 0.3383  |  0:00:11s\n",
      "epoch 246| loss: 0.34105 |  0:00:11s\n",
      "epoch 247| loss: 0.34444 |  0:00:11s\n",
      "epoch 248| loss: 0.34859 |  0:00:11s\n",
      "epoch 249| loss: 0.34221 |  0:00:11s\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "epoch 0  | loss: 4.24287 |  0:00:00s\n",
      "epoch 1  | loss: 2.15244 |  0:00:00s\n",
      "epoch 2  | loss: 1.58292 |  0:00:00s\n",
      "epoch 3  | loss: 1.26691 |  0:00:00s\n",
      "epoch 4  | loss: 1.06626 |  0:00:00s\n",
      "epoch 5  | loss: 0.9529  |  0:00:00s\n",
      "epoch 6  | loss: 0.88656 |  0:00:00s\n",
      "epoch 7  | loss: 0.84019 |  0:00:00s\n",
      "epoch 8  | loss: 0.79465 |  0:00:00s\n",
      "epoch 9  | loss: 0.76328 |  0:00:00s\n",
      "epoch 10 | loss: 0.72436 |  0:00:00s\n",
      "epoch 11 | loss: 0.69744 |  0:00:00s\n",
      "epoch 12 | loss: 0.69848 |  0:00:00s\n",
      "epoch 13 | loss: 0.68787 |  0:00:00s\n",
      "epoch 14 | loss: 0.67379 |  0:00:00s\n",
      "epoch 15 | loss: 0.67166 |  0:00:00s\n",
      "epoch 16 | loss: 0.65451 |  0:00:00s\n",
      "epoch 17 | loss: 0.66407 |  0:00:00s\n",
      "epoch 18 | loss: 0.65599 |  0:00:00s\n",
      "epoch 19 | loss: 0.65139 |  0:00:00s\n",
      "epoch 20 | loss: 0.64927 |  0:00:01s\n",
      "epoch 21 | loss: 0.64578 |  0:00:01s\n",
      "epoch 22 | loss: 0.63364 |  0:00:01s\n",
      "epoch 23 | loss: 0.62991 |  0:00:01s\n",
      "epoch 24 | loss: 0.62301 |  0:00:01s\n",
      "epoch 25 | loss: 0.62647 |  0:00:01s\n",
      "epoch 26 | loss: 0.61679 |  0:00:01s\n",
      "epoch 27 | loss: 0.60603 |  0:00:01s\n",
      "epoch 28 | loss: 0.59713 |  0:00:01s\n",
      "epoch 29 | loss: 0.59047 |  0:00:01s\n",
      "epoch 30 | loss: 0.58662 |  0:00:01s\n",
      "epoch 31 | loss: 0.59503 |  0:00:01s\n",
      "epoch 32 | loss: 0.58066 |  0:00:01s\n",
      "epoch 33 | loss: 0.5762  |  0:00:01s\n",
      "epoch 34 | loss: 0.57702 |  0:00:01s\n",
      "epoch 35 | loss: 0.5748  |  0:00:01s\n",
      "epoch 36 | loss: 0.58111 |  0:00:01s\n",
      "epoch 37 | loss: 0.56751 |  0:00:01s\n",
      "epoch 38 | loss: 0.56548 |  0:00:01s\n",
      "epoch 39 | loss: 0.56671 |  0:00:01s\n",
      "epoch 40 | loss: 0.54826 |  0:00:02s\n",
      "epoch 41 | loss: 0.55204 |  0:00:02s\n",
      "epoch 42 | loss: 0.54543 |  0:00:02s\n",
      "epoch 43 | loss: 0.54748 |  0:00:02s\n",
      "epoch 44 | loss: 0.53076 |  0:00:02s\n",
      "epoch 45 | loss: 0.534   |  0:00:02s\n",
      "epoch 46 | loss: 0.52653 |  0:00:02s\n",
      "epoch 47 | loss: 0.51791 |  0:00:02s\n",
      "epoch 48 | loss: 0.52555 |  0:00:02s\n",
      "epoch 49 | loss: 0.51958 |  0:00:02s\n",
      "epoch 50 | loss: 0.51854 |  0:00:02s\n",
      "epoch 51 | loss: 0.52509 |  0:00:02s\n",
      "epoch 52 | loss: 0.53795 |  0:00:02s\n",
      "epoch 53 | loss: 0.51252 |  0:00:02s\n",
      "epoch 54 | loss: 0.52148 |  0:00:02s\n",
      "epoch 55 | loss: 0.50706 |  0:00:02s\n",
      "epoch 56 | loss: 0.50415 |  0:00:02s\n",
      "epoch 57 | loss: 0.50179 |  0:00:02s\n",
      "epoch 58 | loss: 0.5014  |  0:00:02s\n",
      "epoch 59 | loss: 0.496   |  0:00:02s\n",
      "epoch 60 | loss: 0.49581 |  0:00:03s\n",
      "epoch 61 | loss: 0.49195 |  0:00:03s\n",
      "epoch 62 | loss: 0.49182 |  0:00:03s\n",
      "epoch 63 | loss: 0.48621 |  0:00:03s\n",
      "epoch 64 | loss: 0.48535 |  0:00:03s\n",
      "epoch 65 | loss: 0.48092 |  0:00:03s\n",
      "epoch 66 | loss: 0.48223 |  0:00:03s\n",
      "epoch 67 | loss: 0.47486 |  0:00:03s\n",
      "epoch 68 | loss: 0.48263 |  0:00:03s\n",
      "epoch 69 | loss: 0.46807 |  0:00:03s\n",
      "epoch 70 | loss: 0.47951 |  0:00:03s\n",
      "epoch 71 | loss: 0.47439 |  0:00:03s\n",
      "epoch 72 | loss: 0.46664 |  0:00:03s\n",
      "epoch 73 | loss: 0.46357 |  0:00:03s\n",
      "epoch 74 | loss: 0.45955 |  0:00:03s\n",
      "epoch 75 | loss: 0.44495 |  0:00:03s\n",
      "epoch 76 | loss: 0.45515 |  0:00:03s\n",
      "epoch 77 | loss: 0.44442 |  0:00:03s\n",
      "epoch 78 | loss: 0.44651 |  0:00:03s\n",
      "epoch 79 | loss: 0.44756 |  0:00:03s\n",
      "epoch 80 | loss: 0.43945 |  0:00:03s\n",
      "epoch 81 | loss: 0.4455  |  0:00:03s\n",
      "epoch 82 | loss: 0.42914 |  0:00:04s\n",
      "epoch 83 | loss: 0.42907 |  0:00:04s\n",
      "epoch 84 | loss: 0.42916 |  0:00:04s\n",
      "epoch 85 | loss: 0.43479 |  0:00:04s\n",
      "epoch 86 | loss: 0.4282  |  0:00:04s\n",
      "epoch 87 | loss: 0.43356 |  0:00:04s\n",
      "epoch 88 | loss: 0.4317  |  0:00:04s\n",
      "epoch 89 | loss: 0.42938 |  0:00:04s\n",
      "epoch 90 | loss: 0.42696 |  0:00:04s\n",
      "epoch 91 | loss: 0.43679 |  0:00:04s\n",
      "epoch 92 | loss: 0.43223 |  0:00:04s\n",
      "epoch 93 | loss: 0.43293 |  0:00:04s\n",
      "epoch 94 | loss: 0.43471 |  0:00:04s\n",
      "epoch 95 | loss: 0.43117 |  0:00:04s\n",
      "epoch 96 | loss: 0.43198 |  0:00:04s\n",
      "epoch 97 | loss: 0.42767 |  0:00:04s\n",
      "epoch 98 | loss: 0.44682 |  0:00:04s\n",
      "epoch 99 | loss: 0.42731 |  0:00:04s\n",
      "epoch 100| loss: 0.42579 |  0:00:04s\n",
      "epoch 101| loss: 0.42668 |  0:00:05s\n",
      "epoch 102| loss: 0.41374 |  0:00:05s\n",
      "epoch 103| loss: 0.40874 |  0:00:05s\n",
      "epoch 104| loss: 0.41486 |  0:00:05s\n",
      "epoch 105| loss: 0.4021  |  0:00:05s\n",
      "epoch 106| loss: 0.40922 |  0:00:05s\n",
      "epoch 107| loss: 0.40808 |  0:00:05s\n",
      "epoch 108| loss: 0.4061  |  0:00:05s\n",
      "epoch 109| loss: 0.40864 |  0:00:05s\n",
      "epoch 110| loss: 0.40504 |  0:00:05s\n",
      "epoch 111| loss: 0.39976 |  0:00:05s\n",
      "epoch 112| loss: 0.40696 |  0:00:05s\n",
      "epoch 113| loss: 0.38797 |  0:00:05s\n",
      "epoch 114| loss: 0.40204 |  0:00:05s\n",
      "epoch 115| loss: 0.3983  |  0:00:05s\n",
      "epoch 116| loss: 0.4002  |  0:00:05s\n",
      "epoch 117| loss: 0.40514 |  0:00:05s\n",
      "epoch 118| loss: 0.40652 |  0:00:05s\n",
      "epoch 119| loss: 0.40779 |  0:00:05s\n",
      "epoch 120| loss: 0.41209 |  0:00:05s\n",
      "epoch 121| loss: 0.40213 |  0:00:05s\n",
      "epoch 122| loss: 0.38867 |  0:00:05s\n",
      "epoch 123| loss: 0.38918 |  0:00:06s\n",
      "epoch 124| loss: 0.39164 |  0:00:06s\n",
      "epoch 125| loss: 0.37698 |  0:00:06s\n",
      "epoch 126| loss: 0.37028 |  0:00:06s\n",
      "epoch 127| loss: 0.37927 |  0:00:06s\n",
      "epoch 128| loss: 0.36095 |  0:00:06s\n",
      "epoch 129| loss: 0.36817 |  0:00:06s\n",
      "epoch 130| loss: 0.35612 |  0:00:06s\n",
      "epoch 131| loss: 0.35326 |  0:00:06s\n",
      "epoch 132| loss: 0.35904 |  0:00:06s\n",
      "epoch 133| loss: 0.35966 |  0:00:06s\n",
      "epoch 134| loss: 0.34819 |  0:00:06s\n",
      "epoch 135| loss: 0.35239 |  0:00:06s\n",
      "epoch 136| loss: 0.35978 |  0:00:06s\n",
      "epoch 137| loss: 0.35151 |  0:00:06s\n",
      "epoch 138| loss: 0.36372 |  0:00:06s\n",
      "epoch 139| loss: 0.36289 |  0:00:06s\n",
      "epoch 140| loss: 0.36773 |  0:00:06s\n",
      "epoch 141| loss: 0.36356 |  0:00:06s\n",
      "epoch 142| loss: 0.35889 |  0:00:06s\n",
      "epoch 143| loss: 0.36573 |  0:00:06s\n",
      "epoch 144| loss: 0.36685 |  0:00:07s\n",
      "epoch 145| loss: 0.36418 |  0:00:07s\n",
      "epoch 146| loss: 0.37643 |  0:00:07s\n",
      "epoch 147| loss: 0.36169 |  0:00:07s\n",
      "epoch 148| loss: 0.3599  |  0:00:07s\n",
      "epoch 149| loss: 0.36358 |  0:00:07s\n",
      "epoch 150| loss: 0.38092 |  0:00:07s\n",
      "epoch 151| loss: 0.37406 |  0:00:07s\n",
      "epoch 152| loss: 0.36953 |  0:00:07s\n",
      "epoch 153| loss: 0.37239 |  0:00:07s\n",
      "epoch 154| loss: 0.36479 |  0:00:07s\n",
      "epoch 155| loss: 0.36082 |  0:00:07s\n",
      "epoch 156| loss: 0.35538 |  0:00:07s\n",
      "epoch 157| loss: 0.34878 |  0:00:07s\n",
      "epoch 158| loss: 0.34607 |  0:00:07s\n",
      "epoch 159| loss: 0.34139 |  0:00:07s\n",
      "epoch 160| loss: 0.33437 |  0:00:07s\n",
      "epoch 161| loss: 0.33563 |  0:00:07s\n",
      "epoch 162| loss: 0.34112 |  0:00:07s\n",
      "epoch 163| loss: 0.35652 |  0:00:07s\n",
      "epoch 164| loss: 0.35128 |  0:00:07s\n",
      "epoch 165| loss: 0.34045 |  0:00:07s\n",
      "epoch 166| loss: 0.34459 |  0:00:08s\n",
      "epoch 167| loss: 0.34769 |  0:00:08s\n",
      "epoch 168| loss: 0.33172 |  0:00:08s\n",
      "epoch 169| loss: 0.33832 |  0:00:08s\n",
      "epoch 170| loss: 0.32454 |  0:00:08s\n",
      "epoch 171| loss: 0.33092 |  0:00:08s\n",
      "epoch 172| loss: 0.33065 |  0:00:08s\n",
      "epoch 173| loss: 0.31971 |  0:00:08s\n",
      "epoch 174| loss: 0.31975 |  0:00:08s\n",
      "epoch 175| loss: 0.30903 |  0:00:08s\n",
      "epoch 176| loss: 0.31415 |  0:00:08s\n",
      "epoch 177| loss: 0.32472 |  0:00:08s\n",
      "epoch 178| loss: 0.30966 |  0:00:08s\n",
      "epoch 179| loss: 0.31315 |  0:00:08s\n",
      "epoch 180| loss: 0.31162 |  0:00:08s\n",
      "epoch 181| loss: 0.32061 |  0:00:08s\n",
      "epoch 182| loss: 0.31373 |  0:00:08s\n",
      "epoch 183| loss: 0.31775 |  0:00:08s\n",
      "epoch 184| loss: 0.31597 |  0:00:08s\n",
      "epoch 185| loss: 0.3111  |  0:00:08s\n",
      "epoch 186| loss: 0.31505 |  0:00:08s\n",
      "epoch 187| loss: 0.30957 |  0:00:08s\n",
      "epoch 188| loss: 0.31093 |  0:00:09s\n",
      "epoch 189| loss: 0.31486 |  0:00:09s\n",
      "epoch 190| loss: 0.31301 |  0:00:09s\n",
      "epoch 191| loss: 0.3108  |  0:00:09s\n",
      "epoch 192| loss: 0.30916 |  0:00:09s\n",
      "epoch 193| loss: 0.30084 |  0:00:09s\n",
      "epoch 194| loss: 0.30258 |  0:00:09s\n",
      "epoch 195| loss: 0.30658 |  0:00:09s\n",
      "epoch 196| loss: 0.30231 |  0:00:09s\n",
      "epoch 197| loss: 0.29887 |  0:00:09s\n",
      "epoch 198| loss: 0.3017  |  0:00:09s\n",
      "epoch 199| loss: 0.2996  |  0:00:09s\n",
      "epoch 200| loss: 0.29747 |  0:00:09s\n",
      "epoch 201| loss: 0.302   |  0:00:09s\n",
      "epoch 202| loss: 0.29356 |  0:00:09s\n",
      "epoch 203| loss: 0.29971 |  0:00:09s\n",
      "epoch 204| loss: 0.28496 |  0:00:09s\n",
      "epoch 205| loss: 0.28985 |  0:00:09s\n",
      "epoch 206| loss: 0.28443 |  0:00:09s\n",
      "epoch 207| loss: 0.28011 |  0:00:09s\n",
      "epoch 208| loss: 0.28006 |  0:00:09s\n",
      "epoch 209| loss: 0.27741 |  0:00:10s\n",
      "epoch 210| loss: 0.27276 |  0:00:10s\n",
      "epoch 211| loss: 0.27628 |  0:00:10s\n",
      "epoch 212| loss: 0.2841  |  0:00:10s\n",
      "epoch 213| loss: 0.28351 |  0:00:10s\n",
      "epoch 214| loss: 0.28181 |  0:00:10s\n",
      "epoch 215| loss: 0.29372 |  0:00:10s\n",
      "epoch 216| loss: 0.27954 |  0:00:10s\n",
      "epoch 217| loss: 0.28504 |  0:00:10s\n",
      "epoch 218| loss: 0.281   |  0:00:10s\n",
      "epoch 219| loss: 0.28408 |  0:00:10s\n",
      "epoch 220| loss: 0.28229 |  0:00:10s\n",
      "epoch 221| loss: 0.27346 |  0:00:10s\n",
      "epoch 222| loss: 0.26955 |  0:00:10s\n",
      "epoch 223| loss: 0.27341 |  0:00:10s\n",
      "epoch 224| loss: 0.27228 |  0:00:10s\n",
      "epoch 225| loss: 0.26034 |  0:00:10s\n",
      "epoch 226| loss: 0.26504 |  0:00:10s\n",
      "epoch 227| loss: 0.26373 |  0:00:10s\n",
      "epoch 228| loss: 0.25678 |  0:00:10s\n",
      "epoch 229| loss: 0.2667  |  0:00:11s\n",
      "epoch 230| loss: 0.25775 |  0:00:11s\n",
      "epoch 231| loss: 0.26326 |  0:00:11s\n",
      "epoch 232| loss: 0.25435 |  0:00:11s\n",
      "epoch 233| loss: 0.25562 |  0:00:11s\n",
      "epoch 234| loss: 0.26014 |  0:00:11s\n",
      "epoch 235| loss: 0.2552  |  0:00:11s\n",
      "epoch 236| loss: 0.25414 |  0:00:11s\n",
      "epoch 237| loss: 0.25566 |  0:00:11s\n",
      "epoch 238| loss: 0.25705 |  0:00:11s\n",
      "epoch 239| loss: 0.25846 |  0:00:11s\n",
      "epoch 240| loss: 0.25685 |  0:00:11s\n",
      "epoch 241| loss: 0.26753 |  0:00:11s\n",
      "epoch 242| loss: 0.27538 |  0:00:11s\n",
      "epoch 243| loss: 0.27838 |  0:00:11s\n",
      "epoch 244| loss: 0.27072 |  0:00:11s\n",
      "epoch 245| loss: 0.26688 |  0:00:11s\n",
      "epoch 246| loss: 0.26624 |  0:00:11s\n",
      "epoch 247| loss: 0.26438 |  0:00:11s\n",
      "epoch 248| loss: 0.26376 |  0:00:12s\n",
      "epoch 249| loss: 0.26156 |  0:00:12s\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n"
     ]
    }
   ],
   "source": [
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    name_continuous_imputer, continuous_imputer_instance = continuous_imputer\n",
    "    name_ordinal_imputer, ordinal_imputer_instance = ordinal_imputer\n",
    "    name_model, model_instance = model\n",
    "\n",
    "    try: \n",
    "    \n",
    "        # Now you can call your `train_model` function with these components\n",
    "        dict_results = train_imputer_model(\n",
    "            df_X_train, df_X_test, df_y_train, df_y_test,\n",
    "            c_train, c_test,\n",
    "            ordinal_imputer_instance, name_ordinal_imputer,\n",
    "            continuous_imputer_instance, name_continuous_imputer,\n",
    "            model_instance, name_model,\n",
    "            separate_imputers=True  # Or however you want to specify\n",
    "        )\n",
    "\n",
    "    except Exception as e:  \n",
    "\n",
    "        print(e)\n",
    "    \n",
    "        params = {\n",
    "        \"ordinal_imputer\": name_ordinal_imputer, \n",
    "        \"continuous_imputer\": name_continuous_imputer, \n",
    "        \"model\": name_model, \"train_shape\" : df_X_train.shape, \n",
    "        \"test_shape\": df_X_test.shape\n",
    "    }\n",
    "        dict_results = {\n",
    "        \"params\": params, \n",
    "        \"imputation_time\": None,\n",
    "        \"fitting_time\": None, \n",
    "        \"results_adj\": None, \n",
    "        \"results_org\": None\n",
    "    }\n",
    "        \n",
    "    # Optionally keep the all_dict_results list updated\n",
    "    all_dict_results.append(dict_results)\n",
    "\n",
    "    # Save the updated results back to the pickle file\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(all_dict_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open(results_file, 'wb') as handle:\n",
    "    pickle.dump(all_dict_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Table for reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = \"../pickle/training_2_dict_results.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_file, \"rb\") as input_file:\n",
    "    all_dict_results = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'LinearRegression', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'MultiTaskElasticNet', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'MultiTaskElasticNet_tuned', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'MultiTaskLasso', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'MultiTaskLasso_tuned', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'RandomForestRegressor', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'XGBoostRegressor', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'XGBoostRegressor_tuned', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'TabNetRegressor_default', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'TabNetRegressor_custom', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'PLSRegression_4_components', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'GatedAdditiveTreeEnsembleConfig_tab', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'DANetConfig_tab', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'TabTransformerConfig_tab', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'TabNetModelConfig_tab', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'GatedAdditiveTreeEnsembleConfig_tab', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'DANetConfig_tab', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'TabTransformerConfig_tab', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'TabNetModelConfig_tab', (2881, 200), (13, 200)])\n"
     ]
    }
   ],
   "source": [
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabNetModelConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]\n",
    "\n",
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    name_continuous_imputer, continuous_imputer_instance = continuous_imputer\n",
    "    name_ordinal_imputer, ordinal_imputer_instance = ordinal_imputer\n",
    "    name_model, model_instance = model\n",
    "\n",
    "    params = {\n",
    "        \"ordinal_imputer\": name_ordinal_imputer, \n",
    "        \"continuous_imputer\": name_continuous_imputer, \n",
    "        \"model\": name_model, \"train_shape\" : df_X_train.shape, \n",
    "        \"test_shape\": df_X_test.shape\n",
    "    }\n",
    "\n",
    "    if any(result['params'] == params for result in all_dict_results):\n",
    "        # Skip this iteration if the combination exists\n",
    "        print(f\"Skipping existing combination: {params.values()}\")\n",
    "        \n",
    "        continue\n",
    "\n",
    "    try: \n",
    "        print(name_model)\n",
    "        \n",
    "        # Now you can call your `train_model` function with these components\n",
    "        dict_results = train_imputer_model(\n",
    "            df_X_train, df_X_test, df_y_train, df_y_test,\n",
    "            c_train, c_test,\n",
    "            ordinal_imputer_instance, name_ordinal_imputer,\n",
    "            continuous_imputer_instance, name_continuous_imputer,\n",
    "            model_instance, name_model,\n",
    "            separate_imputers=True  # Or however you want to specify\n",
    "        )\n",
    "\n",
    "    except Exception as e:  \n",
    "\n",
    "        print(e)\n",
    "    \n",
    "        dict_results = {\n",
    "        \"params\": params, \n",
    "        \"imputation_time\": None,\n",
    "        \"fitting_time\": None, \n",
    "        \"results_adj\": None, \n",
    "        \"results_org\": None\n",
    "    }\n",
    "        \n",
    "    # Optionally keep the all_dict_results list updated\n",
    "    all_dict_results.append(dict_results)\n",
    "\n",
    "        # Save the updated results back to the pickle file\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(all_dict_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_dict_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_dict_results \u001b[38;5;241m=\u001b[39m \u001b[43mclean_dict_list\u001b[49m(all_dict_results, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae_score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_dict_list' is not defined"
     ]
    }
   ],
   "source": [
    "all_dict_results = clean_dict_list(all_dict_results, metric=\"mae_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "MultiTaskElasticNet\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "MultiTaskElasticNet_tuned\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "MultiTaskLasso\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "MultiTaskLasso_tuned\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "RandomForestRegressor\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "XGBoostRegressor\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "XGBoostRegressor_tuned\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "TabNetRegressor_default\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "epoch 0  | loss: 3.13311 |  0:00:00s\n",
      "epoch 1  | loss: 1.67434 |  0:00:00s\n",
      "epoch 2  | loss: 1.25121 |  0:00:00s\n",
      "epoch 3  | loss: 1.15286 |  0:00:00s\n",
      "epoch 4  | loss: 1.05784 |  0:00:00s\n",
      "epoch 5  | loss: 0.96523 |  0:00:00s\n",
      "epoch 6  | loss: 0.92765 |  0:00:00s\n",
      "epoch 7  | loss: 0.89131 |  0:00:00s\n",
      "epoch 8  | loss: 0.86607 |  0:00:00s\n",
      "epoch 9  | loss: 0.82915 |  0:00:00s\n",
      "epoch 10 | loss: 0.83506 |  0:00:00s\n",
      "epoch 11 | loss: 0.7886  |  0:00:00s\n",
      "epoch 12 | loss: 0.75816 |  0:00:00s\n",
      "epoch 13 | loss: 0.76323 |  0:00:00s\n",
      "epoch 14 | loss: 0.76212 |  0:00:00s\n",
      "epoch 15 | loss: 0.75083 |  0:00:00s\n",
      "epoch 16 | loss: 0.72542 |  0:00:01s\n",
      "epoch 17 | loss: 0.71856 |  0:00:01s\n",
      "epoch 18 | loss: 0.71925 |  0:00:01s\n",
      "epoch 19 | loss: 0.70533 |  0:00:01s\n",
      "epoch 20 | loss: 0.70061 |  0:00:01s\n",
      "epoch 21 | loss: 0.69113 |  0:00:01s\n",
      "epoch 22 | loss: 0.67685 |  0:00:01s\n",
      "epoch 23 | loss: 0.67698 |  0:00:01s\n",
      "epoch 24 | loss: 0.67197 |  0:00:01s\n",
      "epoch 25 | loss: 0.66981 |  0:00:01s\n",
      "epoch 26 | loss: 0.66185 |  0:00:01s\n",
      "epoch 27 | loss: 0.65994 |  0:00:01s\n",
      "epoch 28 | loss: 0.65575 |  0:00:01s\n",
      "epoch 29 | loss: 0.65478 |  0:00:01s\n",
      "epoch 30 | loss: 0.64765 |  0:00:01s\n",
      "epoch 31 | loss: 0.64554 |  0:00:01s\n",
      "epoch 32 | loss: 0.63432 |  0:00:01s\n",
      "epoch 33 | loss: 0.62939 |  0:00:01s\n",
      "epoch 34 | loss: 0.62534 |  0:00:01s\n",
      "epoch 35 | loss: 0.62469 |  0:00:01s\n",
      "epoch 36 | loss: 0.62174 |  0:00:02s\n",
      "epoch 37 | loss: 0.61922 |  0:00:02s\n",
      "epoch 38 | loss: 0.62018 |  0:00:02s\n",
      "epoch 39 | loss: 0.62086 |  0:00:02s\n",
      "epoch 40 | loss: 0.60617 |  0:00:02s\n",
      "epoch 41 | loss: 0.60947 |  0:00:02s\n",
      "epoch 42 | loss: 0.59172 |  0:00:02s\n",
      "epoch 43 | loss: 0.58443 |  0:00:02s\n",
      "epoch 44 | loss: 0.58781 |  0:00:02s\n",
      "epoch 45 | loss: 0.57683 |  0:00:02s\n",
      "epoch 46 | loss: 0.57306 |  0:00:02s\n",
      "epoch 47 | loss: 0.57694 |  0:00:02s\n",
      "epoch 48 | loss: 0.56855 |  0:00:02s\n",
      "epoch 49 | loss: 0.56316 |  0:00:02s\n",
      "epoch 50 | loss: 0.56719 |  0:00:02s\n",
      "epoch 51 | loss: 0.56633 |  0:00:02s\n",
      "epoch 52 | loss: 0.55997 |  0:00:02s\n",
      "epoch 53 | loss: 0.56786 |  0:00:02s\n",
      "epoch 54 | loss: 0.55522 |  0:00:02s\n",
      "epoch 55 | loss: 0.55718 |  0:00:02s\n",
      "epoch 56 | loss: 0.55059 |  0:00:02s\n",
      "epoch 57 | loss: 0.55296 |  0:00:02s\n",
      "epoch 58 | loss: 0.55163 |  0:00:03s\n",
      "epoch 59 | loss: 0.54834 |  0:00:03s\n",
      "epoch 60 | loss: 0.55297 |  0:00:03s\n",
      "epoch 61 | loss: 0.5449  |  0:00:03s\n",
      "epoch 62 | loss: 0.5401  |  0:00:03s\n",
      "epoch 63 | loss: 0.53168 |  0:00:03s\n",
      "epoch 64 | loss: 0.52247 |  0:00:03s\n",
      "epoch 65 | loss: 0.52582 |  0:00:03s\n",
      "epoch 66 | loss: 0.51292 |  0:00:03s\n",
      "epoch 67 | loss: 0.51423 |  0:00:03s\n",
      "epoch 68 | loss: 0.50964 |  0:00:03s\n",
      "epoch 69 | loss: 0.50876 |  0:00:03s\n",
      "epoch 70 | loss: 0.50005 |  0:00:03s\n",
      "epoch 71 | loss: 0.50396 |  0:00:03s\n",
      "epoch 72 | loss: 0.49637 |  0:00:03s\n",
      "epoch 73 | loss: 0.49309 |  0:00:03s\n",
      "epoch 74 | loss: 0.48867 |  0:00:03s\n",
      "epoch 75 | loss: 0.48842 |  0:00:03s\n",
      "epoch 76 | loss: 0.48183 |  0:00:03s\n",
      "epoch 77 | loss: 0.48301 |  0:00:03s\n",
      "epoch 78 | loss: 0.48205 |  0:00:03s\n",
      "epoch 79 | loss: 0.48052 |  0:00:03s\n",
      "epoch 80 | loss: 0.47403 |  0:00:04s\n",
      "epoch 81 | loss: 0.48338 |  0:00:04s\n",
      "epoch 82 | loss: 0.47462 |  0:00:04s\n",
      "epoch 83 | loss: 0.47119 |  0:00:04s\n",
      "epoch 84 | loss: 0.47134 |  0:00:04s\n",
      "epoch 85 | loss: 0.4746  |  0:00:04s\n",
      "epoch 86 | loss: 0.47936 |  0:00:04s\n",
      "epoch 87 | loss: 0.48048 |  0:00:04s\n",
      "epoch 88 | loss: 0.46815 |  0:00:04s\n",
      "epoch 89 | loss: 0.47599 |  0:00:04s\n",
      "epoch 90 | loss: 0.46779 |  0:00:04s\n",
      "epoch 91 | loss: 0.46429 |  0:00:04s\n",
      "epoch 92 | loss: 0.46651 |  0:00:04s\n",
      "epoch 93 | loss: 0.46411 |  0:00:04s\n",
      "epoch 94 | loss: 0.45887 |  0:00:04s\n",
      "epoch 95 | loss: 0.46711 |  0:00:04s\n",
      "epoch 96 | loss: 0.45915 |  0:00:04s\n",
      "epoch 97 | loss: 0.46154 |  0:00:04s\n",
      "epoch 98 | loss: 0.45802 |  0:00:04s\n",
      "epoch 99 | loss: 0.45159 |  0:00:04s\n",
      "epoch 100| loss: 0.45073 |  0:00:04s\n",
      "epoch 101| loss: 0.45322 |  0:00:04s\n",
      "epoch 102| loss: 0.44542 |  0:00:04s\n",
      "epoch 103| loss: 0.44681 |  0:00:05s\n",
      "epoch 104| loss: 0.44443 |  0:00:05s\n",
      "epoch 105| loss: 0.44417 |  0:00:05s\n",
      "epoch 106| loss: 0.44086 |  0:00:05s\n",
      "epoch 107| loss: 0.44396 |  0:00:05s\n",
      "epoch 108| loss: 0.43298 |  0:00:05s\n",
      "epoch 109| loss: 0.44147 |  0:00:05s\n",
      "epoch 110| loss: 0.42825 |  0:00:05s\n",
      "epoch 111| loss: 0.43181 |  0:00:05s\n",
      "epoch 112| loss: 0.43651 |  0:00:05s\n",
      "epoch 113| loss: 0.42791 |  0:00:05s\n",
      "epoch 114| loss: 0.43285 |  0:00:05s\n",
      "epoch 115| loss: 0.43182 |  0:00:05s\n",
      "epoch 116| loss: 0.4306  |  0:00:05s\n",
      "epoch 117| loss: 0.42956 |  0:00:05s\n",
      "epoch 118| loss: 0.42473 |  0:00:05s\n",
      "epoch 119| loss: 0.42655 |  0:00:05s\n",
      "epoch 120| loss: 0.42597 |  0:00:05s\n",
      "epoch 121| loss: 0.41854 |  0:00:05s\n",
      "epoch 122| loss: 0.41561 |  0:00:05s\n",
      "epoch 123| loss: 0.41897 |  0:00:05s\n",
      "epoch 124| loss: 0.41393 |  0:00:05s\n",
      "epoch 125| loss: 0.41506 |  0:00:06s\n",
      "epoch 126| loss: 0.4127  |  0:00:06s\n",
      "epoch 127| loss: 0.41012 |  0:00:06s\n",
      "epoch 128| loss: 0.42201 |  0:00:06s\n",
      "epoch 129| loss: 0.41418 |  0:00:06s\n",
      "epoch 130| loss: 0.4124  |  0:00:06s\n",
      "epoch 131| loss: 0.40676 |  0:00:06s\n",
      "epoch 132| loss: 0.40992 |  0:00:06s\n",
      "epoch 133| loss: 0.41542 |  0:00:06s\n",
      "epoch 134| loss: 0.411   |  0:00:06s\n",
      "epoch 135| loss: 0.40383 |  0:00:06s\n",
      "epoch 136| loss: 0.40702 |  0:00:06s\n",
      "epoch 137| loss: 0.41123 |  0:00:06s\n",
      "epoch 138| loss: 0.40235 |  0:00:06s\n",
      "epoch 139| loss: 0.41131 |  0:00:06s\n",
      "epoch 140| loss: 0.40156 |  0:00:06s\n",
      "epoch 141| loss: 0.40275 |  0:00:06s\n",
      "epoch 142| loss: 0.40435 |  0:00:06s\n",
      "epoch 143| loss: 0.39838 |  0:00:06s\n",
      "epoch 144| loss: 0.39697 |  0:00:06s\n",
      "epoch 145| loss: 0.40627 |  0:00:06s\n",
      "epoch 146| loss: 0.39956 |  0:00:07s\n",
      "epoch 147| loss: 0.39254 |  0:00:07s\n",
      "epoch 148| loss: 0.39673 |  0:00:07s\n",
      "epoch 149| loss: 0.39021 |  0:00:07s\n",
      "epoch 150| loss: 0.38701 |  0:00:07s\n",
      "epoch 151| loss: 0.39155 |  0:00:07s\n",
      "epoch 152| loss: 0.38715 |  0:00:07s\n",
      "epoch 153| loss: 0.38539 |  0:00:07s\n",
      "epoch 154| loss: 0.3805  |  0:00:07s\n",
      "epoch 155| loss: 0.38658 |  0:00:07s\n",
      "epoch 156| loss: 0.38244 |  0:00:07s\n",
      "epoch 157| loss: 0.38939 |  0:00:07s\n",
      "epoch 158| loss: 0.38604 |  0:00:07s\n",
      "epoch 159| loss: 0.38263 |  0:00:07s\n",
      "epoch 160| loss: 0.383   |  0:00:07s\n",
      "epoch 161| loss: 0.38275 |  0:00:07s\n",
      "epoch 162| loss: 0.3747  |  0:00:07s\n",
      "epoch 163| loss: 0.38457 |  0:00:07s\n",
      "epoch 164| loss: 0.38214 |  0:00:07s\n",
      "epoch 165| loss: 0.38842 |  0:00:07s\n",
      "epoch 166| loss: 0.37563 |  0:00:07s\n",
      "epoch 167| loss: 0.38946 |  0:00:07s\n",
      "epoch 168| loss: 0.39004 |  0:00:08s\n",
      "epoch 169| loss: 0.38555 |  0:00:08s\n",
      "epoch 170| loss: 0.38699 |  0:00:08s\n",
      "epoch 171| loss: 0.38251 |  0:00:08s\n",
      "epoch 172| loss: 0.37322 |  0:00:08s\n",
      "epoch 173| loss: 0.37461 |  0:00:08s\n",
      "epoch 174| loss: 0.37934 |  0:00:08s\n",
      "epoch 175| loss: 0.37561 |  0:00:08s\n",
      "epoch 176| loss: 0.37233 |  0:00:08s\n",
      "epoch 177| loss: 0.36703 |  0:00:08s\n",
      "epoch 178| loss: 0.36985 |  0:00:08s\n",
      "epoch 179| loss: 0.37102 |  0:00:08s\n",
      "epoch 180| loss: 0.37611 |  0:00:08s\n",
      "epoch 181| loss: 0.36982 |  0:00:08s\n",
      "epoch 182| loss: 0.37385 |  0:00:08s\n",
      "epoch 183| loss: 0.36204 |  0:00:08s\n",
      "epoch 184| loss: 0.36449 |  0:00:08s\n",
      "epoch 185| loss: 0.36274 |  0:00:08s\n",
      "epoch 186| loss: 0.3675  |  0:00:08s\n",
      "epoch 187| loss: 0.37158 |  0:00:08s\n",
      "epoch 188| loss: 0.36024 |  0:00:08s\n",
      "epoch 189| loss: 0.36222 |  0:00:08s\n",
      "epoch 190| loss: 0.36547 |  0:00:09s\n",
      "epoch 191| loss: 0.35913 |  0:00:09s\n",
      "epoch 192| loss: 0.37019 |  0:00:09s\n",
      "epoch 193| loss: 0.3661  |  0:00:09s\n",
      "epoch 194| loss: 0.36435 |  0:00:09s\n",
      "epoch 195| loss: 0.3665  |  0:00:09s\n",
      "epoch 196| loss: 0.36435 |  0:00:09s\n",
      "epoch 197| loss: 0.36708 |  0:00:09s\n",
      "epoch 198| loss: 0.37635 |  0:00:09s\n",
      "epoch 199| loss: 0.36185 |  0:00:09s\n",
      "epoch 200| loss: 0.372   |  0:00:09s\n",
      "epoch 201| loss: 0.36781 |  0:00:09s\n",
      "epoch 202| loss: 0.37538 |  0:00:09s\n",
      "epoch 203| loss: 0.39584 |  0:00:09s\n",
      "epoch 204| loss: 0.40129 |  0:00:09s\n",
      "epoch 205| loss: 0.39697 |  0:00:09s\n",
      "epoch 206| loss: 0.39629 |  0:00:09s\n",
      "epoch 207| loss: 0.38705 |  0:00:09s\n",
      "epoch 208| loss: 0.38361 |  0:00:09s\n",
      "epoch 209| loss: 0.37977 |  0:00:09s\n",
      "epoch 210| loss: 0.3787  |  0:00:09s\n",
      "epoch 211| loss: 0.37001 |  0:00:09s\n",
      "epoch 212| loss: 0.3723  |  0:00:10s\n",
      "epoch 213| loss: 0.37208 |  0:00:10s\n",
      "epoch 214| loss: 0.36534 |  0:00:10s\n",
      "epoch 215| loss: 0.37599 |  0:00:10s\n",
      "epoch 216| loss: 0.35701 |  0:00:10s\n",
      "epoch 217| loss: 0.36111 |  0:00:10s\n",
      "epoch 218| loss: 0.35919 |  0:00:10s\n",
      "epoch 219| loss: 0.36595 |  0:00:10s\n",
      "epoch 220| loss: 0.35637 |  0:00:10s\n",
      "epoch 221| loss: 0.36044 |  0:00:10s\n",
      "epoch 222| loss: 0.34806 |  0:00:10s\n",
      "epoch 223| loss: 0.35702 |  0:00:10s\n",
      "epoch 224| loss: 0.35781 |  0:00:10s\n",
      "epoch 225| loss: 0.35377 |  0:00:10s\n",
      "epoch 226| loss: 0.35655 |  0:00:10s\n",
      "epoch 227| loss: 0.35704 |  0:00:10s\n",
      "epoch 228| loss: 0.34493 |  0:00:10s\n",
      "epoch 229| loss: 0.35773 |  0:00:10s\n",
      "epoch 230| loss: 0.34637 |  0:00:10s\n",
      "epoch 231| loss: 0.34904 |  0:00:10s\n",
      "epoch 232| loss: 0.34231 |  0:00:10s\n",
      "epoch 233| loss: 0.34362 |  0:00:11s\n",
      "epoch 234| loss: 0.34797 |  0:00:11s\n",
      "epoch 235| loss: 0.34678 |  0:00:11s\n",
      "epoch 236| loss: 0.34557 |  0:00:11s\n",
      "epoch 237| loss: 0.34948 |  0:00:11s\n",
      "epoch 238| loss: 0.34857 |  0:00:11s\n",
      "epoch 239| loss: 0.35335 |  0:00:11s\n",
      "epoch 240| loss: 0.34921 |  0:00:11s\n",
      "epoch 241| loss: 0.34684 |  0:00:11s\n",
      "epoch 242| loss: 0.34874 |  0:00:11s\n",
      "epoch 243| loss: 0.3433  |  0:00:11s\n",
      "epoch 244| loss: 0.34147 |  0:00:11s\n",
      "epoch 245| loss: 0.3383  |  0:00:11s\n",
      "epoch 246| loss: 0.34105 |  0:00:11s\n",
      "epoch 247| loss: 0.34444 |  0:00:11s\n",
      "epoch 248| loss: 0.34859 |  0:00:11s\n",
      "epoch 249| loss: 0.34221 |  0:00:11s\n",
      "TabNetRegressor_custom\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "epoch 0  | loss: 4.24287 |  0:00:00s\n",
      "epoch 1  | loss: 2.15244 |  0:00:00s\n",
      "epoch 2  | loss: 1.58292 |  0:00:00s\n",
      "epoch 3  | loss: 1.26691 |  0:00:00s\n",
      "epoch 4  | loss: 1.06626 |  0:00:00s\n",
      "epoch 5  | loss: 0.9529  |  0:00:00s\n",
      "epoch 6  | loss: 0.88656 |  0:00:00s\n",
      "epoch 7  | loss: 0.84019 |  0:00:00s\n",
      "epoch 8  | loss: 0.79465 |  0:00:00s\n",
      "epoch 9  | loss: 0.76328 |  0:00:00s\n",
      "epoch 10 | loss: 0.72436 |  0:00:00s\n",
      "epoch 11 | loss: 0.69744 |  0:00:00s\n",
      "epoch 12 | loss: 0.69848 |  0:00:00s\n",
      "epoch 13 | loss: 0.68787 |  0:00:00s\n",
      "epoch 14 | loss: 0.67379 |  0:00:00s\n",
      "epoch 15 | loss: 0.67166 |  0:00:00s\n",
      "epoch 16 | loss: 0.65451 |  0:00:00s\n",
      "epoch 17 | loss: 0.66407 |  0:00:00s\n",
      "epoch 18 | loss: 0.65599 |  0:00:00s\n",
      "epoch 19 | loss: 0.65139 |  0:00:00s\n",
      "epoch 20 | loss: 0.64927 |  0:00:00s\n",
      "epoch 21 | loss: 0.64578 |  0:00:01s\n",
      "epoch 22 | loss: 0.63364 |  0:00:01s\n",
      "epoch 23 | loss: 0.62991 |  0:00:01s\n",
      "epoch 24 | loss: 0.62301 |  0:00:01s\n",
      "epoch 25 | loss: 0.62647 |  0:00:01s\n",
      "epoch 26 | loss: 0.61679 |  0:00:01s\n",
      "epoch 27 | loss: 0.60603 |  0:00:01s\n",
      "epoch 28 | loss: 0.59713 |  0:00:01s\n",
      "epoch 29 | loss: 0.59047 |  0:00:01s\n",
      "epoch 30 | loss: 0.58662 |  0:00:01s\n",
      "epoch 31 | loss: 0.59503 |  0:00:01s\n",
      "epoch 32 | loss: 0.58066 |  0:00:01s\n",
      "epoch 33 | loss: 0.5762  |  0:00:01s\n",
      "epoch 34 | loss: 0.57702 |  0:00:01s\n",
      "epoch 35 | loss: 0.5748  |  0:00:01s\n",
      "epoch 36 | loss: 0.58111 |  0:00:01s\n",
      "epoch 37 | loss: 0.56751 |  0:00:01s\n",
      "epoch 38 | loss: 0.56548 |  0:00:01s\n",
      "epoch 39 | loss: 0.56671 |  0:00:01s\n",
      "epoch 40 | loss: 0.54826 |  0:00:01s\n",
      "epoch 41 | loss: 0.55204 |  0:00:01s\n",
      "epoch 42 | loss: 0.54543 |  0:00:02s\n",
      "epoch 43 | loss: 0.54748 |  0:00:02s\n",
      "epoch 44 | loss: 0.53076 |  0:00:02s\n",
      "epoch 45 | loss: 0.534   |  0:00:02s\n",
      "epoch 46 | loss: 0.52653 |  0:00:02s\n",
      "epoch 47 | loss: 0.51791 |  0:00:02s\n",
      "epoch 48 | loss: 0.52555 |  0:00:02s\n",
      "epoch 49 | loss: 0.51958 |  0:00:02s\n",
      "epoch 50 | loss: 0.51854 |  0:00:02s\n",
      "epoch 51 | loss: 0.52509 |  0:00:02s\n",
      "epoch 52 | loss: 0.53795 |  0:00:02s\n",
      "epoch 53 | loss: 0.51252 |  0:00:02s\n",
      "epoch 54 | loss: 0.52148 |  0:00:02s\n",
      "epoch 55 | loss: 0.50706 |  0:00:02s\n",
      "epoch 56 | loss: 0.50415 |  0:00:02s\n",
      "epoch 57 | loss: 0.50179 |  0:00:02s\n",
      "epoch 58 | loss: 0.5014  |  0:00:02s\n",
      "epoch 59 | loss: 0.496   |  0:00:02s\n",
      "epoch 60 | loss: 0.49581 |  0:00:02s\n",
      "epoch 61 | loss: 0.49195 |  0:00:02s\n",
      "epoch 62 | loss: 0.49182 |  0:00:02s\n",
      "epoch 63 | loss: 0.48621 |  0:00:03s\n",
      "epoch 64 | loss: 0.48535 |  0:00:03s\n",
      "epoch 65 | loss: 0.48092 |  0:00:03s\n",
      "epoch 66 | loss: 0.48223 |  0:00:03s\n",
      "epoch 67 | loss: 0.47486 |  0:00:03s\n",
      "epoch 68 | loss: 0.48263 |  0:00:03s\n",
      "epoch 69 | loss: 0.46807 |  0:00:03s\n",
      "epoch 70 | loss: 0.47951 |  0:00:03s\n",
      "epoch 71 | loss: 0.47439 |  0:00:03s\n",
      "epoch 72 | loss: 0.46664 |  0:00:03s\n",
      "epoch 73 | loss: 0.46357 |  0:00:03s\n",
      "epoch 74 | loss: 0.45955 |  0:00:03s\n",
      "epoch 75 | loss: 0.44495 |  0:00:03s\n",
      "epoch 76 | loss: 0.45515 |  0:00:03s\n",
      "epoch 77 | loss: 0.44442 |  0:00:03s\n",
      "epoch 78 | loss: 0.44651 |  0:00:03s\n",
      "epoch 79 | loss: 0.44756 |  0:00:03s\n",
      "epoch 80 | loss: 0.43945 |  0:00:03s\n",
      "epoch 81 | loss: 0.4455  |  0:00:03s\n",
      "epoch 82 | loss: 0.42914 |  0:00:03s\n",
      "epoch 83 | loss: 0.42907 |  0:00:03s\n",
      "epoch 84 | loss: 0.42916 |  0:00:03s\n",
      "epoch 85 | loss: 0.43479 |  0:00:04s\n",
      "epoch 86 | loss: 0.4282  |  0:00:04s\n",
      "epoch 87 | loss: 0.43356 |  0:00:04s\n",
      "epoch 88 | loss: 0.4317  |  0:00:04s\n",
      "epoch 89 | loss: 0.42938 |  0:00:04s\n",
      "epoch 90 | loss: 0.42696 |  0:00:04s\n",
      "epoch 91 | loss: 0.43679 |  0:00:04s\n",
      "epoch 92 | loss: 0.43223 |  0:00:04s\n",
      "epoch 93 | loss: 0.43293 |  0:00:04s\n",
      "epoch 94 | loss: 0.43471 |  0:00:04s\n",
      "epoch 95 | loss: 0.43117 |  0:00:04s\n",
      "epoch 96 | loss: 0.43198 |  0:00:04s\n",
      "epoch 97 | loss: 0.42767 |  0:00:04s\n",
      "epoch 98 | loss: 0.44682 |  0:00:04s\n",
      "epoch 99 | loss: 0.42731 |  0:00:04s\n",
      "epoch 100| loss: 0.42579 |  0:00:04s\n",
      "epoch 101| loss: 0.42668 |  0:00:04s\n",
      "epoch 102| loss: 0.41374 |  0:00:04s\n",
      "epoch 103| loss: 0.40874 |  0:00:04s\n",
      "epoch 104| loss: 0.41486 |  0:00:04s\n",
      "epoch 105| loss: 0.4021  |  0:00:04s\n",
      "epoch 106| loss: 0.40922 |  0:00:05s\n",
      "epoch 107| loss: 0.40808 |  0:00:05s\n",
      "epoch 108| loss: 0.4061  |  0:00:05s\n",
      "epoch 109| loss: 0.40864 |  0:00:05s\n",
      "epoch 110| loss: 0.40504 |  0:00:05s\n",
      "epoch 111| loss: 0.39976 |  0:00:05s\n",
      "epoch 112| loss: 0.40696 |  0:00:05s\n",
      "epoch 113| loss: 0.38797 |  0:00:05s\n",
      "epoch 114| loss: 0.40204 |  0:00:05s\n",
      "epoch 115| loss: 0.3983  |  0:00:05s\n",
      "epoch 116| loss: 0.4002  |  0:00:05s\n",
      "epoch 117| loss: 0.40514 |  0:00:05s\n",
      "epoch 118| loss: 0.40652 |  0:00:05s\n",
      "epoch 119| loss: 0.40779 |  0:00:05s\n",
      "epoch 120| loss: 0.41209 |  0:00:05s\n",
      "epoch 121| loss: 0.40213 |  0:00:05s\n",
      "epoch 122| loss: 0.38867 |  0:00:05s\n",
      "epoch 123| loss: 0.38918 |  0:00:05s\n",
      "epoch 124| loss: 0.39164 |  0:00:05s\n",
      "epoch 125| loss: 0.37698 |  0:00:05s\n",
      "epoch 126| loss: 0.37028 |  0:00:05s\n",
      "epoch 127| loss: 0.37927 |  0:00:05s\n",
      "epoch 128| loss: 0.36095 |  0:00:05s\n",
      "epoch 129| loss: 0.36817 |  0:00:06s\n",
      "epoch 130| loss: 0.35612 |  0:00:06s\n",
      "epoch 131| loss: 0.35326 |  0:00:06s\n",
      "epoch 132| loss: 0.35904 |  0:00:06s\n",
      "epoch 133| loss: 0.35966 |  0:00:06s\n",
      "epoch 134| loss: 0.34819 |  0:00:06s\n",
      "epoch 135| loss: 0.35239 |  0:00:06s\n",
      "epoch 136| loss: 0.35978 |  0:00:06s\n",
      "epoch 137| loss: 0.35151 |  0:00:06s\n",
      "epoch 138| loss: 0.36372 |  0:00:06s\n",
      "epoch 139| loss: 0.36289 |  0:00:06s\n",
      "epoch 140| loss: 0.36773 |  0:00:06s\n",
      "epoch 141| loss: 0.36356 |  0:00:06s\n",
      "epoch 142| loss: 0.35889 |  0:00:06s\n",
      "epoch 143| loss: 0.36573 |  0:00:06s\n",
      "epoch 144| loss: 0.36685 |  0:00:06s\n",
      "epoch 145| loss: 0.36418 |  0:00:06s\n",
      "epoch 146| loss: 0.37643 |  0:00:06s\n",
      "epoch 147| loss: 0.36169 |  0:00:06s\n",
      "epoch 148| loss: 0.3599  |  0:00:06s\n",
      "epoch 149| loss: 0.36358 |  0:00:06s\n",
      "epoch 150| loss: 0.38092 |  0:00:07s\n",
      "epoch 151| loss: 0.37406 |  0:00:07s\n",
      "epoch 152| loss: 0.36953 |  0:00:07s\n",
      "epoch 153| loss: 0.37239 |  0:00:07s\n",
      "epoch 154| loss: 0.36479 |  0:00:07s\n",
      "epoch 155| loss: 0.36082 |  0:00:07s\n",
      "epoch 156| loss: 0.35538 |  0:00:07s\n",
      "epoch 157| loss: 0.34878 |  0:00:07s\n",
      "epoch 158| loss: 0.34607 |  0:00:07s\n",
      "epoch 159| loss: 0.34139 |  0:00:07s\n",
      "epoch 160| loss: 0.33437 |  0:00:07s\n",
      "epoch 161| loss: 0.33563 |  0:00:07s\n",
      "epoch 162| loss: 0.34112 |  0:00:07s\n",
      "epoch 163| loss: 0.35652 |  0:00:07s\n",
      "epoch 164| loss: 0.35128 |  0:00:07s\n",
      "epoch 165| loss: 0.34045 |  0:00:07s\n",
      "epoch 166| loss: 0.34459 |  0:00:07s\n",
      "epoch 167| loss: 0.34769 |  0:00:07s\n",
      "epoch 168| loss: 0.33172 |  0:00:07s\n",
      "epoch 169| loss: 0.33832 |  0:00:07s\n",
      "epoch 170| loss: 0.32454 |  0:00:07s\n",
      "epoch 171| loss: 0.33092 |  0:00:07s\n",
      "epoch 172| loss: 0.33065 |  0:00:08s\n",
      "epoch 173| loss: 0.31971 |  0:00:08s\n",
      "epoch 174| loss: 0.31975 |  0:00:08s\n",
      "epoch 175| loss: 0.30903 |  0:00:08s\n",
      "epoch 176| loss: 0.31415 |  0:00:08s\n",
      "epoch 177| loss: 0.32472 |  0:00:08s\n",
      "epoch 178| loss: 0.30966 |  0:00:08s\n",
      "epoch 179| loss: 0.31315 |  0:00:08s\n",
      "epoch 180| loss: 0.31162 |  0:00:08s\n",
      "epoch 181| loss: 0.32061 |  0:00:08s\n",
      "epoch 182| loss: 0.31373 |  0:00:08s\n",
      "epoch 183| loss: 0.31775 |  0:00:08s\n",
      "epoch 184| loss: 0.31597 |  0:00:08s\n",
      "epoch 185| loss: 0.3111  |  0:00:08s\n",
      "epoch 186| loss: 0.31505 |  0:00:08s\n",
      "epoch 187| loss: 0.30957 |  0:00:08s\n",
      "epoch 188| loss: 0.31093 |  0:00:08s\n",
      "epoch 189| loss: 0.31486 |  0:00:08s\n",
      "epoch 190| loss: 0.31301 |  0:00:08s\n",
      "epoch 191| loss: 0.3108  |  0:00:08s\n",
      "epoch 192| loss: 0.30916 |  0:00:08s\n",
      "epoch 193| loss: 0.30084 |  0:00:09s\n",
      "epoch 194| loss: 0.30258 |  0:00:09s\n",
      "epoch 195| loss: 0.30658 |  0:00:09s\n",
      "epoch 196| loss: 0.30231 |  0:00:09s\n",
      "epoch 197| loss: 0.29887 |  0:00:09s\n",
      "epoch 198| loss: 0.3017  |  0:00:09s\n",
      "epoch 199| loss: 0.2996  |  0:00:09s\n",
      "epoch 200| loss: 0.29747 |  0:00:09s\n",
      "epoch 201| loss: 0.302   |  0:00:09s\n",
      "epoch 202| loss: 0.29356 |  0:00:09s\n",
      "epoch 203| loss: 0.29971 |  0:00:09s\n",
      "epoch 204| loss: 0.28496 |  0:00:09s\n",
      "epoch 205| loss: 0.28985 |  0:00:09s\n",
      "epoch 206| loss: 0.28443 |  0:00:09s\n",
      "epoch 207| loss: 0.28011 |  0:00:09s\n",
      "epoch 208| loss: 0.28006 |  0:00:09s\n",
      "epoch 209| loss: 0.27741 |  0:00:09s\n",
      "epoch 210| loss: 0.27276 |  0:00:09s\n",
      "epoch 211| loss: 0.27628 |  0:00:09s\n",
      "epoch 212| loss: 0.2841  |  0:00:09s\n",
      "epoch 213| loss: 0.28351 |  0:00:09s\n",
      "epoch 214| loss: 0.28181 |  0:00:10s\n",
      "epoch 215| loss: 0.29372 |  0:00:10s\n",
      "epoch 216| loss: 0.27954 |  0:00:10s\n",
      "epoch 217| loss: 0.28504 |  0:00:10s\n",
      "epoch 218| loss: 0.281   |  0:00:10s\n",
      "epoch 219| loss: 0.28408 |  0:00:10s\n",
      "epoch 220| loss: 0.28229 |  0:00:10s\n",
      "epoch 221| loss: 0.27346 |  0:00:10s\n",
      "epoch 222| loss: 0.26955 |  0:00:10s\n",
      "epoch 223| loss: 0.27341 |  0:00:10s\n",
      "epoch 224| loss: 0.27228 |  0:00:10s\n",
      "epoch 225| loss: 0.26034 |  0:00:10s\n",
      "epoch 226| loss: 0.26504 |  0:00:10s\n",
      "epoch 227| loss: 0.26373 |  0:00:10s\n",
      "epoch 228| loss: 0.25678 |  0:00:10s\n",
      "epoch 229| loss: 0.2667  |  0:00:10s\n",
      "epoch 230| loss: 0.25775 |  0:00:10s\n",
      "epoch 231| loss: 0.26326 |  0:00:10s\n",
      "epoch 232| loss: 0.25435 |  0:00:10s\n",
      "epoch 233| loss: 0.25562 |  0:00:10s\n",
      "epoch 234| loss: 0.26014 |  0:00:10s\n",
      "epoch 235| loss: 0.2552  |  0:00:11s\n",
      "epoch 236| loss: 0.25414 |  0:00:11s\n",
      "epoch 237| loss: 0.25566 |  0:00:11s\n",
      "epoch 238| loss: 0.25705 |  0:00:11s\n",
      "epoch 239| loss: 0.25846 |  0:00:11s\n",
      "epoch 240| loss: 0.25685 |  0:00:11s\n",
      "epoch 241| loss: 0.26753 |  0:00:11s\n",
      "epoch 242| loss: 0.27538 |  0:00:11s\n",
      "epoch 243| loss: 0.27838 |  0:00:11s\n",
      "epoch 244| loss: 0.27072 |  0:00:11s\n",
      "epoch 245| loss: 0.26688 |  0:00:11s\n",
      "epoch 246| loss: 0.26624 |  0:00:11s\n",
      "epoch 247| loss: 0.26438 |  0:00:11s\n",
      "epoch 248| loss: 0.26376 |  0:00:11s\n",
      "epoch 249| loss: 0.26156 |  0:00:11s\n",
      "PLSRegression_4_components\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "GatedAdditiveTreeEnsembleConfig_tab\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">737</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:32\u001b[0m,\u001b[1;36m737\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">748</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:32\u001b[0m,\u001b[1;36m748\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">752</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:32\u001b[0m,\u001b[1;36m752\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">769</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model:                        \n",
       "GatedAdditiveTreeEnsembleModel                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:32\u001b[0m,\u001b[1;36m769\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model:                        \n",
       "GatedAdditiveTreeEnsembleModel                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">967</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gate.gate_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">255</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:32\u001b[0m,\u001b[1;36m967\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gate.gate_model:\u001b[1;36m255\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">980</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:32\u001b[0m,\u001b[1;36m980\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">989</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:32\u001b[0m,\u001b[1;36m989\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b631ceda52f4b5fb28776c3d0a423ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "LR finder stopped early after 3 steps due to diverging loss.\n",
      "Failed to compute suggestion for learning rate because there are not enough points. Increase the loop iteration limits or the size of your dataset/dataloader.\n",
      "Restoring states from the checkpoint path at /home/cschneuwly/Documents/projects/optimus/notebooks/.lr_find_876daee4-7a82-43e9-bdf1-09457822dd6f.ckpt\n",
      "Restored all states from the checkpoint at /home/cschneuwly/Documents/projects/optimus/notebooks/.lr_find_876daee4-7a82-43e9-bdf1-09457822dd6f.ckpt\n",
      "Failed to compute suggestion for learning rate because there are not enough points. Increase the loop iteration limits or the size of your dataset/dataloader.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">791</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:34\u001b[0m,\u001b[1;36m791\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[3;35mNone\u001b[0m. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">798</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gate.gate_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">255</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:34\u001b[0m,\u001b[1;36m798\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gate.gate_model:\u001b[1;36m255\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">811</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:34\u001b[0m,\u001b[1;36m811\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                       | Params | Mode \n",
      "------------------------------------------------------------------------\n",
      "0 | _backbone        | GatedAdditiveTreesBackbone | 2.1 M  | train\n",
      "1 | _embedding_layer | Embedding1dLayer           | 400    | train\n",
      "2 | _head            | CustomHead                 | 156    | train\n",
      "3 | loss             | MSELoss                    | 0      | train\n",
      "------------------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.417     Total estimated model params size (MB)\n",
      "689       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae2f578894f4003bde8714a18188f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d562253a40cf410ab4fcc64ff7b62496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6953239035bf4c1188dee0c62e1b3ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">888</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:36\u001b[0m,\u001b[1;36m888\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">889</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:36\u001b[0m,\u001b[1;36m889\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
      "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
      "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
      "\tWeightsUnpickler error: Unsupported global: GLOBAL omegaconf.dictconfig.DictConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([omegaconf.dictconfig.DictConfig])` or the `torch.serialization.safe_globals([omegaconf.dictconfig.DictConfig])` context manager to allowlist this global if you trust this class/function.\n",
      "\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
      "DANetConfig_tab\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">602</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:37\u001b[0m,\u001b[1;36m602\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">613</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:37\u001b[0m,\u001b[1;36m613\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">617</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:37\u001b[0m,\u001b[1;36m617\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">633</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: DANetModel             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:37\u001b[0m,\u001b[1;36m633\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: DANetModel             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">660</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:37\u001b[0m,\u001b[1;36m660\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">668</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:37\u001b[0m,\u001b[1;36m668\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe2954ccd4348c09219348a73035c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "LR finder stopped early after 3 steps due to diverging loss.\n",
      "Failed to compute suggestion for learning rate because there are not enough points. Increase the loop iteration limits or the size of your dataset/dataloader.\n",
      "Restoring states from the checkpoint path at /home/cschneuwly/Documents/projects/optimus/notebooks/.lr_find_c560011d-ab92-480d-9966-d1c4118aa1cf.ckpt\n",
      "Restored all states from the checkpoint at /home/cschneuwly/Documents/projects/optimus/notebooks/.lr_find_c560011d-ab92-480d-9966-d1c4118aa1cf.ckpt\n",
      "Failed to compute suggestion for learning rate because there are not enough points. Increase the loop iteration limits or the size of your dataset/dataloader.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">978</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:37\u001b[0m,\u001b[1;36m978\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[3;35mNone\u001b[0m. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">984</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:37\u001b[0m,\u001b[1;36m984\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | _backbone        | DANetBackbone    | 1.4 M  | train\n",
      "1 | _embedding_layer | Embedding1dLayer | 400    | train\n",
      "2 | _head            | LinearHead       | 260    | train\n",
      "3 | loss             | MSELoss          | 0      | train\n",
      "--------------------------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.787     Total estimated model params size (MB)\n",
      "156       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b7b3579bcf45aebca0cbc243030240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddd1e09d64a4a8a8958c675d277c6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656b80ac3a6941218cfbf40654137c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">321</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:38\u001b[0m,\u001b[1;36m321\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">322</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:38\u001b[0m,\u001b[1;36m322\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
      "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
      "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
      "\tWeightsUnpickler error: Unsupported global: GLOBAL omegaconf.dictconfig.DictConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([omegaconf.dictconfig.DictConfig])` or the `torch.serialization.safe_globals([omegaconf.dictconfig.DictConfig])` context manager to allowlist this global if you trust this class/function.\n",
      "\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
      "TabTransformerConfig_tab\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">518</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:38\u001b[0m,\u001b[1;36m518\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">529</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:38\u001b[0m,\u001b[1;36m529\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">533</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:38\u001b[0m,\u001b[1;36m533\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabTransformerModel    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:38\u001b[0m,\u001b[1;36m548\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabTransformerModel    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">568</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:38\u001b[0m,\u001b[1;36m568\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:38\u001b[0m,\u001b[1;36m576\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f1a1509407415d9abc8765a5155eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "LR finder stopped early after 3 steps due to diverging loss.\n",
      "Failed to compute suggestion for learning rate because there are not enough points. Increase the loop iteration limits or the size of your dataset/dataloader.\n",
      "Restoring states from the checkpoint path at /home/cschneuwly/Documents/projects/optimus/notebooks/.lr_find_ad7a3db4-4aa1-4406-8b59-d38918fcbb27.ckpt\n",
      "Restored all states from the checkpoint at /home/cschneuwly/Documents/projects/optimus/notebooks/.lr_find_ad7a3db4-4aa1-4406-8b59-d38918fcbb27.ckpt\n",
      "Failed to compute suggestion for learning rate because there are not enough points. Increase the loop iteration limits or the size of your dataset/dataloader.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">701</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:38\u001b[0m,\u001b[1;36m701\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[3;35mNone\u001b[0m. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">703</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:38\u001b[0m,\u001b[1;36m703\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                   | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | _backbone        | TabTransformerBackbone | 271 K  | train\n",
      "1 | _embedding_layer | Embedding2dLayer       | 0      | train\n",
      "2 | _head            | LinearHead             | 804    | train\n",
      "3 | loss             | MSELoss                | 0      | train\n",
      "--------------------------------------------------------------------\n",
      "272 K     Trainable params\n",
      "0         Non-trainable params\n",
      "272 K     Total params\n",
      "1.090     Total estimated model params size (MB)\n",
      "119       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeaa53e2320c4b48801f288d7ee597c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e051f34025349c9b971f78950adfe3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f58c710fb641a4b7e480c2d9d0bd64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">829</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:38\u001b[0m,\u001b[1;36m829\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">830</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:38\u001b[0m,\u001b[1;36m830\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
      "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
      "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
      "\tWeightsUnpickler error: Unsupported global: GLOBAL omegaconf.dictconfig.DictConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([omegaconf.dictconfig.DictConfig])` or the `torch.serialization.safe_globals([omegaconf.dictconfig.DictConfig])` context manager to allowlist this global if you trust this class/function.\n",
      "\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
      "TabNetModelConfig_tab\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">015</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:39\u001b[0m,\u001b[1;36m015\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">026</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:39\u001b[0m,\u001b[1;36m026\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">030</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:39\u001b[0m,\u001b[1;36m030\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">045</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabNetModel            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:39\u001b[0m,\u001b[1;36m045\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabNetModel            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">065</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:39\u001b[0m,\u001b[1;36m065\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">072</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:39\u001b[0m,\u001b[1;36m072\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673b1656c8ea4834a2d0c70236ba6134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "LR finder stopped early after 3 steps due to diverging loss.\n",
      "Failed to compute suggestion for learning rate because there are not enough points. Increase the loop iteration limits or the size of your dataset/dataloader.\n",
      "Restoring states from the checkpoint path at /home/cschneuwly/Documents/projects/optimus/notebooks/.lr_find_6d918c7a-39f4-4830-bad2-2d33363bf743.ckpt\n",
      "Restored all states from the checkpoint at /home/cschneuwly/Documents/projects/optimus/notebooks/.lr_find_6d918c7a-39f4-4830-bad2-2d33363bf743.ckpt\n",
      "Failed to compute suggestion for learning rate because there are not enough points. Increase the loop iteration limits or the size of your dataset/dataloader.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">265</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:39\u001b[0m,\u001b[1;36m265\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[3;35mNone\u001b[0m. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">267</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:39\u001b[0m,\u001b[1;36m267\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type           | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | _embedding_layer | Identity       | 0      | train\n",
      "1 | _backbone        | TabNetBackbone | 18.9 K | train\n",
      "2 | _head            | Identity       | 0      | train\n",
      "3 | loss             | MSELoss        | 0      | train\n",
      "------------------------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n",
      "107       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98cd39b81f5f45b686c3ef6f6934ec93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e29e049709340a4a8d78d98a6205d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6dd146feab94759a5f6c4dc31ccc967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">465</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:39\u001b[0m,\u001b[1;36m465\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:22:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">466</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m12:22:39\u001b[0m,\u001b[1;36m466\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
      "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
      "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
      "\tWeightsUnpickler error: Unsupported global: GLOBAL omegaconf.dictconfig.DictConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([omegaconf.dictconfig.DictConfig])` or the `torch.serialization.safe_globals([omegaconf.dictconfig.DictConfig])` context manager to allowlist this global if you trust this class/function.\n",
      "\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'GatedAdditiveTreeEnsembleConfig_tab', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'DANetConfig_tab', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'TabTransformerConfig_tab', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'TabNetModelConfig_tab', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'GatedAdditiveTreeEnsembleConfig_tab', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'DANetConfig_tab', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'TabTransformerConfig_tab', (2881, 200), (13, 200)])\n",
      "Skipping existing combination: dict_values(['NoImputer', 'NoImputer', 'TabNetModelConfig_tab', (2881, 200), (13, 200)])\n"
     ]
    }
   ],
   "source": [
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    # (\"FTTransformerConfig\",\n",
    "    #     TabularModelWrapper(\n",
    "    #     FTTransformerConfig(\n",
    "    #     task=\"regression\",\n",
    "    #     head=\"LinearHead\",\n",
    "    #     head_config=head_config), data_config, trainer_config, optimizer_config\n",
    "    # )),\n",
    "    (\"TabNetModelConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]\n",
    "\n",
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    name_continuous_imputer, continuous_imputer_instance = continuous_imputer\n",
    "    name_ordinal_imputer, ordinal_imputer_instance = ordinal_imputer\n",
    "    name_model, model_instance = model\n",
    "\n",
    "    params = {\n",
    "        \"ordinal_imputer\": name_ordinal_imputer, \n",
    "        \"continuous_imputer\": name_continuous_imputer, \n",
    "        \"model\": name_model, \"train_shape\" : df_X_train.shape, \n",
    "        \"test_shape\": df_X_test.shape\n",
    "    }\n",
    "\n",
    "    if any(result['params'] == params for result in all_dict_results):\n",
    "        # Skip this iteration if the combination exists\n",
    "        print(f\"Skipping existing combination: {params.values()}\")\n",
    "        \n",
    "        continue\n",
    "\n",
    "    try: \n",
    "        print(name_model)\n",
    "        \n",
    "        # Now you can call your `train_model` function with these components\n",
    "        dict_results = train_imputer_model(\n",
    "            df_X_train, df_X_test, df_y_train, df_y_test,\n",
    "            c_train, c_test,\n",
    "            ordinal_imputer_instance, name_ordinal_imputer,\n",
    "            continuous_imputer_instance, name_continuous_imputer,\n",
    "            model_instance, name_model,\n",
    "            separate_imputers=True  # Or however you want to specify\n",
    "        )\n",
    "\n",
    "    except Exception as e:  \n",
    "\n",
    "        print(e)\n",
    "    \n",
    "        dict_results = {\n",
    "        \"params\": params, \n",
    "        \"imputation_time\": None,\n",
    "        \"fitting_time\": None, \n",
    "        \"results_adj\": None, \n",
    "        \"results_org\": None\n",
    "    }\n",
    "        \n",
    "    # Optionally keep the all_dict_results list updated\n",
    "    all_dict_results.append(dict_results)\n",
    "\n",
    "        # Save the updated results back to the pickle file\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(all_dict_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'LinearRegression',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.2466392517089844,\n",
       "  'fitting_time': 0.22939062118530273,\n",
       "  'results_adj': {'mse_score': array([0.65983176, 0.48974311, 0.40951464, 0.56684282]),\n",
       "   'mae_score': array([0.63965764, 0.55144938, 0.56535002, 0.59999667]),\n",
       "   'r2': array([0.33312259, 0.44426866, 0.144955  , 0.31048062]),\n",
       "   'explained_variance': array([0.36730884, 0.47760179, 0.14545957, 0.43985495]),\n",
       "   'corr': array([0.60633336, 0.69220668, 0.4020632 , 0.66605104])},\n",
       "  'results_org': {'mse_score': array([0.65983176, 0.4897431 , 0.40951466, 0.56684279]),\n",
       "   'mae_score': array([0.63965764, 0.55144938, 0.56535003, 0.59999666]),\n",
       "   'r2': array([0.29810904, 0.45135258, 0.20239561, 0.33725209]),\n",
       "   'explained_variance': array([0.33409019, 0.48426081, 0.20286628, 0.46160331]),\n",
       "   'corr': array([0.57814397, 0.69816204, 0.46213839, 0.68191102])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskElasticNet',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.283444404602051,\n",
       "  'fitting_time': 0.09822368621826172,\n",
       "  'results_adj': {'mse_score': array([1.18012248, 0.95041535, 0.50741149, 1.02939714]),\n",
       "   'mae_score': array([0.88414168, 0.78683573, 0.65378091, 0.82689555]),\n",
       "   'r2': array([-0.19272377, -0.07847478, -0.05944846, -0.25218006]),\n",
       "   'explained_variance': array([ 0.11229868,  0.03189858, -0.05332468,  0.12857136]),\n",
       "   'corr': array([ 0.42176385,  0.17864276, -0.16306812,  0.44631446])},\n",
       "  'results_org': {'mse_score': array([1.18012249, 0.95041535, 0.50741151, 1.02939711]),\n",
       "   'mae_score': array([0.88414168, 0.78683573, 0.65378092, 0.82689554]),\n",
       "   'r2': array([-0.25534622, -0.06472746,  0.01172365, -0.20356259]),\n",
       "   'explained_variance': array([0.06569104, 0.04423898, 0.01743605, 0.16240568]),\n",
       "   'corr': array([0.25863755, 0.21083052, 0.14561963, 0.49623359])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskElasticNet_tuned',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.2664968967437744,\n",
       "  'fitting_time': 1.4926152229309082,\n",
       "  'results_adj': {'mse_score': array([0.66791342, 0.47856617, 0.41412878, 0.59264981]),\n",
       "   'mae_score': array([0.63043587, 0.55392437, 0.58019171, 0.59956285]),\n",
       "   'r2': array([0.32495464, 0.45695159, 0.13532092, 0.27908847]),\n",
       "   'explained_variance': array([0.3700506 , 0.49637797, 0.13598028, 0.44010284]),\n",
       "   'corr': array([0.60831821, 0.70457467, 0.38152442, 0.66946516])},\n",
       "  'results_org': {'mse_score': array([0.66791342, 0.47856617, 0.4141288 , 0.59264978]),\n",
       "   'mae_score': array([0.63043586, 0.55392437, 0.58019172, 0.59956284]),\n",
       "   'r2': array([0.28951224, 0.46387383, 0.19340873, 0.30707878]),\n",
       "   'explained_variance': array([0.33697591, 0.50279765, 0.19402379, 0.46184157]),\n",
       "   'corr': array([0.58049709, 0.70936568, 0.44690586, 0.68551862])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskLasso',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.283153772354126,\n",
       "  'fitting_time': 0.07776927947998047,\n",
       "  'results_adj': {'mse_score': array([1.39363767, 1.04056339, 0.48866937, 1.24000841]),\n",
       "   'mae_score': array([0.99127575, 0.78457157, 0.62110666, 0.93446712]),\n",
       "   'r2': array([-0.40851885, -0.18076941, -0.0203159 , -0.50837198]),\n",
       "   'explained_variance': array([-2.22044605e-16,  0.00000000e+00,  0.00000000e+00,  1.11022302e-16]),\n",
       "   'corr': array([nan, nan, nan, nan])},\n",
       "  'results_org': {'mse_score': array([1.39363768, 1.04056339, 0.48866939, 1.24000838]),\n",
       "   'mae_score': array([0.99127576, 0.78457157, 0.62110667, 0.93446711]),\n",
       "   'r2': array([-0.48247136, -0.16571814,  0.04822734, -0.44980754]),\n",
       "   'explained_variance': array([-0.05250375,  0.01274701,  0.06717846,  0.03882626]),\n",
       "   'corr': array([-0.0848666 ,  0.11455326,  0.2721653 ,  0.20679355])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'MultiTaskLasso_tuned',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.3114430904388428,\n",
       "  'fitting_time': 1.4922456741333008,\n",
       "  'results_adj': {'mse_score': array([0.6555347 , 0.47602153, 0.41898635, 0.58247095]),\n",
       "   'mae_score': array([0.62193632, 0.55058805, 0.57780272, 0.59499437]),\n",
       "   'r2': array([0.33746553, 0.45983909, 0.12517858, 0.29147024]),\n",
       "   'explained_variance': array([0.38303248, 0.49996522, 0.12605199, 0.44788336]),\n",
       "   'corr': array([0.61892446, 0.70715313, 0.37654024, 0.67491708])},\n",
       "  'results_org': {'mse_score': array([0.6555347 , 0.47602153, 0.41898636, 0.58247092]),\n",
       "   'mae_score': array([0.62193631, 0.55058805, 0.57780274, 0.59499436]),\n",
       "   'r2': array([0.30268   , 0.46672453, 0.18394773, 0.31897981]),\n",
       "   'explained_variance': array([0.35063939, 0.50633917, 0.18476246, 0.46932   ]),\n",
       "   'corr': array([0.59223356, 0.71197064, 0.44079738, 0.69050252])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'RandomForestRegressor',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.289330244064331,\n",
       "  'fitting_time': 51.79721212387085,\n",
       "  'results_adj': {'mse_score': array([0.81204962, 0.55738872, 0.42447239, 0.76265381]),\n",
       "   'mae_score': array([0.66916949, 0.63959102, 0.60835909, 0.64774379]),\n",
       "   'r2': array([0.17927936, 0.36750845, 0.11372402, 0.07229206]),\n",
       "   'explained_variance': array([0.38575368, 0.43668934, 0.11735442, 0.37009751]),\n",
       "   'corr': array([0.63471399, 0.67665811, 0.34287971, 0.62716925])},\n",
       "  'results_org': {'mse_score': array([0.81204962, 0.55738872, 0.42447241, 0.76265379]),\n",
       "   'mae_score': array([0.6691695 , 0.63959102, 0.6083591 , 0.64774379]),\n",
       "   'r2': array([0.13618846, 0.37557082, 0.17326266, 0.10831149]),\n",
       "   'explained_variance': array([0.35350346, 0.44386986, 0.17664918, 0.39455427]),\n",
       "   'corr': array([0.60552878, 0.68293217, 0.42214619, 0.66388455])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'PLSRegression_4_components',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.3004002571105957,\n",
       "  'fitting_time': 0.15016818046569824,\n",
       "  'results_adj': {'mse_score': array([0.99283749, 0.68320591, 0.51129344, 0.88042711]),\n",
       "   'mae_score': array([0.8049879 , 0.73842664, 0.68894711, 0.76406833]),\n",
       "   'r2': array([-0.00343896,  0.22473859, -0.06755375, -0.07096982]),\n",
       "   'explained_variance': array([ 0.25778331,  0.29950329, -0.06753554,  0.2736962 ]),\n",
       "   'corr': array([0.50966098, 0.55561882, 0.0742507 , 0.52674345])},\n",
       "  'results_org': {'mse_score': array([0.99283749, 0.68320591, 0.51129345, 0.88042708]),\n",
       "   'mae_score': array([0.80498791, 0.73842664, 0.68894712, 0.76406832]),\n",
       "   'r2': array([-0.05612325,  0.23462085,  0.00416286, -0.02938806]),\n",
       "   'explained_variance': array([0.21881416, 0.30843253, 0.00417985, 0.30189586]),\n",
       "   'corr': array([0.46922857, 0.57093376, 0.17716915, 0.57292837])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'TabNetRegressor_default',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.3759474754333496,\n",
       "  'fitting_time': 13.77210783958435,\n",
       "  'results_adj': {'mse_score': array([0.61824897, 0.61184618, 0.36866036, 0.57763236]),\n",
       "   'mae_score': array([0.69107406, 0.60773177, 0.5361999 , 0.59462053]),\n",
       "   'r2': array([0.3751494 , 0.30571336, 0.23025659, 0.297356  ]),\n",
       "   'explained_variance': array([0.56567234, 0.38915553, 0.23426406, 0.55584824]),\n",
       "   'corr': array([0.77300748, 0.67628222, 0.58077844, 0.81923406])},\n",
       "  'results_org': {'mse_score': array([0.61824897, 0.61184618, 0.36866037, 0.57763234]),\n",
       "   'mae_score': array([0.69107407, 0.60773177, 0.53619991, 0.59462053]),\n",
       "   'r2': array([0.34234241, 0.31456344, 0.28196676, 0.32463705]),\n",
       "   'explained_variance': array([0.54286851, 0.39694198, 0.28570502, 0.57309301]),\n",
       "   'corr': array([0.76293555, 0.67836772, 0.73113403, 0.85040194])}},\n",
       " {'params': {'ordinal_imputer': 'SimpleImputer_most_frequent',\n",
       "   'continuous_imputer': 'KNNImputer',\n",
       "   'model': 'TabNetRegressor_custom',\n",
       "   'train_shape': (2881, 348),\n",
       "   'test_shape': (13, 348)},\n",
       "  'imputation_time': 3.4543991088867188,\n",
       "  'fitting_time': 13.39520812034607,\n",
       "  'results_adj': {'mse_score': array([1.07617402, 1.31252905, 0.77527955, 1.0442195 ]),\n",
       "   'mae_score': array([0.76465789, 0.96862147, 0.76452422, 0.76252167]),\n",
       "   'r2': array([-0.08766535, -0.48937986, -0.61874284, -0.27021028]),\n",
       "   'explained_variance': array([ 0.20827438, -0.34330108, -0.60463007,  0.30404738]),\n",
       "   'corr': array([ 0.54009087,  0.30700851, -0.06850123,  0.58642515])},\n",
       "  'results_org': {'mse_score': array([1.07617403, 1.31252906, 0.77527957, 1.04421947]),\n",
       "   'mae_score': array([0.76465789, 0.96862147, 0.76452423, 0.76252167]),\n",
       "   'r2': array([-0.14477185, -0.47039474, -0.5099982 , -0.22089277]),\n",
       "   'explained_variance': array([ 0.16670582, -0.32617802, -0.4968335 ,  0.33106863]),\n",
       "   'corr': array([0.50999118, 0.31151104, 0.0452715 , 0.59746408])}},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'LinearRegression',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': 0.09009456634521484,\n",
       "  'results_adj': {'mse_score': array([1.11192349, 0.67668626, 0.61999815, 0.97750844]),\n",
       "   'mae_score': array([0.72849831, 0.70235973, 0.70986192, 0.71215901]),\n",
       "   'r2': array([-0.12379655,  0.2321367 , -0.29452346, -0.18906157]),\n",
       "   'explained_variance': array([ 0.02475189,  0.28845771, -0.29319881,  0.10973059]),\n",
       "   'corr': array([0.33204585, 0.54765514, 0.01649677, 0.38058137])},\n",
       "  'results_org': {'mse_score': array([1.11192349, 0.67668626, 0.61999817, 0.97750843]),\n",
       "   'mae_score': array([0.72849832, 0.70235973, 0.70986193, 0.712159  ]),\n",
       "   'r2': array([-0.18280006,  0.24192465, -0.20755938, -0.14289477]),\n",
       "   'explained_variance': array([-0.02645227,  0.29752774, -0.20632372,  0.14429641]),\n",
       "   'corr': array([0.27766053, 0.55012684, 0.07284141, 0.39622517])}},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'MultiTaskElasticNet',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': 0.01528787612915039,\n",
       "  'results_adj': {'mse_score': array([1.18012247, 0.95041534, 0.50741149, 1.02939713]),\n",
       "   'mae_score': array([0.88414167, 0.78683572, 0.65378091, 0.82689555]),\n",
       "   'r2': array([-0.19272375, -0.07847477, -0.05944845, -0.25218005]),\n",
       "   'explained_variance': array([ 0.11229868,  0.03189858, -0.05332468,  0.12857136]),\n",
       "   'corr': array([ 0.42176386,  0.17864277, -0.16306808,  0.44631445])},\n",
       "  'results_org': {'mse_score': array([1.18012248, 0.95041534, 0.50741151, 1.02939711]),\n",
       "   'mae_score': array([0.88414168, 0.78683573, 0.65378092, 0.82689554]),\n",
       "   'r2': array([-0.25534621, -0.06472745,  0.01172366, -0.20356258]),\n",
       "   'explained_variance': array([0.06569104, 0.04423898, 0.01743605, 0.16240568]),\n",
       "   'corr': array([0.25863755, 0.21083053, 0.14561964, 0.49623358])}},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'MultiTaskElasticNet_tuned',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': 0.8313999176025391,\n",
       "  'results_adj': {'mse_score': array([1.09767924, 0.67163602, 0.61727141, 0.96027028]),\n",
       "   'mae_score': array([0.72712752, 0.70316248, 0.71357071, 0.70813001]),\n",
       "   'r2': array([-0.1094002 ,  0.23786741, -0.28883017, -0.16809271]),\n",
       "   'explained_variance': array([ 0.04259982,  0.29559122, -0.28782174,  0.12798901]),\n",
       "   'corr': array([0.33826662, 0.55120885, 0.00953623, 0.39231636])},\n",
       "  'results_org': {'mse_score': array([1.09767923, 0.67163602, 0.61727143, 0.96027027]),\n",
       "   'mae_score': array([0.72712752, 0.70316248, 0.71357072, 0.70813   ]),\n",
       "   'r2': array([-0.16764784,  0.24758231, -0.20224855, -0.12274005]),\n",
       "   'explained_variance': array([-0.00766726,  0.30457033, -0.20130787,  0.16184592]),\n",
       "   'corr': array([0.28384559, 0.55450481, 0.06742918, 0.41077564])}},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'MultiTaskLasso',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': 0.007750749588012695,\n",
       "  'results_adj': {'mse_score': array([1.39363767, 1.04056339, 0.48866937, 1.24000841]),\n",
       "   'mae_score': array([0.99127575, 0.78457157, 0.62110666, 0.93446712]),\n",
       "   'r2': array([-0.40851885, -0.18076941, -0.0203159 , -0.50837198]),\n",
       "   'explained_variance': array([-2.22044605e-16,  0.00000000e+00,  0.00000000e+00,  1.11022302e-16]),\n",
       "   'corr': array([nan, nan, nan, nan])},\n",
       "  'results_org': {'mse_score': array([1.39363768, 1.04056339, 0.48866939, 1.24000838]),\n",
       "   'mae_score': array([0.99127576, 0.78457157, 0.62110667, 0.93446711]),\n",
       "   'r2': array([-0.48247136, -0.16571814,  0.04822734, -0.44980754]),\n",
       "   'explained_variance': array([-0.05250375,  0.01274701,  0.06717846,  0.03882626]),\n",
       "   'corr': array([-0.0848666 ,  0.11455326,  0.2721653 ,  0.20679355])}},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'MultiTaskLasso_tuned',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': 0.8366336822509766,\n",
       "  'results_adj': {'mse_score': array([1.09986228, 0.67700338, 0.61721354, 0.96322248]),\n",
       "   'mae_score': array([0.72439764, 0.70502407, 0.71262079, 0.70634911]),\n",
       "   'r2': array([-0.11160655,  0.23177686, -0.28870934, -0.17168383]),\n",
       "   'explained_variance': array([ 0.04182356,  0.29179378, -0.28783433,  0.1250568 ]),\n",
       "   'corr': array([0.34030126, 0.54948447, 0.01369735, 0.39123818])},\n",
       "  'results_org': {'mse_score': array([1.09986228, 0.67700337, 0.61721356, 0.96322247]),\n",
       "   'mae_score': array([0.72439764, 0.70502408, 0.71262081, 0.7063491 ]),\n",
       "   'r2': array([-0.16997004,  0.2415694 , -0.20213584, -0.12619174]),\n",
       "   'explained_variance': array([-0.00848428,  0.30082129, -0.20131962,  0.15902757]),\n",
       "   'corr': array([0.28608858, 0.55225247, 0.07079544, 0.40890542])}},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'RandomForestRegressor',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': 31.880318641662598,\n",
       "  'results_adj': {'mse_score': array([1.00638713, 0.65012684, 0.47869162, 0.82220865]),\n",
       "   'mae_score': array([0.75528169, 0.6841987 , 0.63512616, 0.63151397]),\n",
       "   'r2': array([-1.71332791e-02,  2.62274753e-01,  5.17132936e-04, -1.51675905e-04]),\n",
       "   'explained_variance': array([0.29209145, 0.405549  , 0.02445608, 0.37078241]),\n",
       "   'corr': array([0.54046621, 0.64364297, 0.21686966, 0.60995505])},\n",
       "  'results_org': {'mse_score': array([1.00638713, 0.65012684, 0.47869164, 0.82220864]),\n",
       "   'mae_score': array([0.7552817 , 0.6841987 , 0.63512617, 0.63151397]),\n",
       "   'r2': array([-0.07053657,  0.27167853,  0.06766084,  0.03868046]),\n",
       "   'explained_variance': array([0.25492361, 0.41312647, 0.08999161, 0.39521257]),\n",
       "   'corr': array([0.50511182, 0.65009756, 0.3086371 , 0.63522421])}},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'XGBoostRegressor',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': 0.8378174304962158,\n",
       "  'results_adj': {'mse_score': array([0.99729777, 0.55285888, 0.49806901, 0.7462314 ]),\n",
       "   'mae_score': array([0.75445592, 0.63451078, 0.64294552, 0.64429738]),\n",
       "   'r2': array([-0.00794687,  0.37264865, -0.03994184,  0.09226863]),\n",
       "   'explained_variance': array([ 0.26511088,  0.47604274, -0.03447538,  0.31643386]),\n",
       "   'corr': array([0.52174936, 0.69849083, 0.21172288, 0.56606   ])},\n",
       "  'results_org': {'mse_score': array([0.99729777, 0.55285888, 0.49806903, 0.74623138]),\n",
       "   'mae_score': array([0.75445593, 0.63451079, 0.64294554, 0.64429738]),\n",
       "   'r2': array([-0.06086784,  0.38064549,  0.02991984,  0.12751245]),\n",
       "   'explained_variance': array([0.22652646, 0.48272162, 0.03501907, 0.34297417]),\n",
       "   'corr': array([0.48966434, 0.70257856, 0.27320828, 0.58583766])}},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'XGBoostRegressor_tuned',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': 1.9914910793304443,\n",
       "  'results_adj': {'mse_score': array([1.0153611 , 0.63851973, 0.46345103, 0.70749896]),\n",
       "   'mae_score': array([0.73457703, 0.71458275, 0.63021056, 0.61263546]),\n",
       "   'r2': array([-0.02620307,  0.27544581,  0.03233868,  0.13938357]),\n",
       "   'explained_variance': array([0.22165364, 0.34897739, 0.05887258, 0.43032201]),\n",
       "   'corr': array([0.48104477, 0.59075482, 0.30682341, 0.65598979])},\n",
       "  'results_org': {'mse_score': array([1.0153611 , 0.63851973, 0.46345105, 0.70749894]),\n",
       "   'mae_score': array([0.73457704, 0.71458276, 0.63021057, 0.61263545]),\n",
       "   'r2': array([-0.08008256,  0.2846817 ,  0.09734466,  0.17279809]),\n",
       "   'explained_variance': array([0.18078756, 0.35727599, 0.12209605, 0.45244048]),\n",
       "   'corr': array([0.44678191, 0.59775758, 0.36862204, 0.67323253])}},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'TabNetRegressor_default',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': 11.830575942993164,\n",
       "  'results_adj': {'mse_score': array([1.00024251, 0.85216095, 0.6231349 , 0.78732824]),\n",
       "   'mae_score': array([0.78064659, 0.8013238 , 0.6795552 , 0.67213814]),\n",
       "   'r2': array([-0.01092304,  0.03301847, -0.30107284,  0.04227758]),\n",
       "   'explained_variance': array([ 0.38275983,  0.13551578, -0.29939216,  0.5247155 ]),\n",
       "   'corr': array([0.62946614, 0.47112118, 0.06684408, 0.73037268])},\n",
       "  'results_org': {'mse_score': array([1.0002425 , 0.85216095, 0.62313492, 0.78732822]),\n",
       "   'mae_score': array([0.78064659, 0.8013238 , 0.67955522, 0.67213815]),\n",
       "   'r2': array([-0.06400027,  0.04534457, -0.21366878,  0.07946235]),\n",
       "   'explained_variance': array([ 0.35035243,  0.14653537, -0.212101  ,  0.54316902]),\n",
       "   'corr': array([0.60852724, 0.4852577 , 0.12261516, 0.74095112])}},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'TabNetRegressor_custom',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': 11.706139326095581,\n",
       "  'results_adj': {'mse_score': array([0.92610036, 0.76428738, 0.61165174, 0.87483944]),\n",
       "   'mae_score': array([0.71338154, 0.75841494, 0.67114785, 0.72399585]),\n",
       "   'r2': array([ 0.06401079,  0.13273216, -0.2770966 , -0.06417287]),\n",
       "   'explained_variance': array([ 0.22209961,  0.26101411, -0.27432143,  0.26805491]),\n",
       "   'corr': array([0.55329131, 0.58084529, 0.23700988, 0.59708229])},\n",
       "  'results_org': {'mse_score': array([0.92610035, 0.76428739, 0.61165176, 0.87483943]),\n",
       "   'mae_score': array([0.71338154, 0.75841494, 0.67114786, 0.72399584]),\n",
       "   'r2': array([ 0.01486787,  0.14378722, -0.19130323, -0.02285503]),\n",
       "   'explained_variance': array([ 0.18125695,  0.27043396, -0.1887145 ,  0.2964736 ]),\n",
       "   'corr': array([0.53795846, 0.59013198, 0.27340583, 0.5986342 ])}},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'PLSRegression_4_components',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': 0.050071001052856445,\n",
       "  'results_adj': {'mse_score': array([1.08140908, 0.78765117, 0.5694762 , 0.94630352]),\n",
       "   'mae_score': array([0.79248414, 0.79068015, 0.72178585, 0.73452485]),\n",
       "   'r2': array([-0.09295631,  0.10622033, -0.1890363 , -0.15110326]),\n",
       "   'explained_variance': array([ 0.1855152 ,  0.19584409, -0.18846787,  0.20844666]),\n",
       "   'corr': array([ 0.43286088,  0.44542341, -0.05356343,  0.45740887])},\n",
       "  'results_org': {'mse_score': array([1.08140909, 0.78765116, 0.56947622, 0.9463035 ]),\n",
       "   'mae_score': array([0.79248415, 0.79068015, 0.72178586, 0.73452484]),\n",
       "   'r2': array([-0.1503406 ,  0.11761334, -0.10915869, -0.10641023]),\n",
       "   'explained_variance': array([ 0.14275171,  0.20609467, -0.10862844,  0.23917972]),\n",
       "   'corr': array([0.3812462 , 0.45398549, 0.03688166, 0.49549602])}},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'GatedAdditiveTreeEnsembleConfig_tab',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': None,\n",
       "  'results_adj': None,\n",
       "  'results_org': None},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'DANetConfig_tab',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': None,\n",
       "  'results_adj': None,\n",
       "  'results_org': None},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'TabTransformerConfig_tab',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': None,\n",
       "  'results_adj': None,\n",
       "  'results_org': None},\n",
       " {'params': {'ordinal_imputer': 'NoImputer',\n",
       "   'continuous_imputer': 'NoImputer',\n",
       "   'model': 'TabNetModelConfig_tab',\n",
       "   'train_shape': (2881, 200),\n",
       "   'test_shape': (13, 200)},\n",
       "  'imputation_time': None,\n",
       "  'fitting_time': None,\n",
       "  'results_adj': None,\n",
       "  'results_org': None}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dict_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>imputation_time</th>\n",
       "      <th>fitting_time</th>\n",
       "      <th>results_adj</th>\n",
       "      <th>results_org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'ordinal_imputer': 'SimpleImputer_most_freque...</td>\n",
       "      <td>3.246639</td>\n",
       "      <td>0.229391</td>\n",
       "      <td>{'mse_score': [0.659831758923781, 0.4897431123...</td>\n",
       "      <td>{'mse_score': [0.6598317562332855, 0.489743104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'ordinal_imputer': 'SimpleImputer_most_freque...</td>\n",
       "      <td>3.283444</td>\n",
       "      <td>0.098224</td>\n",
       "      <td>{'mse_score': [1.1801224802168766, 0.950415349...</td>\n",
       "      <td>{'mse_score': [1.1801224892206006, 0.950415348...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'ordinal_imputer': 'SimpleImputer_most_freque...</td>\n",
       "      <td>3.266497</td>\n",
       "      <td>1.492615</td>\n",
       "      <td>{'mse_score': [0.6679134194781107, 0.478566173...</td>\n",
       "      <td>{'mse_score': [0.6679134155298025, 0.478566167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'ordinal_imputer': 'SimpleImputer_most_freque...</td>\n",
       "      <td>3.283154</td>\n",
       "      <td>0.077769</td>\n",
       "      <td>{'mse_score': [1.3936376654364884, 1.040563386...</td>\n",
       "      <td>{'mse_score': [1.39363767778841, 1.04056338628...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'ordinal_imputer': 'SimpleImputer_most_freque...</td>\n",
       "      <td>3.311443</td>\n",
       "      <td>1.492246</td>\n",
       "      <td>{'mse_score': [0.6555347035833681, 0.476021533...</td>\n",
       "      <td>{'mse_score': [0.655534699980677, 0.4760215269...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'ordinal_imputer': 'SimpleImputer_most_freque...</td>\n",
       "      <td>3.289330</td>\n",
       "      <td>51.797212</td>\n",
       "      <td>{'mse_score': [0.8120496178211589, 0.557388719...</td>\n",
       "      <td>{'mse_score': [0.8120496171306019, 0.557388722...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'ordinal_imputer': 'SimpleImputer_most_freque...</td>\n",
       "      <td>3.300400</td>\n",
       "      <td>0.150168</td>\n",
       "      <td>{'mse_score': [0.9928374904980006, 0.683205912...</td>\n",
       "      <td>{'mse_score': [0.9928374937104268, 0.683205911...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'ordinal_imputer': 'SimpleImputer_most_freque...</td>\n",
       "      <td>3.375947</td>\n",
       "      <td>13.772108</td>\n",
       "      <td>{'mse_score': [0.6182489690113672, 0.611846183...</td>\n",
       "      <td>{'mse_score': [0.6182489748896371, 0.611846177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'ordinal_imputer': 'SimpleImputer_most_freque...</td>\n",
       "      <td>3.454399</td>\n",
       "      <td>13.395208</td>\n",
       "      <td>{'mse_score': [1.0761740236083321, 1.312529050...</td>\n",
       "      <td>{'mse_score': [1.076174034182812, 1.3125290559...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.090095</td>\n",
       "      <td>{'mse_score': [1.1119234898099377, 0.676686264...</td>\n",
       "      <td>{'mse_score': [1.111923487408025, 0.6766862634...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015288</td>\n",
       "      <td>{'mse_score': [1.1801224687295142, 0.950415342...</td>\n",
       "      <td>{'mse_score': [1.1801224777332378, 0.950415341...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.831400</td>\n",
       "      <td>{'mse_score': [1.0976792354702392, 0.671636024...</td>\n",
       "      <td>{'mse_score': [1.0976792337396566, 0.671636022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007751</td>\n",
       "      <td>{'mse_score': [1.3936376654364884, 1.040563386...</td>\n",
       "      <td>{'mse_score': [1.39363767778841, 1.04056338628...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836634</td>\n",
       "      <td>{'mse_score': [1.0998622817940762, 0.677003376...</td>\n",
       "      <td>{'mse_score': [1.0998622798698838, 0.677003374...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.880319</td>\n",
       "      <td>{'mse_score': [1.0063871308109065, 0.650126838...</td>\n",
       "      <td>{'mse_score': [1.0063871300392733, 0.650126843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837817</td>\n",
       "      <td>{'mse_score': [0.9972977744677737, 0.552858876...</td>\n",
       "      <td>{'mse_score': [0.9972977727407778, 0.552858879...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.991491</td>\n",
       "      <td>{'mse_score': [1.015361101896433, 0.6385197295...</td>\n",
       "      <td>{'mse_score': [1.0153611005115688, 0.638519728...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.830576</td>\n",
       "      <td>{'mse_score': [1.0002425052752673, 0.852160951...</td>\n",
       "      <td>{'mse_score': [1.0002425013137521, 0.852160952...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.706139</td>\n",
       "      <td>{'mse_score': [0.9261003635990263, 0.764287381...</td>\n",
       "      <td>{'mse_score': [0.9261003504544436, 0.764287386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050071</td>\n",
       "      <td>{'mse_score': [1.081409082021159, 0.7876511651...</td>\n",
       "      <td>{'mse_score': [1.0814090864925796, 0.787651164...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  imputation_time  \\\n",
       "0   {'ordinal_imputer': 'SimpleImputer_most_freque...         3.246639   \n",
       "1   {'ordinal_imputer': 'SimpleImputer_most_freque...         3.283444   \n",
       "2   {'ordinal_imputer': 'SimpleImputer_most_freque...         3.266497   \n",
       "3   {'ordinal_imputer': 'SimpleImputer_most_freque...         3.283154   \n",
       "4   {'ordinal_imputer': 'SimpleImputer_most_freque...         3.311443   \n",
       "5   {'ordinal_imputer': 'SimpleImputer_most_freque...         3.289330   \n",
       "6   {'ordinal_imputer': 'SimpleImputer_most_freque...         3.300400   \n",
       "7   {'ordinal_imputer': 'SimpleImputer_most_freque...         3.375947   \n",
       "8   {'ordinal_imputer': 'SimpleImputer_most_freque...         3.454399   \n",
       "9   {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "10  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "11  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "12  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "13  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "14  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "15  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "16  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "17  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "18  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "19  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "20  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "21  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "22  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "23  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "\n",
       "    fitting_time                                        results_adj  \\\n",
       "0       0.229391  {'mse_score': [0.659831758923781, 0.4897431123...   \n",
       "1       0.098224  {'mse_score': [1.1801224802168766, 0.950415349...   \n",
       "2       1.492615  {'mse_score': [0.6679134194781107, 0.478566173...   \n",
       "3       0.077769  {'mse_score': [1.3936376654364884, 1.040563386...   \n",
       "4       1.492246  {'mse_score': [0.6555347035833681, 0.476021533...   \n",
       "5      51.797212  {'mse_score': [0.8120496178211589, 0.557388719...   \n",
       "6       0.150168  {'mse_score': [0.9928374904980006, 0.683205912...   \n",
       "7      13.772108  {'mse_score': [0.6182489690113672, 0.611846183...   \n",
       "8      13.395208  {'mse_score': [1.0761740236083321, 1.312529050...   \n",
       "9       0.090095  {'mse_score': [1.1119234898099377, 0.676686264...   \n",
       "10      0.015288  {'mse_score': [1.1801224687295142, 0.950415342...   \n",
       "11      0.831400  {'mse_score': [1.0976792354702392, 0.671636024...   \n",
       "12      0.007751  {'mse_score': [1.3936376654364884, 1.040563386...   \n",
       "13      0.836634  {'mse_score': [1.0998622817940762, 0.677003376...   \n",
       "14     31.880319  {'mse_score': [1.0063871308109065, 0.650126838...   \n",
       "15      0.837817  {'mse_score': [0.9972977744677737, 0.552858876...   \n",
       "16      1.991491  {'mse_score': [1.015361101896433, 0.6385197295...   \n",
       "17     11.830576  {'mse_score': [1.0002425052752673, 0.852160951...   \n",
       "18     11.706139  {'mse_score': [0.9261003635990263, 0.764287381...   \n",
       "19      0.050071  {'mse_score': [1.081409082021159, 0.7876511651...   \n",
       "20           NaN                                               None   \n",
       "21           NaN                                               None   \n",
       "22           NaN                                               None   \n",
       "23           NaN                                               None   \n",
       "\n",
       "                                          results_org  \n",
       "0   {'mse_score': [0.6598317562332855, 0.489743104...  \n",
       "1   {'mse_score': [1.1801224892206006, 0.950415348...  \n",
       "2   {'mse_score': [0.6679134155298025, 0.478566167...  \n",
       "3   {'mse_score': [1.39363767778841, 1.04056338628...  \n",
       "4   {'mse_score': [0.655534699980677, 0.4760215269...  \n",
       "5   {'mse_score': [0.8120496171306019, 0.557388722...  \n",
       "6   {'mse_score': [0.9928374937104268, 0.683205911...  \n",
       "7   {'mse_score': [0.6182489748896371, 0.611846177...  \n",
       "8   {'mse_score': [1.076174034182812, 1.3125290559...  \n",
       "9   {'mse_score': [1.111923487408025, 0.6766862634...  \n",
       "10  {'mse_score': [1.1801224777332378, 0.950415341...  \n",
       "11  {'mse_score': [1.0976792337396566, 0.671636022...  \n",
       "12  {'mse_score': [1.39363767778841, 1.04056338628...  \n",
       "13  {'mse_score': [1.0998622798698838, 0.677003374...  \n",
       "14  {'mse_score': [1.0063871300392733, 0.650126843...  \n",
       "15  {'mse_score': [0.9972977727407778, 0.552858879...  \n",
       "16  {'mse_score': [1.0153611005115688, 0.638519728...  \n",
       "17  {'mse_score': [1.0002425013137521, 0.852160952...  \n",
       "18  {'mse_score': [0.9261003504544436, 0.764287386...  \n",
       "19  {'mse_score': [1.0814090864925796, 0.787651164...  \n",
       "20                                               None  \n",
       "21                                               None  \n",
       "22                                               None  \n",
       "23                                               None  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_dict_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metric_table(\n",
    "    results_list,\n",
    "    targets,\n",
    "    metric_name,\n",
    "    source=\"Adjusted\",\n",
    "    float_format=\"%.3f\",\n",
    "    csv_filename=None,\n",
    "    sort_order=\"ascending\"  # or \"descending\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a LaTeX table for a single metric across targets, models, and imputers.\n",
    "    Optionally export the same table as CSV and sort by mean performance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results_list : list of dict\n",
    "        List of experiment results.\n",
    "    targets : list of str\n",
    "        Target names (e.g., ['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN']).\n",
    "    metric_name : str\n",
    "        Metric to extract (e.g., 'mae_score').\n",
    "    source : str\n",
    "        'Adjusted' or 'Original'.\n",
    "    float_format : str\n",
    "        Format for floats (e.g., '%.3f').\n",
    "    csv_filename : str or None\n",
    "        If provided, saves the table to CSV.\n",
    "    sort_order : str\n",
    "        'ascending' or 'descending' for sorting by mean.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        LaTeX-formatted table string.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    version_key = \"results_adj\" if source.lower() == \"adjusted\" else \"results_org\"\n",
    "\n",
    "    for res in results_list:\n",
    "        result_block = res.get(version_key)\n",
    "        if result_block is None:\n",
    "            continue\n",
    "\n",
    "        metric_values = result_block.get(metric_name)\n",
    "        if metric_values is None:\n",
    "            continue\n",
    "\n",
    "        if len(metric_values) != len(targets):\n",
    "            continue\n",
    "\n",
    "        ordinal_imputer = res[\"params\"].get(\"ordinal_imputer\")\n",
    "        model = res[\"params\"].get(\"model\")\n",
    "\n",
    "        values = np.array(metric_values, dtype=np.float64)\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "\n",
    "        row = {\n",
    "            \"Ordinal Imputer\": ordinal_imputer,\n",
    "            \"Model\": model,\n",
    "            \"Mean\": mean_val,  # for sorting\n",
    "            \"Mean  SD\": f\"{mean_val:.3f}  {std_val:.3f}\",\n",
    "        }\n",
    "        row.update({target: val for target, val in zip(targets, values)})\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Reorder columns for display\n",
    "    display_cols = [\"Ordinal Imputer\", \"Model\"] + targets + [\"Mean  SD\"]\n",
    "    df = df.sort_values(by=\"Mean\", ascending=(sort_order == \"ascending\"))\n",
    "    df = df[display_cols]\n",
    "\n",
    "    # Save CSV\n",
    "    if csv_filename:\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    # LaTeX output\n",
    "    latex_table = df.to_latex(\n",
    "        index=False,\n",
    "        escape=False,\n",
    "        float_format=float_format,\n",
    "        caption=f\"{metric_name.replace('_', ' ').upper()} across targets\",\n",
    "        label=f\"tab:{metric_name}\",\n",
    "        longtable=False\n",
    "    )\n",
    "\n",
    "    return df, latex_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{CORR across targets}\n",
      "\\label{tab:corr}\n",
      "\\begin{tabular}{llrrrrl}\n",
      "\\toprule\n",
      "Ordinal Imputer & Model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & Mean  SD \\\\\n",
      "\\midrule\n",
      "SimpleImputer_most_frequent & TabNetRegressor_default & 0.773 & 0.676 & 0.581 & 0.819 & 0.712  0.092 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskLasso_tuned & 0.619 & 0.707 & 0.377 & 0.675 & 0.594  0.130 \\\\\n",
      "SimpleImputer_most_frequent & LinearRegression & 0.606 & 0.692 & 0.402 & 0.666 & 0.592  0.114 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskElasticNet_tuned & 0.608 & 0.705 & 0.382 & 0.669 & 0.591  0.126 \\\\\n",
      "SimpleImputer_most_frequent & RandomForestRegressor & 0.635 & 0.677 & 0.343 & 0.627 & 0.570  0.133 \\\\\n",
      "NoImputer & XGBoostRegressor_tuned & 0.481 & 0.591 & 0.307 & 0.656 & 0.509  0.132 \\\\\n",
      "NoImputer & RandomForestRegressor & 0.540 & 0.644 & 0.217 & 0.610 & 0.503  0.169 \\\\\n",
      "NoImputer & XGBoostRegressor & 0.522 & 0.698 & 0.212 & 0.566 & 0.500  0.178 \\\\\n",
      "NoImputer & TabNetRegressor_custom & 0.553 & 0.581 & 0.237 & 0.597 & 0.492  0.148 \\\\\n",
      "NoImputer & TabNetRegressor_default & 0.629 & 0.471 & 0.067 & 0.730 & 0.474  0.253 \\\\\n",
      "SimpleImputer_most_frequent & PLSRegression_4_components & 0.510 & 0.556 & 0.074 & 0.527 & 0.417  0.198 \\\\\n",
      "SimpleImputer_most_frequent & TabNetRegressor_custom & 0.540 & 0.307 & -0.069 & 0.586 & 0.341  0.259 \\\\\n",
      "NoImputer & MultiTaskLasso_tuned & 0.340 & 0.549 & 0.014 & 0.391 & 0.324  0.195 \\\\\n",
      "NoImputer & MultiTaskElasticNet_tuned & 0.338 & 0.551 & 0.010 & 0.392 & 0.323  0.197 \\\\\n",
      "NoImputer & PLSRegression_4_components & 0.433 & 0.445 & -0.054 & 0.457 & 0.321  0.216 \\\\\n",
      "NoImputer & LinearRegression & 0.332 & 0.548 & 0.016 & 0.381 & 0.319  0.192 \\\\\n",
      "NoImputer & MultiTaskElasticNet & 0.422 & 0.179 & -0.163 & 0.446 & 0.221  0.245 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskElasticNet & 0.422 & 0.179 & -0.163 & 0.446 & 0.221  0.245 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskLasso & NaN & NaN & NaN & NaN & nan  nan \\\\\n",
      "NoImputer & MultiTaskLasso & NaN & NaN & NaN & NaN & nan  nan \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='corr',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_corr_adjusted_sorted.csv\",\n",
    "    sort_order=\"descending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{R2 across targets}\n",
      "\\label{tab:r2}\n",
      "\\begin{tabular}{llrrrrl}\n",
      "\\toprule\n",
      "Ordinal Imputer & Model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & Mean  SD \\\\\n",
      "\\midrule\n",
      "SimpleImputer_most_frequent & LinearRegression & 0.333 & 0.444 & 0.145 & 0.310 & 0.308  0.107 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskLasso_tuned & 0.337 & 0.460 & 0.125 & 0.291 & 0.303  0.120 \\\\\n",
      "SimpleImputer_most_frequent & TabNetRegressor_default & 0.375 & 0.306 & 0.230 & 0.297 & 0.302  0.051 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskElasticNet_tuned & 0.325 & 0.457 & 0.135 & 0.279 & 0.299  0.115 \\\\\n",
      "SimpleImputer_most_frequent & RandomForestRegressor & 0.179 & 0.368 & 0.114 & 0.072 & 0.183  0.113 \\\\\n",
      "NoImputer & XGBoostRegressor_tuned & -0.026 & 0.275 & 0.032 & 0.139 & 0.105  0.115 \\\\\n",
      "NoImputer & XGBoostRegressor & -0.008 & 0.373 & -0.040 & 0.092 & 0.104  0.162 \\\\\n",
      "NoImputer & RandomForestRegressor & -0.017 & 0.262 & 0.001 & -0.000 & 0.061  0.116 \\\\\n",
      "SimpleImputer_most_frequent & PLSRegression_4_components & -0.003 & 0.225 & -0.068 & -0.071 & 0.021  0.121 \\\\\n",
      "NoImputer & TabNetRegressor_custom & 0.064 & 0.133 & -0.277 & -0.064 & -0.036  0.156 \\\\\n",
      "NoImputer & TabNetRegressor_default & -0.011 & 0.033 & -0.301 & 0.042 & -0.059  0.141 \\\\\n",
      "NoImputer & PLSRegression_4_components & -0.093 & 0.106 & -0.189 & -0.151 & -0.082  0.114 \\\\\n",
      "NoImputer & MultiTaskElasticNet_tuned & -0.109 & 0.238 & -0.289 & -0.168 & -0.082  0.196 \\\\\n",
      "NoImputer & MultiTaskLasso_tuned & -0.112 & 0.232 & -0.289 & -0.172 & -0.085  0.194 \\\\\n",
      "NoImputer & LinearRegression & -0.124 & 0.232 & -0.295 & -0.189 & -0.094  0.198 \\\\\n",
      "NoImputer & MultiTaskElasticNet & -0.193 & -0.078 & -0.059 & -0.252 & -0.146  0.080 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskElasticNet & -0.193 & -0.078 & -0.059 & -0.252 & -0.146  0.080 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskLasso & -0.409 & -0.181 & -0.020 & -0.508 & -0.279  0.191 \\\\\n",
      "NoImputer & MultiTaskLasso & -0.409 & -0.181 & -0.020 & -0.508 & -0.279  0.191 \\\\\n",
      "SimpleImputer_most_frequent & TabNetRegressor_custom & -0.088 & -0.489 & -0.619 & -0.270 & -0.366  0.204 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='r2',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_r2_adjusted_sorted.csv\",\n",
    "    sort_order=\"descending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{MSE SCORE across targets}\n",
      "\\label{tab:mse_score}\n",
      "\\begin{tabular}{llrrrrl}\n",
      "\\toprule\n",
      "Ordinal Imputer & Model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & Mean  SD \\\\\n",
      "\\midrule\n",
      "SimpleImputer_most_frequent & LinearRegression & 0.660 & 0.490 & 0.410 & 0.567 & 0.531  0.093 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskLasso_tuned & 0.656 & 0.476 & 0.419 & 0.582 & 0.533  0.092 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskElasticNet_tuned & 0.668 & 0.479 & 0.414 & 0.593 & 0.538  0.098 \\\\\n",
      "SimpleImputer_most_frequent & TabNetRegressor_default & 0.618 & 0.612 & 0.369 & 0.578 & 0.544  0.102 \\\\\n",
      "SimpleImputer_most_frequent & RandomForestRegressor & 0.812 & 0.557 & 0.424 & 0.763 & 0.639  0.156 \\\\\n",
      "NoImputer & XGBoostRegressor & 0.997 & 0.553 & 0.498 & 0.746 & 0.699  0.196 \\\\\n",
      "NoImputer & XGBoostRegressor_tuned & 1.015 & 0.639 & 0.463 & 0.707 & 0.706  0.199 \\\\\n",
      "NoImputer & RandomForestRegressor & 1.006 & 0.650 & 0.479 & 0.822 & 0.739  0.196 \\\\\n",
      "SimpleImputer_most_frequent & PLSRegression_4_components & 0.993 & 0.683 & 0.511 & 0.880 & 0.767  0.185 \\\\\n",
      "NoImputer & TabNetRegressor_custom & 0.926 & 0.764 & 0.612 & 0.875 & 0.794  0.121 \\\\\n",
      "NoImputer & TabNetRegressor_default & 1.000 & 0.852 & 0.623 & 0.787 & 0.816  0.135 \\\\\n",
      "NoImputer & MultiTaskElasticNet_tuned & 1.098 & 0.672 & 0.617 & 0.960 & 0.837  0.199 \\\\\n",
      "NoImputer & MultiTaskLasso_tuned & 1.100 & 0.677 & 0.617 & 0.963 & 0.839  0.199 \\\\\n",
      "NoImputer & PLSRegression_4_components & 1.081 & 0.788 & 0.569 & 0.946 & 0.846  0.191 \\\\\n",
      "NoImputer & LinearRegression & 1.112 & 0.677 & 0.620 & 0.978 & 0.847  0.205 \\\\\n",
      "NoImputer & MultiTaskElasticNet & 1.180 & 0.950 & 0.507 & 1.029 & 0.917  0.250 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskElasticNet & 1.180 & 0.950 & 0.507 & 1.029 & 0.917  0.250 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskLasso & 1.394 & 1.041 & 0.489 & 1.240 & 1.041  0.342 \\\\\n",
      "NoImputer & MultiTaskLasso & 1.394 & 1.041 & 0.489 & 1.240 & 1.041  0.342 \\\\\n",
      "SimpleImputer_most_frequent & TabNetRegressor_custom & 1.076 & 1.313 & 0.775 & 1.044 & 1.052  0.190 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='mse_score',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_mse_adjusted_sorted.csv\",\n",
    "    sort_order=\"ascending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{MAE SCORE across targets}\n",
      "\\label{tab:mae_score}\n",
      "\\begin{tabular}{llrrrrl}\n",
      "\\toprule\n",
      "Ordinal Imputer & Model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & Mean  SD \\\\\n",
      "\\midrule\n",
      "SimpleImputer_most_frequent & MultiTaskLasso_tuned & 0.622 & 0.551 & 0.578 & 0.595 & 0.586  0.026 \\\\\n",
      "SimpleImputer_most_frequent & LinearRegression & 0.640 & 0.551 & 0.565 & 0.600 & 0.589  0.034 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskElasticNet_tuned & 0.630 & 0.554 & 0.580 & 0.600 & 0.591  0.028 \\\\\n",
      "SimpleImputer_most_frequent & TabNetRegressor_default & 0.691 & 0.608 & 0.536 & 0.595 & 0.607  0.055 \\\\\n",
      "SimpleImputer_most_frequent & RandomForestRegressor & 0.669 & 0.640 & 0.608 & 0.648 & 0.641  0.022 \\\\\n",
      "NoImputer & XGBoostRegressor & 0.754 & 0.635 & 0.643 & 0.644 & 0.669  0.049 \\\\\n",
      "NoImputer & XGBoostRegressor_tuned & 0.735 & 0.715 & 0.630 & 0.613 & 0.673  0.052 \\\\\n",
      "NoImputer & RandomForestRegressor & 0.755 & 0.684 & 0.635 & 0.632 & 0.677  0.050 \\\\\n",
      "NoImputer & MultiTaskLasso_tuned & 0.724 & 0.705 & 0.713 & 0.706 & 0.712  0.008 \\\\\n",
      "NoImputer & MultiTaskElasticNet_tuned & 0.727 & 0.703 & 0.714 & 0.708 & 0.713  0.009 \\\\\n",
      "NoImputer & LinearRegression & 0.728 & 0.702 & 0.710 & 0.712 & 0.713  0.010 \\\\\n",
      "NoImputer & TabNetRegressor_custom & 0.713 & 0.758 & 0.671 & 0.724 & 0.717  0.031 \\\\\n",
      "NoImputer & TabNetRegressor_default & 0.781 & 0.801 & 0.680 & 0.672 & 0.733  0.058 \\\\\n",
      "SimpleImputer_most_frequent & PLSRegression_4_components & 0.805 & 0.738 & 0.689 & 0.764 & 0.749  0.042 \\\\\n",
      "NoImputer & PLSRegression_4_components & 0.792 & 0.791 & 0.722 & 0.735 & 0.760  0.032 \\\\\n",
      "NoImputer & MultiTaskElasticNet & 0.884 & 0.787 & 0.654 & 0.827 & 0.788  0.085 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskElasticNet & 0.884 & 0.787 & 0.654 & 0.827 & 0.788  0.085 \\\\\n",
      "SimpleImputer_most_frequent & TabNetRegressor_custom & 0.765 & 0.969 & 0.765 & 0.763 & 0.815  0.089 \\\\\n",
      "NoImputer & MultiTaskLasso & 0.991 & 0.785 & 0.621 & 0.934 & 0.833  0.144 \\\\\n",
      "SimpleImputer_most_frequent & MultiTaskLasso & 0.991 & 0.785 & 0.621 & 0.934 & 0.833  0.144 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='mae_score',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_mae_adjusted_sorted.csv\",\n",
    "    sort_order=\"ascending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "MultiTaskLasso_tuned          2\n",
       "LinearRegression              2\n",
       "MultiTaskElasticNet_tuned     2\n",
       "TabNetRegressor_default       2\n",
       "RandomForestRegressor         2\n",
       "PLSRegression_4_components    2\n",
       "TabNetRegressor_custom        2\n",
       "MultiTaskElasticNet           2\n",
       "MultiTaskLasso                2\n",
       "XGBoostRegressor_tuned        1\n",
       "XGBoostRegressor              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latex_df.Model.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
