{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.serialization.safe_globals at 0x7ad5aef7c950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from itertools import product\n",
    "import warnings\n",
    "\n",
    "# System path modification\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning imports\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, Lasso, LassoCV, MultiTaskLasso, MultiTaskLassoCV,\n",
    "    ElasticNet, ElasticNetCV, MultiTaskElasticNet, MultiTaskElasticNetCV\n",
    ")\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Custom modules\n",
    "from src.train import *\n",
    "from src.functions import *\n",
    "from src.plots import *\n",
    "from src.dataset import *\n",
    "from src.multixgboost import *\n",
    "from src.wrapper import *\n",
    "from src.debug import *\n",
    "\n",
    "# Visualizatiokn \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning and machine learning specific \n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "from pytorch_tabular.config import DataConfig, TrainerConfig, OptimizerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "\n",
    "from pytorch_tabular.models import (\n",
    "    GatedAdditiveTreeEnsembleConfig,\n",
    "    DANetConfig,\n",
    "    TabTransformerConfig,\n",
    "    FTTransformerConfig,\n",
    "    TabNetModelConfig,\n",
    ")\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Print CUDA availability for PyTorch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "from omegaconf import DictConfig\n",
    "torch.serialization.safe_globals([DictConfig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_pickle_data_palettes()\n",
    "\n",
    "results_pickle_folder = \"../pickle/\"\n",
    "\n",
    "# Unpack data\n",
    "df_X, df_y, df_all, df_FinalCombination = data[\"df_X\"], data[\"df_y\"], data[\"df_all\"], data[\"df_FinalCombination\"]\n",
    "dict_select = data[\"dict_select\"]\n",
    "\n",
    "# Unpack colormaps\n",
    "full_palette, gender_palette, dx_palette = data[\"colormaps\"].values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = list(df_X.isna().any(axis=1))\n",
    "idx_test = list(~df_X.isna().any(axis=1))\n",
    "\n",
    "set_intersect_rid = set(df_all[idx_train].RID).intersection(set(df_all[idx_test].RID))\n",
    "intersect_rid_idx = df_all.RID.isin(set_intersect_rid)\n",
    "\n",
    "for i, bool_test in enumerate(idx_test): \n",
    "    if intersect_rid_idx.iloc[i] & bool_test:\n",
    "        idx_test[i] = False\n",
    "        idx_train[i] = True\n",
    "        \n",
    "df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]] = df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]].astype(\"int\", errors='ignore')\n",
    "\n",
    "df_X_train = df_X.loc[idx_train]\n",
    "df_X_test = df_X.loc[idx_test]\n",
    "\n",
    "df_y_train = df_y.loc[idx_train]\n",
    "df_y_test = df_y.loc[idx_test]\n",
    "\n",
    "c_train = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_train]\n",
    "c_test = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3609    128_S_2002\n",
       "5631    116_S_4167\n",
       "5662    033_S_4176\n",
       "5780    098_S_4215\n",
       "5950    018_S_4349\n",
       "6069    941_S_4292\n",
       "6077    116_S_4453\n",
       "6085    135_S_4489\n",
       "6224    033_S_4505\n",
       "6400    014_S_4576\n",
       "6429    073_S_4300\n",
       "7021    003_S_2374\n",
       "7192    033_S_4179\n",
       "Name: SubjectID, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.SubjectID.iloc[idx_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define all the models and combinations to try out with their hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42\n",
    "\n",
    "# Continuous Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "continuous_imputer_list = [\n",
    "    (\"KNNImputer_5\", KNNImputer(n_neighbors=5)),\n",
    "]\n",
    "\n",
    "# Ordinal Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "ordinal_imputer_list = [\n",
    "    (\"KNNImputer1\", KNNImputer(n_neighbors=1)),\n",
    "]\n",
    "\n",
    "# Predictive Models List (list of tuples with unique strings and corresponding instances)\n",
    "predictive_models_list = [\n",
    "    (\"LinearRegression\", LinearRegression()),\n",
    "    (\"MultiTaskElasticNet\", MultiTaskElasticNet()),\n",
    "    (\"MultiTaskElasticNet_tuned\", MultiTaskElasticNet(**{'alpha': 0.1, 'l1_ratio': 0.1})),\n",
    "    (\"MultiTaskLasso\", MultiTaskLasso()),\n",
    "    (\"MultiTaskLasso_tuned\", MultiTaskLasso(**{'alpha': 0.001})),\n",
    "    (\"RandomForestRegressor\", RandomForestRegressor()),\n",
    "    (\"XGBoostRegressor\", XGBoostRegressor()),\n",
    "    (\"XGBoostRegressor_tuned\", XGBoostRegressor(**{'colsample_bytree': 0.8776807051588262, 'learning_rate': 0.13329520360246094, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.5924272277627636})),\n",
    "    (\"TabNetRegressor_default\", TabNetModelWrapper(n_a=8, n_d=8)),\n",
    "    (\"TabNetRegressor_custom\", TabNetModelWrapper(n_a=32, n_d=32)),\n",
    "    (\"PLSRegression_4_components\", PLSRegression(n_components=4))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['APOE_epsilon2', 'APOE_epsilon3', 'APOE_epsilon4']\n",
    "continuous_features = [col for col in df_X_train.columns if col not in ordinal_features]\n",
    "\n",
    "# Prepare Tabular configurations (shared for all PyTorch models)\n",
    "data_config = DataConfig(\n",
    "    target=df_y_train.columns.tolist(),\n",
    "    continuous_cols=continuous_features,\n",
    "    categorical_cols=ordinal_features\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024, max_epochs=10, auto_lr_find=False,\n",
    "    early_stopping=\"valid_loss\", early_stopping_mode=\"min\", early_stopping_patience=5,\n",
    "    checkpoints=\"valid_loss\", load_best=True, progress_bar=\"nones\",\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "head_config = LinearHeadConfig(dropout=0.1).__dict__\n",
    "\n",
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabNetModelConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: LinearRegression\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskElasticNet\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskElasticNet_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskLasso\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: MultiTaskLasso_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: RandomForestRegressor\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: XGBoostRegressor\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: XGBoostRegressor_tuned\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabNetRegressor_default\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabNetRegressor_custom\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: PLSRegression_4_components\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: GatedAdditiveTreeEnsembleConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: DANetConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabTransformerConfig_tab\n",
      "Continuous Imputer: KNNImputer_5, Ordinal Imputer: KNNImputer1, Model: TabNetModelConfig_tab\n",
      "Combinations of preprocessing and models to test : 15\n"
     ]
    }
   ],
   "source": [
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "# Display all combinations\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    print(f\"Continuous Imputer: {continuous_imputer[0]}, Ordinal Imputer: {ordinal_imputer[0]}, Model: {model[0]}\")\n",
    "\n",
    "print(f\"Combinations of preprocessing and models to test : {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HDF5 file\n",
    "results_file = '../pickle/training_2_dict_results.pickle'\n",
    "\n",
    "if os.path.exists(results_file): \n",
    "\n",
    "    with open(results_file, \"rb\") as input_file:\n",
    "        all_dict_results = pickle.load(input_file)\n",
    "\n",
    "else : \n",
    "    all_dict_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in all_dict_results:\n",
    "    print(result[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False : \n",
    "    params_comb = [{'ordinal_imputer': 'SimpleImputer_most_frequent', 'continuous_imputer': 'KNNImputer', 'model': 'GatedAdditiveTreeEnsembleConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "    {'ordinal_imputer': 'SimpleImputer_most_frequent', 'continuous_imputer': 'KNNImputer', 'model': 'DANetConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "    {'ordinal_imputer': 'SimpleImputer_most_frequent', 'continuous_imputer': 'KNNImputer', 'model': 'TabTransformerConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "    {'ordinal_imputer': 'SimpleImputer_most_frequent', 'continuous_imputer': 'KNNImputer', 'model': 'TabNetModelConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "    {'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'GatedAdditiveTreeEnsembleConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "    {'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'DANetConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "    {'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'TabTransformerConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]},\n",
    "    {'ordinal_imputer': 'NoImputer', 'continuous_imputer': 'NoImputer', 'model': 'TabNetModelConfig_tab', 'train_shape': [2893, 348], 'test_shape': [1, 348]}]\n",
    "\n",
    "    for params in params_comb:\n",
    "        all_dict_results = clean_dict_list(all_dict_results, remove_if_none=False, remove_key_val={\"params\": params})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict_results = clean_dict_list(all_dict_results, remove_if_none=False, remove_key_val={'fitting_time':None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training :LinearRegression\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "Training :MultiTaskElasticNet\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "Training :MultiTaskElasticNet_tuned\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "Training :MultiTaskLasso\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "Training :MultiTaskLasso_tuned\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "Training :RandomForestRegressor\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "Training :XGBoostRegressor\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "Training :XGBoostRegressor_tuned\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "Training :TabNetRegressor_default\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "epoch 0  | loss: 2.53895 |  0:00:00s\n",
      "epoch 1  | loss: 1.58979 |  0:00:00s\n",
      "epoch 2  | loss: 1.22013 |  0:00:00s\n",
      "epoch 3  | loss: 1.00636 |  0:00:00s\n",
      "epoch 4  | loss: 0.95021 |  0:00:00s\n",
      "epoch 5  | loss: 0.90679 |  0:00:00s\n",
      "epoch 6  | loss: 0.8647  |  0:00:00s\n",
      "epoch 7  | loss: 0.83772 |  0:00:00s\n",
      "epoch 8  | loss: 0.81759 |  0:00:00s\n",
      "epoch 9  | loss: 0.8123  |  0:00:00s\n",
      "epoch 10 | loss: 0.80257 |  0:00:00s\n",
      "epoch 11 | loss: 0.79333 |  0:00:00s\n",
      "epoch 12 | loss: 0.79088 |  0:00:00s\n",
      "epoch 13 | loss: 0.771   |  0:00:01s\n",
      "epoch 14 | loss: 0.76155 |  0:00:01s\n",
      "epoch 15 | loss: 0.75178 |  0:00:01s\n",
      "epoch 16 | loss: 0.75811 |  0:00:01s\n",
      "epoch 17 | loss: 0.74076 |  0:00:01s\n",
      "epoch 18 | loss: 0.73147 |  0:00:01s\n",
      "epoch 19 | loss: 0.72248 |  0:00:01s\n",
      "epoch 20 | loss: 0.71376 |  0:00:01s\n",
      "epoch 21 | loss: 0.70822 |  0:00:01s\n",
      "epoch 22 | loss: 0.70477 |  0:00:01s\n",
      "epoch 23 | loss: 0.70551 |  0:00:01s\n",
      "epoch 24 | loss: 0.69895 |  0:00:01s\n",
      "epoch 25 | loss: 0.70659 |  0:00:01s\n",
      "epoch 26 | loss: 0.68795 |  0:00:01s\n",
      "epoch 27 | loss: 0.68278 |  0:00:01s\n",
      "epoch 28 | loss: 0.67914 |  0:00:01s\n",
      "epoch 29 | loss: 0.67351 |  0:00:02s\n",
      "epoch 30 | loss: 0.66812 |  0:00:02s\n",
      "epoch 31 | loss: 0.66132 |  0:00:02s\n",
      "epoch 32 | loss: 0.65229 |  0:00:02s\n",
      "epoch 33 | loss: 0.65142 |  0:00:02s\n",
      "epoch 34 | loss: 0.63801 |  0:00:02s\n",
      "epoch 35 | loss: 0.65051 |  0:00:02s\n",
      "epoch 36 | loss: 0.63905 |  0:00:02s\n",
      "epoch 37 | loss: 0.64138 |  0:00:02s\n",
      "epoch 38 | loss: 0.63212 |  0:00:02s\n",
      "epoch 39 | loss: 0.6388  |  0:00:02s\n",
      "epoch 40 | loss: 0.62923 |  0:00:02s\n",
      "epoch 41 | loss: 0.61638 |  0:00:02s\n",
      "epoch 42 | loss: 0.62465 |  0:00:02s\n",
      "epoch 43 | loss: 0.61361 |  0:00:02s\n",
      "epoch 44 | loss: 0.61305 |  0:00:02s\n",
      "epoch 45 | loss: 0.59776 |  0:00:02s\n",
      "epoch 46 | loss: 0.59112 |  0:00:02s\n",
      "epoch 47 | loss: 0.59377 |  0:00:02s\n",
      "epoch 48 | loss: 0.59048 |  0:00:03s\n",
      "epoch 49 | loss: 0.58749 |  0:00:03s\n",
      "epoch 50 | loss: 0.584   |  0:00:03s\n",
      "epoch 51 | loss: 0.57739 |  0:00:03s\n",
      "epoch 52 | loss: 0.57936 |  0:00:03s\n",
      "epoch 53 | loss: 0.58466 |  0:00:03s\n",
      "epoch 54 | loss: 0.58541 |  0:00:03s\n",
      "epoch 55 | loss: 0.57982 |  0:00:03s\n",
      "epoch 56 | loss: 0.58021 |  0:00:03s\n",
      "epoch 57 | loss: 0.5761  |  0:00:03s\n",
      "epoch 58 | loss: 0.56587 |  0:00:03s\n",
      "epoch 59 | loss: 0.55698 |  0:00:03s\n",
      "epoch 60 | loss: 0.56012 |  0:00:03s\n",
      "epoch 61 | loss: 0.56762 |  0:00:03s\n",
      "epoch 62 | loss: 0.56142 |  0:00:03s\n",
      "epoch 63 | loss: 0.5669  |  0:00:03s\n",
      "epoch 64 | loss: 0.55522 |  0:00:03s\n",
      "epoch 65 | loss: 0.5463  |  0:00:03s\n",
      "epoch 66 | loss: 0.55162 |  0:00:03s\n",
      "epoch 67 | loss: 0.54693 |  0:00:03s\n",
      "epoch 68 | loss: 0.54527 |  0:00:04s\n",
      "epoch 69 | loss: 0.54841 |  0:00:04s\n",
      "epoch 70 | loss: 0.54225 |  0:00:04s\n",
      "epoch 71 | loss: 0.53946 |  0:00:04s\n",
      "epoch 72 | loss: 0.53817 |  0:00:04s\n",
      "epoch 73 | loss: 0.53069 |  0:00:04s\n",
      "epoch 74 | loss: 0.53146 |  0:00:04s\n",
      "epoch 75 | loss: 0.52696 |  0:00:04s\n",
      "epoch 76 | loss: 0.52931 |  0:00:04s\n",
      "epoch 77 | loss: 0.53118 |  0:00:04s\n",
      "epoch 78 | loss: 0.52709 |  0:00:04s\n",
      "epoch 79 | loss: 0.5261  |  0:00:04s\n",
      "epoch 80 | loss: 0.52816 |  0:00:04s\n",
      "epoch 81 | loss: 0.52204 |  0:00:04s\n",
      "epoch 82 | loss: 0.51605 |  0:00:04s\n",
      "epoch 83 | loss: 0.51544 |  0:00:04s\n",
      "epoch 84 | loss: 0.52879 |  0:00:04s\n",
      "epoch 85 | loss: 0.51752 |  0:00:04s\n",
      "epoch 86 | loss: 0.51448 |  0:00:04s\n",
      "epoch 87 | loss: 0.51884 |  0:00:05s\n",
      "epoch 88 | loss: 0.50571 |  0:00:05s\n",
      "epoch 89 | loss: 0.51112 |  0:00:05s\n",
      "epoch 90 | loss: 0.51186 |  0:00:05s\n",
      "epoch 91 | loss: 0.50695 |  0:00:05s\n",
      "epoch 92 | loss: 0.49707 |  0:00:05s\n",
      "epoch 93 | loss: 0.50154 |  0:00:05s\n",
      "epoch 94 | loss: 0.50109 |  0:00:05s\n",
      "epoch 95 | loss: 0.50164 |  0:00:05s\n",
      "epoch 96 | loss: 0.50187 |  0:00:05s\n",
      "epoch 97 | loss: 0.48838 |  0:00:05s\n",
      "epoch 98 | loss: 0.49348 |  0:00:05s\n",
      "epoch 99 | loss: 0.48616 |  0:00:05s\n",
      "epoch 100| loss: 0.47655 |  0:00:05s\n",
      "epoch 101| loss: 0.48637 |  0:00:05s\n",
      "epoch 102| loss: 0.48149 |  0:00:05s\n",
      "epoch 103| loss: 0.48537 |  0:00:05s\n",
      "epoch 104| loss: 0.48841 |  0:00:05s\n",
      "epoch 105| loss: 0.47217 |  0:00:05s\n",
      "epoch 106| loss: 0.48668 |  0:00:06s\n",
      "epoch 107| loss: 0.48104 |  0:00:06s\n",
      "epoch 108| loss: 0.47764 |  0:00:06s\n",
      "epoch 109| loss: 0.47079 |  0:00:06s\n",
      "epoch 110| loss: 0.46915 |  0:00:06s\n",
      "epoch 111| loss: 0.47424 |  0:00:06s\n",
      "epoch 112| loss: 0.46199 |  0:00:06s\n",
      "epoch 113| loss: 0.46821 |  0:00:06s\n",
      "epoch 114| loss: 0.46559 |  0:00:06s\n",
      "epoch 115| loss: 0.4668  |  0:00:06s\n",
      "epoch 116| loss: 0.4701  |  0:00:06s\n",
      "epoch 117| loss: 0.46831 |  0:00:06s\n",
      "epoch 118| loss: 0.4653  |  0:00:06s\n",
      "epoch 119| loss: 0.45464 |  0:00:06s\n",
      "epoch 120| loss: 0.46016 |  0:00:06s\n",
      "epoch 121| loss: 0.44627 |  0:00:06s\n",
      "epoch 122| loss: 0.44997 |  0:00:06s\n",
      "epoch 123| loss: 0.45093 |  0:00:06s\n",
      "epoch 124| loss: 0.45101 |  0:00:06s\n",
      "epoch 125| loss: 0.44287 |  0:00:06s\n",
      "epoch 126| loss: 0.44709 |  0:00:07s\n",
      "epoch 127| loss: 0.44954 |  0:00:07s\n",
      "epoch 128| loss: 0.43941 |  0:00:07s\n",
      "epoch 129| loss: 0.44627 |  0:00:07s\n",
      "epoch 130| loss: 0.44581 |  0:00:07s\n",
      "epoch 131| loss: 0.44395 |  0:00:07s\n",
      "epoch 132| loss: 0.4348  |  0:00:07s\n",
      "epoch 133| loss: 0.4477  |  0:00:07s\n",
      "epoch 134| loss: 0.44115 |  0:00:07s\n",
      "epoch 135| loss: 0.44936 |  0:00:07s\n",
      "epoch 136| loss: 0.44419 |  0:00:07s\n",
      "epoch 137| loss: 0.44262 |  0:00:07s\n",
      "epoch 138| loss: 0.4318  |  0:00:07s\n",
      "epoch 139| loss: 0.4306  |  0:00:07s\n",
      "epoch 140| loss: 0.43332 |  0:00:07s\n",
      "epoch 141| loss: 0.43431 |  0:00:07s\n",
      "epoch 142| loss: 0.43545 |  0:00:07s\n",
      "epoch 143| loss: 0.43248 |  0:00:07s\n",
      "epoch 144| loss: 0.42481 |  0:00:07s\n",
      "epoch 145| loss: 0.42341 |  0:00:08s\n",
      "epoch 146| loss: 0.42407 |  0:00:08s\n",
      "epoch 147| loss: 0.41812 |  0:00:08s\n",
      "epoch 148| loss: 0.41887 |  0:00:08s\n",
      "epoch 149| loss: 0.42396 |  0:00:08s\n",
      "epoch 150| loss: 0.42169 |  0:00:08s\n",
      "epoch 151| loss: 0.42026 |  0:00:08s\n",
      "epoch 152| loss: 0.42261 |  0:00:08s\n",
      "epoch 153| loss: 0.4165  |  0:00:08s\n",
      "epoch 154| loss: 0.42098 |  0:00:08s\n",
      "epoch 155| loss: 0.42152 |  0:00:08s\n",
      "epoch 156| loss: 0.41854 |  0:00:08s\n",
      "epoch 157| loss: 0.41853 |  0:00:08s\n",
      "epoch 158| loss: 0.40566 |  0:00:08s\n",
      "epoch 159| loss: 0.40829 |  0:00:08s\n",
      "epoch 160| loss: 0.41054 |  0:00:08s\n",
      "epoch 161| loss: 0.41265 |  0:00:08s\n",
      "epoch 162| loss: 0.40763 |  0:00:08s\n",
      "epoch 163| loss: 0.40775 |  0:00:08s\n",
      "epoch 164| loss: 0.40818 |  0:00:09s\n",
      "epoch 165| loss: 0.41127 |  0:00:09s\n",
      "epoch 166| loss: 0.40076 |  0:00:09s\n",
      "epoch 167| loss: 0.40151 |  0:00:09s\n",
      "epoch 168| loss: 0.40641 |  0:00:09s\n",
      "epoch 169| loss: 0.40339 |  0:00:09s\n",
      "epoch 170| loss: 0.39372 |  0:00:09s\n",
      "epoch 171| loss: 0.40011 |  0:00:09s\n",
      "epoch 172| loss: 0.39795 |  0:00:09s\n",
      "epoch 173| loss: 0.39008 |  0:00:09s\n",
      "epoch 174| loss: 0.39598 |  0:00:09s\n",
      "epoch 175| loss: 0.38575 |  0:00:09s\n",
      "epoch 176| loss: 0.38314 |  0:00:09s\n",
      "epoch 177| loss: 0.38319 |  0:00:09s\n",
      "epoch 178| loss: 0.3865  |  0:00:09s\n",
      "epoch 179| loss: 0.38564 |  0:00:09s\n",
      "epoch 180| loss: 0.38601 |  0:00:09s\n",
      "epoch 181| loss: 0.38398 |  0:00:09s\n",
      "epoch 182| loss: 0.38055 |  0:00:09s\n",
      "epoch 183| loss: 0.3794  |  0:00:09s\n",
      "epoch 184| loss: 0.38387 |  0:00:10s\n",
      "epoch 185| loss: 0.37925 |  0:00:10s\n",
      "epoch 186| loss: 0.38215 |  0:00:10s\n",
      "epoch 187| loss: 0.38904 |  0:00:10s\n",
      "epoch 188| loss: 0.37653 |  0:00:10s\n",
      "epoch 189| loss: 0.3716  |  0:00:10s\n",
      "epoch 190| loss: 0.37836 |  0:00:10s\n",
      "epoch 191| loss: 0.36798 |  0:00:10s\n",
      "epoch 192| loss: 0.37184 |  0:00:10s\n",
      "epoch 193| loss: 0.37314 |  0:00:10s\n",
      "epoch 194| loss: 0.35993 |  0:00:10s\n",
      "epoch 195| loss: 0.3681  |  0:00:10s\n",
      "epoch 196| loss: 0.37582 |  0:00:10s\n",
      "epoch 197| loss: 0.3669  |  0:00:10s\n",
      "epoch 198| loss: 0.37578 |  0:00:10s\n",
      "epoch 199| loss: 0.37043 |  0:00:10s\n",
      "epoch 200| loss: 0.36148 |  0:00:10s\n",
      "epoch 201| loss: 0.36198 |  0:00:10s\n",
      "epoch 202| loss: 0.36922 |  0:00:10s\n",
      "epoch 203| loss: 0.3638  |  0:00:11s\n",
      "epoch 204| loss: 0.36594 |  0:00:11s\n",
      "epoch 205| loss: 0.36592 |  0:00:11s\n",
      "epoch 206| loss: 0.36028 |  0:00:11s\n",
      "epoch 207| loss: 0.361   |  0:00:11s\n",
      "epoch 208| loss: 0.36358 |  0:00:11s\n",
      "epoch 209| loss: 0.35498 |  0:00:11s\n",
      "epoch 210| loss: 0.35473 |  0:00:11s\n",
      "epoch 211| loss: 0.35563 |  0:00:11s\n",
      "epoch 212| loss: 0.35624 |  0:00:11s\n",
      "epoch 213| loss: 0.35605 |  0:00:11s\n",
      "epoch 214| loss: 0.35689 |  0:00:11s\n",
      "epoch 215| loss: 0.36146 |  0:00:11s\n",
      "epoch 216| loss: 0.35405 |  0:00:11s\n",
      "epoch 217| loss: 0.35671 |  0:00:11s\n",
      "epoch 218| loss: 0.35028 |  0:00:11s\n",
      "epoch 219| loss: 0.35272 |  0:00:11s\n",
      "epoch 220| loss: 0.3451  |  0:00:11s\n",
      "epoch 221| loss: 0.35086 |  0:00:11s\n",
      "epoch 222| loss: 0.35413 |  0:00:11s\n",
      "epoch 223| loss: 0.39038 |  0:00:11s\n",
      "epoch 224| loss: 0.40459 |  0:00:12s\n",
      "epoch 225| loss: 0.40711 |  0:00:12s\n",
      "epoch 226| loss: 0.39494 |  0:00:12s\n",
      "epoch 227| loss: 0.38517 |  0:00:12s\n",
      "epoch 228| loss: 0.38091 |  0:00:12s\n",
      "epoch 229| loss: 0.37346 |  0:00:12s\n",
      "epoch 230| loss: 0.36588 |  0:00:12s\n",
      "epoch 231| loss: 0.35726 |  0:00:12s\n",
      "epoch 232| loss: 0.35625 |  0:00:12s\n",
      "epoch 233| loss: 0.35376 |  0:00:12s\n",
      "epoch 234| loss: 0.35096 |  0:00:12s\n",
      "epoch 235| loss: 0.35674 |  0:00:12s\n",
      "epoch 236| loss: 0.35013 |  0:00:12s\n",
      "epoch 237| loss: 0.35383 |  0:00:12s\n",
      "epoch 238| loss: 0.34891 |  0:00:12s\n",
      "epoch 239| loss: 0.35312 |  0:00:12s\n",
      "epoch 240| loss: 0.34764 |  0:00:12s\n",
      "epoch 241| loss: 0.35234 |  0:00:12s\n",
      "epoch 242| loss: 0.34757 |  0:00:12s\n",
      "epoch 243| loss: 0.34519 |  0:00:12s\n",
      "epoch 244| loss: 0.34853 |  0:00:12s\n",
      "epoch 245| loss: 0.34859 |  0:00:12s\n",
      "epoch 246| loss: 0.35755 |  0:00:13s\n",
      "epoch 247| loss: 0.34017 |  0:00:13s\n",
      "epoch 248| loss: 0.34018 |  0:00:13s\n",
      "epoch 249| loss: 0.34686 |  0:00:13s\n",
      "Training :TabNetRegressor_custom\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "epoch 0  | loss: 4.41883 |  0:00:00s\n",
      "epoch 1  | loss: 2.24503 |  0:00:00s\n",
      "epoch 2  | loss: 1.72858 |  0:00:00s\n",
      "epoch 3  | loss: 1.2861  |  0:00:00s\n",
      "epoch 4  | loss: 1.1323  |  0:00:00s\n",
      "epoch 5  | loss: 0.99436 |  0:00:00s\n",
      "epoch 6  | loss: 0.9386  |  0:00:00s\n",
      "epoch 7  | loss: 0.86119 |  0:00:00s\n",
      "epoch 8  | loss: 0.83935 |  0:00:00s\n",
      "epoch 9  | loss: 0.8047  |  0:00:00s\n",
      "epoch 10 | loss: 0.78203 |  0:00:00s\n",
      "epoch 11 | loss: 0.74723 |  0:00:01s\n",
      "epoch 12 | loss: 0.73089 |  0:00:01s\n",
      "epoch 13 | loss: 0.69394 |  0:00:01s\n",
      "epoch 14 | loss: 0.67419 |  0:00:01s\n",
      "epoch 15 | loss: 0.6633  |  0:00:01s\n",
      "epoch 16 | loss: 0.65608 |  0:00:01s\n",
      "epoch 17 | loss: 0.66164 |  0:00:01s\n",
      "epoch 18 | loss: 0.66418 |  0:00:01s\n",
      "epoch 19 | loss: 0.64628 |  0:00:01s\n",
      "epoch 20 | loss: 0.64821 |  0:00:01s\n",
      "epoch 21 | loss: 0.64499 |  0:00:01s\n",
      "epoch 22 | loss: 0.64092 |  0:00:01s\n",
      "epoch 23 | loss: 0.63274 |  0:00:01s\n",
      "epoch 24 | loss: 0.62165 |  0:00:01s\n",
      "epoch 25 | loss: 0.6088  |  0:00:01s\n",
      "epoch 26 | loss: 0.60276 |  0:00:01s\n",
      "epoch 27 | loss: 0.59696 |  0:00:01s\n",
      "epoch 28 | loss: 0.59059 |  0:00:01s\n",
      "epoch 29 | loss: 0.58947 |  0:00:01s\n",
      "epoch 30 | loss: 0.57146 |  0:00:01s\n",
      "epoch 31 | loss: 0.57089 |  0:00:02s\n",
      "epoch 32 | loss: 0.57076 |  0:00:02s\n",
      "epoch 33 | loss: 0.55706 |  0:00:02s\n",
      "epoch 34 | loss: 0.55605 |  0:00:02s\n",
      "epoch 35 | loss: 0.54207 |  0:00:02s\n",
      "epoch 36 | loss: 0.53297 |  0:00:02s\n",
      "epoch 37 | loss: 0.54659 |  0:00:02s\n",
      "epoch 38 | loss: 0.54124 |  0:00:02s\n",
      "epoch 39 | loss: 0.53834 |  0:00:02s\n",
      "epoch 40 | loss: 0.53586 |  0:00:02s\n",
      "epoch 41 | loss: 0.5228  |  0:00:02s\n",
      "epoch 42 | loss: 0.52471 |  0:00:02s\n",
      "epoch 43 | loss: 0.51581 |  0:00:02s\n",
      "epoch 44 | loss: 0.51199 |  0:00:02s\n",
      "epoch 45 | loss: 0.51539 |  0:00:02s\n",
      "epoch 46 | loss: 0.51566 |  0:00:02s\n",
      "epoch 47 | loss: 0.52109 |  0:00:02s\n",
      "epoch 48 | loss: 0.50982 |  0:00:02s\n",
      "epoch 49 | loss: 0.49567 |  0:00:02s\n",
      "epoch 50 | loss: 0.49381 |  0:00:03s\n",
      "epoch 51 | loss: 0.49626 |  0:00:03s\n",
      "epoch 52 | loss: 0.48727 |  0:00:03s\n",
      "epoch 53 | loss: 0.47862 |  0:00:03s\n",
      "epoch 54 | loss: 0.48516 |  0:00:03s\n",
      "epoch 55 | loss: 0.47102 |  0:00:03s\n",
      "epoch 56 | loss: 0.47564 |  0:00:03s\n",
      "epoch 57 | loss: 0.48619 |  0:00:03s\n",
      "epoch 58 | loss: 0.47569 |  0:00:03s\n",
      "epoch 59 | loss: 0.48221 |  0:00:03s\n",
      "epoch 60 | loss: 0.47768 |  0:00:03s\n",
      "epoch 61 | loss: 0.4748  |  0:00:03s\n",
      "epoch 62 | loss: 0.47059 |  0:00:03s\n",
      "epoch 63 | loss: 0.46351 |  0:00:03s\n",
      "epoch 64 | loss: 0.45834 |  0:00:03s\n",
      "epoch 65 | loss: 0.45635 |  0:00:03s\n",
      "epoch 66 | loss: 0.45228 |  0:00:03s\n",
      "epoch 67 | loss: 0.45957 |  0:00:04s\n",
      "epoch 68 | loss: 0.45925 |  0:00:04s\n",
      "epoch 69 | loss: 0.45391 |  0:00:04s\n",
      "epoch 70 | loss: 0.46552 |  0:00:04s\n",
      "epoch 71 | loss: 0.45931 |  0:00:04s\n",
      "epoch 72 | loss: 0.46442 |  0:00:04s\n",
      "epoch 73 | loss: 0.45724 |  0:00:04s\n",
      "epoch 74 | loss: 0.44332 |  0:00:04s\n",
      "epoch 75 | loss: 0.44067 |  0:00:04s\n",
      "epoch 76 | loss: 0.43795 |  0:00:04s\n",
      "epoch 77 | loss: 0.44059 |  0:00:04s\n",
      "epoch 78 | loss: 0.43847 |  0:00:04s\n",
      "epoch 79 | loss: 0.43722 |  0:00:04s\n",
      "epoch 80 | loss: 0.43509 |  0:00:04s\n",
      "epoch 81 | loss: 0.41949 |  0:00:04s\n",
      "epoch 82 | loss: 0.42435 |  0:00:04s\n",
      "epoch 83 | loss: 0.42756 |  0:00:04s\n",
      "epoch 84 | loss: 0.40895 |  0:00:04s\n",
      "epoch 85 | loss: 0.41284 |  0:00:04s\n",
      "epoch 86 | loss: 0.40865 |  0:00:04s\n",
      "epoch 87 | loss: 0.4068  |  0:00:05s\n",
      "epoch 88 | loss: 0.42422 |  0:00:05s\n",
      "epoch 89 | loss: 0.42134 |  0:00:05s\n",
      "epoch 90 | loss: 0.41274 |  0:00:05s\n",
      "epoch 91 | loss: 0.40917 |  0:00:05s\n",
      "epoch 92 | loss: 0.41055 |  0:00:05s\n",
      "epoch 93 | loss: 0.40426 |  0:00:05s\n",
      "epoch 94 | loss: 0.39806 |  0:00:05s\n",
      "epoch 95 | loss: 0.39249 |  0:00:05s\n",
      "epoch 96 | loss: 0.39091 |  0:00:05s\n",
      "epoch 97 | loss: 0.40007 |  0:00:05s\n",
      "epoch 98 | loss: 0.40292 |  0:00:05s\n",
      "epoch 99 | loss: 0.39775 |  0:00:05s\n",
      "epoch 100| loss: 0.41332 |  0:00:05s\n",
      "epoch 101| loss: 0.41514 |  0:00:05s\n",
      "epoch 102| loss: 0.41201 |  0:00:05s\n",
      "epoch 103| loss: 0.41414 |  0:00:05s\n",
      "epoch 104| loss: 0.41477 |  0:00:05s\n",
      "epoch 105| loss: 0.41338 |  0:00:05s\n",
      "epoch 106| loss: 0.42628 |  0:00:06s\n",
      "epoch 107| loss: 0.42946 |  0:00:06s\n",
      "epoch 108| loss: 0.42304 |  0:00:06s\n",
      "epoch 109| loss: 0.43085 |  0:00:06s\n",
      "epoch 110| loss: 0.42434 |  0:00:06s\n",
      "epoch 111| loss: 0.42421 |  0:00:06s\n",
      "epoch 112| loss: 0.4171  |  0:00:06s\n",
      "epoch 113| loss: 0.41351 |  0:00:06s\n",
      "epoch 114| loss: 0.40963 |  0:00:06s\n",
      "epoch 115| loss: 0.40644 |  0:00:06s\n",
      "epoch 116| loss: 0.3991  |  0:00:06s\n",
      "epoch 117| loss: 0.39265 |  0:00:07s\n",
      "epoch 118| loss: 0.40291 |  0:00:07s\n",
      "epoch 119| loss: 0.39432 |  0:00:07s\n",
      "epoch 120| loss: 0.38638 |  0:00:07s\n",
      "epoch 121| loss: 0.38346 |  0:00:07s\n",
      "epoch 122| loss: 0.38504 |  0:00:07s\n",
      "epoch 123| loss: 0.37474 |  0:00:07s\n",
      "epoch 124| loss: 0.37246 |  0:00:07s\n",
      "epoch 125| loss: 0.37242 |  0:00:07s\n",
      "epoch 126| loss: 0.36488 |  0:00:07s\n",
      "epoch 127| loss: 0.35787 |  0:00:07s\n",
      "epoch 128| loss: 0.35472 |  0:00:07s\n",
      "epoch 129| loss: 0.36266 |  0:00:07s\n",
      "epoch 130| loss: 0.37153 |  0:00:07s\n",
      "epoch 131| loss: 0.35962 |  0:00:07s\n",
      "epoch 132| loss: 0.36591 |  0:00:07s\n",
      "epoch 133| loss: 0.35999 |  0:00:07s\n",
      "epoch 134| loss: 0.35692 |  0:00:07s\n",
      "epoch 135| loss: 0.3566  |  0:00:07s\n",
      "epoch 136| loss: 0.35495 |  0:00:08s\n",
      "epoch 137| loss: 0.36169 |  0:00:08s\n",
      "epoch 138| loss: 0.36429 |  0:00:08s\n",
      "epoch 139| loss: 0.36669 |  0:00:08s\n",
      "epoch 140| loss: 0.35701 |  0:00:08s\n",
      "epoch 141| loss: 0.35258 |  0:00:08s\n",
      "epoch 142| loss: 0.35144 |  0:00:08s\n",
      "epoch 143| loss: 0.35781 |  0:00:08s\n",
      "epoch 144| loss: 0.34534 |  0:00:08s\n",
      "epoch 145| loss: 0.35024 |  0:00:08s\n",
      "epoch 146| loss: 0.34059 |  0:00:08s\n",
      "epoch 147| loss: 0.34345 |  0:00:08s\n",
      "epoch 148| loss: 0.3364  |  0:00:08s\n",
      "epoch 149| loss: 0.32689 |  0:00:08s\n",
      "epoch 150| loss: 0.32859 |  0:00:08s\n",
      "epoch 151| loss: 0.32394 |  0:00:08s\n",
      "epoch 152| loss: 0.327   |  0:00:08s\n",
      "epoch 153| loss: 0.32894 |  0:00:08s\n",
      "epoch 154| loss: 0.32559 |  0:00:09s\n",
      "epoch 155| loss: 0.32164 |  0:00:09s\n",
      "epoch 156| loss: 0.31587 |  0:00:09s\n",
      "epoch 157| loss: 0.31305 |  0:00:09s\n",
      "epoch 158| loss: 0.31088 |  0:00:09s\n",
      "epoch 159| loss: 0.31843 |  0:00:09s\n",
      "epoch 160| loss: 0.30839 |  0:00:09s\n",
      "epoch 161| loss: 0.30612 |  0:00:09s\n",
      "epoch 162| loss: 0.30573 |  0:00:09s\n",
      "epoch 163| loss: 0.30322 |  0:00:09s\n",
      "epoch 164| loss: 0.30609 |  0:00:09s\n",
      "epoch 165| loss: 0.29619 |  0:00:09s\n",
      "epoch 166| loss: 0.3014  |  0:00:09s\n",
      "epoch 167| loss: 0.30029 |  0:00:09s\n",
      "epoch 168| loss: 0.29131 |  0:00:09s\n",
      "epoch 169| loss: 0.30033 |  0:00:09s\n",
      "epoch 170| loss: 0.30081 |  0:00:09s\n",
      "epoch 171| loss: 0.29024 |  0:00:10s\n",
      "epoch 172| loss: 0.28979 |  0:00:10s\n",
      "epoch 173| loss: 0.28478 |  0:00:10s\n",
      "epoch 174| loss: 0.28638 |  0:00:10s\n",
      "epoch 175| loss: 0.28115 |  0:00:10s\n",
      "epoch 176| loss: 0.28696 |  0:00:10s\n",
      "epoch 177| loss: 0.28356 |  0:00:10s\n",
      "epoch 178| loss: 0.28297 |  0:00:10s\n",
      "epoch 179| loss: 0.27762 |  0:00:10s\n",
      "epoch 180| loss: 0.27935 |  0:00:10s\n",
      "epoch 181| loss: 0.27753 |  0:00:10s\n",
      "epoch 182| loss: 0.27989 |  0:00:10s\n",
      "epoch 183| loss: 0.28886 |  0:00:10s\n",
      "epoch 184| loss: 0.29197 |  0:00:10s\n",
      "epoch 185| loss: 0.2896  |  0:00:10s\n",
      "epoch 186| loss: 0.28758 |  0:00:10s\n",
      "epoch 187| loss: 0.28261 |  0:00:10s\n",
      "epoch 188| loss: 0.28109 |  0:00:10s\n",
      "epoch 189| loss: 0.2824  |  0:00:10s\n",
      "epoch 190| loss: 0.27569 |  0:00:10s\n",
      "epoch 191| loss: 0.27903 |  0:00:10s\n",
      "epoch 192| loss: 0.27129 |  0:00:10s\n",
      "epoch 193| loss: 0.26441 |  0:00:11s\n",
      "epoch 194| loss: 0.2698  |  0:00:11s\n",
      "epoch 195| loss: 0.26902 |  0:00:11s\n",
      "epoch 196| loss: 0.27556 |  0:00:11s\n",
      "epoch 197| loss: 0.26895 |  0:00:11s\n",
      "epoch 198| loss: 0.27531 |  0:00:11s\n",
      "epoch 199| loss: 0.27165 |  0:00:11s\n",
      "epoch 200| loss: 0.26662 |  0:00:11s\n",
      "epoch 201| loss: 0.26123 |  0:00:11s\n",
      "epoch 202| loss: 0.26919 |  0:00:11s\n",
      "epoch 203| loss: 0.26199 |  0:00:11s\n",
      "epoch 204| loss: 0.2604  |  0:00:11s\n",
      "epoch 205| loss: 0.26339 |  0:00:11s\n",
      "epoch 206| loss: 0.25942 |  0:00:11s\n",
      "epoch 207| loss: 0.25672 |  0:00:11s\n",
      "epoch 208| loss: 0.25418 |  0:00:12s\n",
      "epoch 209| loss: 0.25749 |  0:00:12s\n",
      "epoch 210| loss: 0.25041 |  0:00:12s\n",
      "epoch 211| loss: 0.24705 |  0:00:12s\n",
      "epoch 212| loss: 0.25195 |  0:00:12s\n",
      "epoch 213| loss: 0.25129 |  0:00:12s\n",
      "epoch 214| loss: 0.24974 |  0:00:12s\n",
      "epoch 215| loss: 0.25176 |  0:00:12s\n",
      "epoch 216| loss: 0.24785 |  0:00:12s\n",
      "epoch 217| loss: 0.24425 |  0:00:12s\n",
      "epoch 218| loss: 0.24406 |  0:00:12s\n",
      "epoch 219| loss: 0.23858 |  0:00:12s\n",
      "epoch 220| loss: 0.23865 |  0:00:12s\n",
      "epoch 221| loss: 0.23733 |  0:00:12s\n",
      "epoch 222| loss: 0.24381 |  0:00:12s\n",
      "epoch 223| loss: 0.24162 |  0:00:12s\n",
      "epoch 224| loss: 0.24509 |  0:00:12s\n",
      "epoch 225| loss: 0.27555 |  0:00:12s\n",
      "epoch 226| loss: 0.27649 |  0:00:12s\n",
      "epoch 227| loss: 0.26909 |  0:00:12s\n",
      "epoch 228| loss: 0.2624  |  0:00:13s\n",
      "epoch 229| loss: 0.27188 |  0:00:13s\n",
      "epoch 230| loss: 0.26387 |  0:00:13s\n",
      "epoch 231| loss: 0.27231 |  0:00:13s\n",
      "epoch 232| loss: 0.27209 |  0:00:13s\n",
      "epoch 233| loss: 0.27447 |  0:00:13s\n",
      "epoch 234| loss: 0.26799 |  0:00:13s\n",
      "epoch 235| loss: 0.2652  |  0:00:13s\n",
      "epoch 236| loss: 0.27345 |  0:00:13s\n",
      "epoch 237| loss: 0.26098 |  0:00:13s\n",
      "epoch 238| loss: 0.26013 |  0:00:13s\n",
      "epoch 239| loss: 0.26276 |  0:00:13s\n",
      "epoch 240| loss: 0.26172 |  0:00:13s\n",
      "epoch 241| loss: 0.26122 |  0:00:13s\n",
      "epoch 242| loss: 0.25676 |  0:00:13s\n",
      "epoch 243| loss: 0.25215 |  0:00:13s\n",
      "epoch 244| loss: 0.25766 |  0:00:13s\n",
      "epoch 245| loss: 0.25216 |  0:00:13s\n",
      "epoch 246| loss: 0.25488 |  0:00:13s\n",
      "epoch 247| loss: 0.24835 |  0:00:13s\n",
      "epoch 248| loss: 0.25639 |  0:00:14s\n",
      "epoch 249| loss: 0.25016 |  0:00:14s\n",
      "Training :PLSRegression_4_components\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n",
      "Training :GatedAdditiveTreeEnsembleConfig_tab\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">442</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:16\u001b[0m,\u001b[1;36m442\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">457</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:16\u001b[0m,\u001b[1;36m457\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">461</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:16\u001b[0m,\u001b[1;36m461\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">488</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model:                        \n",
       "GatedAdditiveTreeEnsembleModel                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:16\u001b[0m,\u001b[1;36m488\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model:                        \n",
       "GatedAdditiveTreeEnsembleModel                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">721</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gate.gate_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">255</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:16\u001b[0m,\u001b[1;36m721\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gate.gate_model:\u001b[1;36m255\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">740</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:16\u001b[0m,\u001b[1;36m740\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">751</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:16\u001b[0m,\u001b[1;36m751\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX 6000 Ada Generation') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                       | Params | Mode \n",
      "------------------------------------------------------------------------\n",
      "0 | _backbone        | GatedAdditiveTreesBackbone | 3.3 M  | train\n",
      "1 | _embedding_layer | Embedding1dLayer           | 530    | train\n",
      "2 | _head            | CustomHead                 | 156    | train\n",
      "3 | loss             | MSELoss                    | 0      | train\n",
      "------------------------------------------------------------------------\n",
      "3.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.3 M     Total params\n",
      "13.054    Total estimated model params size (MB)\n",
      "692       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d909174b44be43d8807bff02b12fecfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed71ca05abba4681919b6f261b0f532b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052649adde5349769980595f9f45c22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43f040dc21649f7a29927b4fbff9cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ab858310244acdbd1493f550113668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c908988f654e4cfb8fce76ece4baf060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98cb221ee34a47e4b2e56e75fabfed04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6460b185b33d44bcaac3466b93eeee05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23704591c6c4a4db91fbe328c4dea4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64f2a77b8f342bb916194a3818dddf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba4479cf9f540bfb386ccffb5885a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5d1925b6214f6bb87d8ea50605c88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">790</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:32\u001b[0m,\u001b[1;36m790\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">791</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:32\u001b[0m,\u001b[1;36m791\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training :DANetConfig_tab\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">005</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:39\u001b[0m,\u001b[1;36m005\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">019</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:39\u001b[0m,\u001b[1;36m019\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">023</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:39\u001b[0m,\u001b[1;36m023\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">052</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: DANetModel             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:39\u001b[0m,\u001b[1;36m052\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: DANetModel             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">112</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:39\u001b[0m,\u001b[1;36m112\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">121</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:39\u001b[0m,\u001b[1;36m121\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | _backbone        | DANetBackbone    | 1.8 M  | train\n",
      "1 | _embedding_layer | Embedding1dLayer | 530    | train\n",
      "2 | _head            | LinearHead       | 260    | train\n",
      "3 | loss             | MSELoss          | 0      | train\n",
      "--------------------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.082     Total estimated model params size (MB)\n",
      "159       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c32b1b31f54d3abc68308acda3c721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fa2ee7ac764f7684bf88f3ddf11e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6fbcbb236842898a7a7814f6f920ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d0e5733d0a401b89f9f827cb92c71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df48841d13fc46789cdd39dc695d6af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f476c9666a5345acae542ecffec6f76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945245a521484b18b8999fe1c59fc075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea53ead31014451962eebdd339f84ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">780</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:40\u001b[0m,\u001b[1;36m780\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">788</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:40\u001b[0m,\u001b[1;36m788\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training :TabTransformerConfig_tab\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">721</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:46\u001b[0m,\u001b[1;36m721\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">734</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:46\u001b[0m,\u001b[1;36m734\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">739</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:46\u001b[0m,\u001b[1;36m739\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabTransformerModel    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:46\u001b[0m,\u001b[1;36m768\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabTransformerModel    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">817</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:46\u001b[0m,\u001b[1;36m817\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">825</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:46\u001b[0m,\u001b[1;36m825\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                   | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | _backbone        | TabTransformerBackbone | 271 K  | train\n",
      "1 | _embedding_layer | Embedding2dLayer       | 408    | train\n",
      "2 | _head            | LinearHead             | 1.4 K  | train\n",
      "3 | loss             | MSELoss                | 0      | train\n",
      "--------------------------------------------------------------------\n",
      "273 K     Trainable params\n",
      "0         Non-trainable params\n",
      "273 K     Total params\n",
      "1.094     Total estimated model params size (MB)\n",
      "125       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea3c21b60bb41cb9b707e4402cd4d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1ea687adda46b2b00833dcb1725d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668d27c0897c409c95ea062565e7b20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f8e3039a5149489a3e811006bf4458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535e8d19cf1f4bd1aec1eaee32270453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc83ca70bd04e9f95d4f98d73da9e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc48495af7324ba19c85b23790f9f137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd2450d7c1d4937bb820ab9fdc04a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf4839d07564e558f56a43af946848a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53755410fed74bbb99127c7c095f0b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ab9a44eb014bf19e3824cddd55386e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8256022df85b4826b10be8d488e237e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">260</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:48\u001b[0m,\u001b[1;36m260\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">262</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:48\u001b[0m,\u001b[1;36m262\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training :TabNetModelConfig_tab\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">015</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:55\u001b[0m,\u001b[1;36m015\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">027</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:55\u001b[0m,\u001b[1;36m027\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">034</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:55\u001b[0m,\u001b[1;36m034\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">062</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabNetModel            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:55\u001b[0m,\u001b[1;36m062\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabNetModel            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">755</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:55\u001b[0m,\u001b[1;36m755\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">763</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:55\u001b[0m,\u001b[1;36m763\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type           | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | _embedding_layer | Identity       | 0      | train\n",
      "1 | _backbone        | TabNetBackbone | 22.7 K | train\n",
      "2 | _head            | Identity       | 0      | train\n",
      "3 | loss             | MSELoss        | 0      | train\n",
      "------------------------------------------------------------\n",
      "22.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "22.7 K    Total params\n",
      "0.091     Total estimated model params size (MB)\n",
      "111       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebd92fc60984200b695501f33f2c35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2051f7eaa5645a1afc608cb1c7f985d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4382386c1a1642e9adc69b1cd96e7f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203ee414b7af422b9978ec1b4a3106b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb744def8b94651b6e5533d47a108e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62efedfa4e574753b1df1a6259705d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79593daed5a4fc79889b43581e2a5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce3c7b590e1422d98b86ce871c6c63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2305af33a94123afe6881cf7115a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">281</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:57\u001b[0m,\u001b[1;36m281\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:45:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">284</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:45:57\u001b[0m,\u001b[1;36m284\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    name_continuous_imputer, continuous_imputer_instance = continuous_imputer\n",
    "    name_ordinal_imputer, ordinal_imputer_instance = ordinal_imputer\n",
    "    name_model, model_instance = model\n",
    "\n",
    "    params = {\n",
    "        \"ordinal_imputer\": name_ordinal_imputer, \n",
    "        \"continuous_imputer\": name_continuous_imputer, \n",
    "        \"model\": name_model, \"train_shape\" : df_X_train.shape, \n",
    "        \"test_shape\": df_X_test.shape\n",
    "    }\n",
    "    print(f\"Training :{name_model}\")\n",
    "\n",
    "    if any(result['params'] == params for result in all_dict_results):\n",
    "        # Skip this iteration if the combination exists\n",
    "        print(f\"Skipping existing combination: {params.values()}\")\n",
    "        \n",
    "        continue\n",
    "\n",
    "    try: \n",
    "    \n",
    "        # Now you can call your `train_model` function with these components\n",
    "        dict_results = train_imputer_model(\n",
    "            df_X_train, df_X_test, df_y_train, df_y_test,\n",
    "            c_train, c_test,\n",
    "            ordinal_imputer_instance, name_ordinal_imputer,\n",
    "            continuous_imputer_instance, name_continuous_imputer,\n",
    "            model_instance, name_model,\n",
    "            separate_imputers=True  # Or however you want to specify\n",
    "        )\n",
    "\n",
    "    except Exception as e:  \n",
    "\n",
    "        print(e)\n",
    "    \n",
    "        dict_results = {\n",
    "        \"params\": params, \n",
    "        \"imputation_time\": None,\n",
    "        \"fitting_time\": None, \n",
    "        \"results_adj\": None, \n",
    "        \"results_org\": None\n",
    "    }\n",
    "        \n",
    "    # Optionally keep the all_dict_results list updated\n",
    "    all_dict_results.append(dict_results)\n",
    "\n",
    "        # Save the updated results back to the pickle file\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(all_dict_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open(results_file, 'wb') as handle:\n",
    "    pickle.dump(all_dict_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/training_2_dict_results.pickle', \"rb\") as input_file:\n",
    "    dict_results_split = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'LinearRegression',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.546679735183716,\n",
       "  'fitting_time': 0.11383223533630371,\n",
       "  'results_adj': {'mse_score': array([0.90495076, 0.49760788, 0.55481313, 0.90373644]),\n",
       "   'mae_score': array([0.69934173, 0.54078073, 0.63081682, 0.76542299]),\n",
       "   'r2': array([ 0.08538623,  0.4353442 , -0.15842057, -0.09932378]),\n",
       "   'explained_variance': array([ 0.1991749 ,  0.49904245, -0.1551376 ,  0.15684105]),\n",
       "   'corr': array([0.48281869, 0.70747809, 0.19354395, 0.44611662])},\n",
       "  'results_org': {'mse_score': array([0.90495075, 0.49760787, 0.55481314, 0.90373643]),\n",
       "   'mae_score': array([0.69934172, 0.54078073, 0.63081684, 0.76542298]),\n",
       "   'r2': array([ 0.0373656 ,  0.44254187, -0.08059966, -0.05664115]),\n",
       "   'explained_variance': array([ 0.1571286 ,  0.50542817, -0.07753724,  0.18957775]),\n",
       "   'corr': array([0.44167655, 0.71204173, 0.24615771, 0.46414007])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'MultiTaskElasticNet',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.489232063293457,\n",
       "  'fitting_time': 0.018779516220092773,\n",
       "  'results_adj': {'mse_score': array([1.20906697, 0.94488291, 0.50155455, 1.04690455]),\n",
       "   'mae_score': array([0.89987272, 0.78106017, 0.65084197, 0.84097282]),\n",
       "   'r2': array([-0.22197732, -0.0721969 , -0.04721946, -0.27347643]),\n",
       "   'explained_variance': array([ 0.09083314,  0.04260419, -0.04030874,  0.11584773]),\n",
       "   'corr': array([ 0.36862199,  0.21168429, -0.1225737 ,  0.42516646])},\n",
       "  'results_org': {'mse_score': array([1.20906697, 0.94488291, 0.50155456, 1.04690452]),\n",
       "   'mae_score': array([0.89987273, 0.78106017, 0.65084199, 0.84097281]),\n",
       "   'r2': array([-0.2861357 , -0.05852961,  0.02313113, -0.22403211]),\n",
       "   'explained_variance': array([0.04309848, 0.05480813, 0.0295776 , 0.15017606]),\n",
       "   'corr': array([0.20774186, 0.23840131, 0.1745106 , 0.47244814])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'MultiTaskElasticNet_tuned',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.492828369140625,\n",
       "  'fitting_time': 1.1727585792541504,\n",
       "  'results_adj': {'mse_score': array([0.90810495, 0.55286854, 0.51893907, 0.82851883]),\n",
       "   'mae_score': array([0.70887769, 0.66168112, 0.68717562, 0.73806648]),\n",
       "   'r2': array([ 0.08219836,  0.37263768, -0.08351742, -0.00782751]),\n",
       "   'explained_variance': array([ 0.23492975,  0.4530064 , -0.07404118,  0.26702401]),\n",
       "   'corr': array([0.48510694, 0.69211641, 0.12970377, 0.51785747])},\n",
       "  'results_org': {'mse_score': array([0.90810494, 0.55286854, 0.51893908, 0.82851881]),\n",
       "   'mae_score': array([0.70887769, 0.66168112, 0.68717563, 0.73806647]),\n",
       "   'r2': array([ 0.03401035,  0.38063466, -0.0107284 ,  0.03130266]),\n",
       "   'explained_variance': array([ 0.19476071,  0.45997893, -0.00188875,  0.29548273]),\n",
       "   'corr': array([0.44353135, 0.69982104, 0.21645983, 0.5539747 ])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'MultiTaskLasso',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.539802074432373,\n",
       "  'fitting_time': 0.013393402099609375,\n",
       "  'results_adj': {'mse_score': array([1.39363767, 1.04056339, 0.48866937, 1.24000841]),\n",
       "   'mae_score': array([0.99127575, 0.78457157, 0.62110666, 0.93446712]),\n",
       "   'r2': array([-0.40851885, -0.18076941, -0.0203159 , -0.50837198]),\n",
       "   'explained_variance': array([-2.22044605e-16,  0.00000000e+00,  0.00000000e+00,  1.11022302e-16]),\n",
       "   'corr': array([nan, nan, nan, nan])},\n",
       "  'results_org': {'mse_score': array([1.39363768, 1.04056339, 0.48866939, 1.24000838]),\n",
       "   'mae_score': array([0.99127576, 0.78457157, 0.62110667, 0.93446711]),\n",
       "   'r2': array([-0.48247136, -0.16571814,  0.04822734, -0.44980754]),\n",
       "   'explained_variance': array([-0.05250375,  0.01274701,  0.06717846,  0.03882626]),\n",
       "   'corr': array([-0.0848666 ,  0.11455326,  0.2721653 ,  0.20679355])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'MultiTaskLasso_tuned',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.5328798294067383,\n",
       "  'fitting_time': 1.0734038352966309,\n",
       "  'results_adj': {'mse_score': array([0.90692505, 0.50201317, 0.54520183, 0.89984733]),\n",
       "   'mae_score': array([0.70091402, 0.55433196, 0.63429515, 0.76552797]),\n",
       "   'r2': array([ 0.08339085,  0.43034533, -0.13835268, -0.09459298]),\n",
       "   'explained_variance': array([ 0.20332613,  0.4975565 , -0.13459356,  0.16670847]),\n",
       "   'corr': array([0.4817163 , 0.70761501, 0.18600501, 0.45034094])},\n",
       "  'results_org': {'mse_score': array([0.90692505, 0.50201316, 0.54520184, 0.89984731]),\n",
       "   'mae_score': array([0.70091402, 0.55433196, 0.63429517, 0.76552796]),\n",
       "   'r2': array([ 0.03526546,  0.43760672, -0.0618799 , -0.05209404]),\n",
       "   'explained_variance': array([ 0.16149779,  0.50396115, -0.05837331,  0.19906206]),\n",
       "   'corr': array([0.44094337, 0.71238021, 0.24275908, 0.46892807])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'RandomForestRegressor',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.543470621109009,\n",
       "  'fitting_time': 39.73552131652832,\n",
       "  'results_adj': {'mse_score': array([0.84764808, 0.59065774, 0.42565947, 0.67044658]),\n",
       "   'mae_score': array([0.67142092, 0.64809394, 0.61732085, 0.59782818]),\n",
       "   'r2': array([0.14330078, 0.32975674, 0.11124545, 0.18445486]),\n",
       "   'explained_variance': array([0.38624994, 0.41333391, 0.12621144, 0.50034926]),\n",
       "   'corr': array([0.63052957, 0.6562599 , 0.35630916, 0.72898249])},\n",
       "  'results_org': {'mse_score': array([0.84764808, 0.59065774, 0.42565949, 0.67044656]),\n",
       "   'mae_score': array([0.67142093, 0.64809394, 0.61732087, 0.59782817]),\n",
       "   'r2': array([0.09832088, 0.33830033, 0.17095059, 0.21611943]),\n",
       "   'explained_variance': array([0.35402577, 0.42081215, 0.1849112 , 0.51974883]),\n",
       "   'corr': array([0.60407232, 0.66162398, 0.43324057, 0.76021186])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'XGBoostRegressor',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.513993978500366,\n",
       "  'fitting_time': 1.0943939685821533,\n",
       "  'results_adj': {'mse_score': array([0.86449674, 0.47497977, 0.46478002, 0.67842825]),\n",
       "   'mae_score': array([0.67505678, 0.588612  , 0.62721356, 0.62809435]),\n",
       "   'r2': array([0.12627221, 0.46102123, 0.02956381, 0.17474579]),\n",
       "   'explained_variance': array([0.34997438, 0.54373007, 0.03724718, 0.42375683]),\n",
       "   'corr': array([0.59233941, 0.75157234, 0.30013177, 0.65407088])},\n",
       "  'results_org': {'mse_score': array([0.86449674, 0.47497977, 0.46478004, 0.67842823]),\n",
       "   'mae_score': array([0.67505678, 0.588612  , 0.62721358, 0.62809434]),\n",
       "   'r2': array([0.08039824, 0.46789159, 0.0947562 , 0.20678733]),\n",
       "   'explained_variance': array([0.31584561, 0.54954615, 0.10192342, 0.4461302 ]),\n",
       "   'corr': array([0.56208851, 0.75150742, 0.36223933, 0.67990746])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'XGBoostRegressor_tuned',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.5420496463775635,\n",
       "  'fitting_time': 4.45147180557251,\n",
       "  'results_adj': {'mse_score': array([0.6308272 , 0.462175  , 0.5259817 , 0.51322933]),\n",
       "   'mae_score': array([0.59925489, 0.58811478, 0.65453581, 0.56229667]),\n",
       "   'r2': array([ 0.36243686,  0.47555131, -0.09822206,  0.37569719]),\n",
       "   'explained_variance': array([ 0.48461327,  0.50718105, -0.0966368 ,  0.4523102 ]),\n",
       "   'corr': array([0.70645005, 0.73189506, 0.17887866, 0.71698597])},\n",
       "  'results_org': {'mse_score': array([0.6308272 , 0.46217501, 0.52598171, 0.51322931]),\n",
       "   'mae_score': array([0.59925489, 0.58811478, 0.65453582, 0.56229666]),\n",
       "   'r2': array([ 0.32896242,  0.48223645, -0.0244452 ,  0.39993654]),\n",
       "   'explained_variance': array([ 0.45755354,  0.51346301, -0.02296644,  0.47357496]),\n",
       "   'corr': array([0.68528133, 0.73806412, 0.23856215, 0.7466399 ])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'TabNetRegressor_default',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.4944937229156494,\n",
       "  'fitting_time': 13.224292993545532,\n",
       "  'results_adj': {'mse_score': array([0.8216751 , 0.8404823 , 0.5203032 , 0.76534016]),\n",
       "   'mae_score': array([0.74490355, 0.80100554, 0.65439722, 0.73735269]),\n",
       "   'r2': array([ 0.16955109,  0.04627071, -0.08636565,  0.06902434]),\n",
       "   'explained_variance': array([ 0.48709471,  0.17130853, -0.0712552 ,  0.44659165]),\n",
       "   'corr': array([0.74875972, 0.62636679, 0.39121443, 0.73855652])},\n",
       "  'results_org': {'mse_score': array([0.82167509, 0.84048231, 0.52030322, 0.76534014]),\n",
       "   'mae_score': array([0.74490355, 0.80100555, 0.65439724, 0.73735268]),\n",
       "   'r2': array([ 0.12594944,  0.05842788, -0.01338531,  0.10517063]),\n",
       "   'explained_variance': array([0.46016528, 0.18187186, 0.00071005, 0.46807843]),\n",
       "   'corr': array([0.73393783, 0.62382313, 0.41816281, 0.73583888])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'TabNetRegressor_custom',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.5664618015289307,\n",
       "  'fitting_time': 14.135967493057251,\n",
       "  'results_adj': {'mse_score': array([0.66670096, 0.37726113, 0.27140571, 0.68236445]),\n",
       "   'mae_score': array([0.60825698, 0.5181797 , 0.41030007, 0.66762727]),\n",
       "   'r2': array([0.32618005, 0.57190652, 0.43331919, 0.16995771]),\n",
       "   'explained_variance': array([0.55059567, 0.61411643, 0.43390211, 0.34748061]),\n",
       "   'corr': array([0.74458259, 0.79524247, 0.65907645, 0.59441324])},\n",
       "  'results_org': {'mse_score': array([0.66670095, 0.37726113, 0.27140571, 0.68236443]),\n",
       "   'mae_score': array([0.60825698, 0.51817969, 0.41030008, 0.66762726]),\n",
       "   'r2': array([0.29080199, 0.57736343, 0.47138793, 0.20218515]),\n",
       "   'explained_variance': array([0.52700027, 0.61903529, 0.47193169, 0.37281551]),\n",
       "   'corr': array([0.72608774, 0.79177894, 0.68790177, 0.61490637])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'PLSRegression_4_components',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.6335606575012207,\n",
       "  'fitting_time': 0.06684541702270508,\n",
       "  'results_adj': {'mse_score': array([0.99045728, 0.65785276, 0.50080414, 0.85728069]),\n",
       "   'mae_score': array([0.8083    , 0.72508155, 0.68162059, 0.7675592 ]),\n",
       "   'r2': array([-0.00103333,  0.25350784, -0.04565266, -0.04281403]),\n",
       "   'explained_variance': array([ 0.21192405,  0.31133576, -0.0451718 ,  0.24744161]),\n",
       "   'corr': array([0.46040993, 0.56679457, 0.11538158, 0.49850043])},\n",
       "  'results_org': {'mse_score': array([0.99045729, 0.65785276, 0.50080416, 0.85728066]),\n",
       "   'mae_score': array([0.80830001, 0.72508155, 0.6816206 , 0.7675592 ]),\n",
       "   'r2': array([-0.05359132,  0.26302337,  0.02459267, -0.00232546]),\n",
       "   'explained_variance': array([0.17054712, 0.32011417, 0.02504123, 0.27666065]),\n",
       "   'corr': array([0.41373314, 0.58210874, 0.21123202, 0.54262628])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'GatedAdditiveTreeEnsembleConfig_tab',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.6853761672973633,\n",
       "  'fitting_time': 16.58865261077881,\n",
       "  'results_adj': {'mse_score': array([0.71751199, 0.59537909, 0.48069354, 0.72654929]),\n",
       "   'mae_score': array([0.62320508, 0.67862278, 0.64148972, 0.6627077 ]),\n",
       "   'r2': array([ 0.27482646,  0.32439925, -0.00366278,  0.11621035]),\n",
       "   'explained_variance': array([0.44612471, 0.32889129, 0.00528249, 0.51796476]),\n",
       "   'corr': array([0.68356181, 0.57371742, 0.14714728, 0.7666605 ])},\n",
       "  'results_org': {'mse_score': array([0.71751198, 0.59537908, 0.48069355, 0.72654927]),\n",
       "   'mae_score': array([0.62320508, 0.67862278, 0.64148973, 0.66270769]),\n",
       "   'r2': array([0.23675214, 0.33301113, 0.06376174, 0.1505246 ]),\n",
       "   'explained_variance': array([0.41704419, 0.33744592, 0.07210607, 0.5366804 ]),\n",
       "   'corr': array([0.65732853, 0.58116846, 0.27040709, 0.79265556])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'DANetConfig_tab',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.6424624919891357,\n",
       "  'fitting_time': 1.9297711849212646,\n",
       "  'results_adj': {'mse_score': array([1.20153618, 1.03300805, 0.46411184, 1.00515148]),\n",
       "   'mae_score': array([0.90988558, 0.78696006, 0.60205184, 0.8361604 ]),\n",
       "   'r2': array([-0.21436612, -0.17219606,  0.03095894, -0.22268713]),\n",
       "   'explained_variance': array([0.00681004, 0.03044085, 0.04244947, 0.02422282]),\n",
       "   'corr': array([0.08352621, 0.27506256, 0.3086047 , 0.17793547])},\n",
       "  'results_org': {'mse_score': array([1.20153619, 1.03300805, 0.46411185, 1.00515145]),\n",
       "   'mae_score': array([0.90988558, 0.78696007, 0.60205185, 0.83616039]),\n",
       "   'r2': array([-0.27812488, -0.15725408,  0.09605763, -0.17521476]),\n",
       "   'explained_variance': array([-0.04533615,  0.04279983,  0.10677625,  0.0621086 ]),\n",
       "   'corr': array([-0.05510621,  0.22606527,  0.35779884,  0.25855494])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'TabTransformerConfig_tab',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.8767473697662354,\n",
       "  'fitting_time': 1.5686109066009521,\n",
       "  'results_adj': {'mse_score': array([2.04240112, 1.47625433, 1.38090545, 0.756786  ]),\n",
       "   'mae_score': array([1.19020596, 1.05006374, 0.99672679, 0.7683889 ]),\n",
       "   'r2': array([-1.06420977, -0.67516556, -1.88325781,  0.07942979]),\n",
       "   'explained_variance': array([-0.94498394, -0.52136561, -1.54413513,  0.20298762]),\n",
       "   'corr': array([ 0.0318612 ,  0.16683373, -0.03198455,  0.51409722])},\n",
       "  'results_org': {'mse_score': array([2.04240113, 1.47625433, 1.38090549, 0.75678598]),\n",
       "   'mae_score': array([1.19020597, 1.05006373, 0.99672681, 0.76838889]),\n",
       "   'r2': array([-1.1725885 , -0.65381223, -1.689565  ,  0.11517209]),\n",
       "   'explained_variance': array([-1.04710287, -0.50197275, -1.37322404,  0.23393263]),\n",
       "   'corr': array([-0.0103213 ,  0.24968949,  0.00531154,  0.52002649])}},\n",
       " {'params': {'ordinal_imputer': 'KNNImputer1',\n",
       "   'continuous_imputer': 'KNNImputer_5',\n",
       "   'model': 'TabNetModelConfig_tab',\n",
       "   'train_shape': (2881, 256),\n",
       "   'test_shape': (13, 256)},\n",
       "  'imputation_time': 2.774425745010376,\n",
       "  'fitting_time': 2.305694818496704,\n",
       "  'results_adj': {'mse_score': array([1.46771975, 1.17941271, 0.65666346, 1.35494902]),\n",
       "   'mae_score': array([1.1126174 , 0.92068767, 0.74701429, 0.98404606]),\n",
       "   'r2': array([-0.48339199, -0.33832736, -0.3710787 , -0.64818813]),\n",
       "   'explained_variance': array([-0.31466322,  0.17539941, -0.06628935, -0.18192988]),\n",
       "   'corr': array([-0.19937232,  0.42583886,  0.15870146, -0.31780129])},\n",
       "  'results_org': {'mse_score': array([1.46771977, 1.17941273, 0.65666349, 1.35494899]),\n",
       "   'mae_score': array([1.11261741, 0.92068768, 0.7470143 , 0.98404606]),\n",
       "   'r2': array([-0.56127562, -0.32126772, -0.27897177, -0.58419516]),\n",
       "   'explained_variance': array([-0.38368796,  0.1859106 ,  0.00534232, -0.13603996]),\n",
       "   'corr': array([-0.19139578,  0.44724602,  0.21832848, -0.15155108])}}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_results_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models only on MRI features to compare performances\n",
    "\n",
    "## Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = list(df_X.isna().any(axis=1))\n",
    "idx_test = list(~df_X.isna().any(axis=1))\n",
    "\n",
    "set_intersect_rid = set(df_all[idx_train].RID).intersection(set(df_all[idx_test].RID))\n",
    "intersect_rid_idx = df_all.RID.isin(set_intersect_rid)\n",
    "\n",
    "for i, bool_test in enumerate(idx_test): \n",
    "    if intersect_rid_idx.iloc[i] & bool_test:\n",
    "        idx_test[i] = False\n",
    "        idx_train[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]] = df_X[[\"APOE_epsilon2\", \"APOE_epsilon3\", \"APOE_epsilon4\"]].astype(\"int\", errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train = df_X[dict_select[\"MRIth\"]].loc[idx_train]\n",
    "df_X_test = df_X[dict_select[\"MRIth\"]].loc[idx_test]\n",
    "\n",
    "df_y_train = df_y.loc[idx_train]\n",
    "df_y_test = df_y.loc[idx_test]\n",
    "\n",
    "c_train = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_train]\n",
    "c_test = df_all[[\"AGE\", \"PTGENDER\", \"PTEDUCAT\"]].iloc[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42\n",
    "n_imputation_iter = 10\n",
    "\n",
    "# Continuous Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "continuous_imputer_list = [\n",
    "    (\"NoImputer\", KNNImputer(n_neighbors=1)),\n",
    "\n",
    "]\n",
    "\n",
    "# Ordinal Imputer List (list of tuples with unique strings and corresponding instances)\n",
    "ordinal_imputer_list = [\n",
    "    (\"NoImputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "]\n",
    "\n",
    "# Predictive Models List (list of tuples with unique strings and corresponding instances)\n",
    "predictive_models_list = [\n",
    "    (\"LinearRegression\", LinearRegression()),\n",
    "    (\"MultiTaskElasticNet\", MultiTaskElasticNet()),\n",
    "    (\"MultiTaskElasticNet_tuned\", MultiTaskElasticNet(**{'alpha': 0.01, 'l1_ratio': 0.01})),\n",
    "    (\"MultiTaskLasso\", MultiTaskLasso()),\n",
    "    (\"MultiTaskLasso_tuned\", MultiTaskLasso(**{'alpha': 0.001})),\n",
    "    (\"RandomForestRegressor\", RandomForestRegressor()),\n",
    "    (\"XGBoostRegressor\", XGBoostRegressor()),\n",
    "    (\"XGBoostRegressor_tuned\", XGBoostRegressor(**{'colsample_bytree': 0.8776807051588262, 'learning_rate': 0.13329520360246094, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.5924272277627636})),\n",
    "    (\"TabNetRegressor_default\", TabNetModelWrapper(n_a=8, n_d=8)),\n",
    "    (\"TabNetRegressor_custom\", TabNetModelWrapper(n_a=32, n_d=32)),\n",
    "    (\"PLSRegression_4_components\", PLSRegression(n_components=4))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['APOE_epsilon2', 'APOE_epsilon3', 'APOE_epsilon4']\n",
    "continuous_features = [col for col in df_X_train.columns if col not in ordinal_features]\n",
    "\n",
    "# Prepare Tabular configurations (shared for all PyTorch models)\n",
    "data_config = DataConfig(\n",
    "    target=df_y_train.columns.tolist(),\n",
    "    continuous_cols=continuous_features,\n",
    "    categorical_cols=[]\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024, max_epochs=10, auto_lr_find=False,\n",
    "    early_stopping=\"valid_loss\", early_stopping_mode=\"min\", early_stopping_patience=5,\n",
    "    checkpoints=\"valid_loss\", load_best=True, progress_bar=\"nones\",\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "head_config = LinearHeadConfig(dropout=0.1).__dict__\n",
    "\n",
    "predictive_models_list += [\n",
    "    (\"GatedAdditiveTreeEnsembleConfig_tab\", \n",
    "    TabularModelWrapper(\n",
    "        GatedAdditiveTreeEnsembleConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        gflu_stages=6,\n",
    "        gflu_dropout=0.0,\n",
    "        tree_depth=5,\n",
    "        num_trees=20,\n",
    "        chain_trees=False,\n",
    "        share_head_weights=True), data_config, trainer_config, optimizer_config \n",
    "    )),\n",
    "    (\"DANetConfig_tab\",\n",
    "    TabularModelWrapper(\n",
    "        DANetConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_layers=8,\n",
    "        k=5,\n",
    "        dropout_rate=0.1), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabTransformerConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        embedding_initialization=\"kaiming_uniform\",\n",
    "        embedding_bias=False), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "    (\"TabNetModelConfig_tab\",\n",
    "        TabularModelWrapper(\n",
    "        TabNetModelConfig(\n",
    "        task=\"regression\",\n",
    "        head=\"LinearHead\",\n",
    "        head_config=head_config,\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=2,\n",
    "        n_shared=2), data_config, trainer_config, optimizer_config\n",
    "    )),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: LinearRegression\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskElasticNet\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskElasticNet_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskLasso\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: MultiTaskLasso_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: RandomForestRegressor\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: XGBoostRegressor\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: XGBoostRegressor_tuned\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetRegressor_default\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetRegressor_custom\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: PLSRegression_4_components\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: GatedAdditiveTreeEnsembleConfig_tab\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: DANetConfig_tab\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabTransformerConfig_tab\n",
      "Continuous Imputer: NoImputer, Ordinal Imputer: NoImputer, Model: TabNetModelConfig_tab\n",
      "Combinations of preprocessing and models to test : 15\n"
     ]
    }
   ],
   "source": [
    "# Generate all combinations\n",
    "combinations = list(product(continuous_imputer_list, ordinal_imputer_list, predictive_models_list))\n",
    "\n",
    "# Display all combinations\n",
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    print(f\"Continuous Imputer: {continuous_imputer[0]}, Ordinal Imputer: {ordinal_imputer[0]}, Model: {model[0]}\")\n",
    "\n",
    "print(f\"Combinations of preprocessing and models to test : {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HDF5 file\n",
    "results_file = '../pickle/training_2_dict_results.pickle'\n",
    "\n",
    "with open(results_file, \"rb\") as input_file:\n",
    "    all_dict_results = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "epoch 0  | loss: 3.13311 |  0:00:00s\n",
      "epoch 1  | loss: 1.67434 |  0:00:00s\n",
      "epoch 2  | loss: 1.25121 |  0:00:00s\n",
      "epoch 3  | loss: 1.15286 |  0:00:00s\n",
      "epoch 4  | loss: 1.05784 |  0:00:00s\n",
      "epoch 5  | loss: 0.96523 |  0:00:00s\n",
      "epoch 6  | loss: 0.92765 |  0:00:00s\n",
      "epoch 7  | loss: 0.89131 |  0:00:00s\n",
      "epoch 8  | loss: 0.86607 |  0:00:00s\n",
      "epoch 9  | loss: 0.82915 |  0:00:00s\n",
      "epoch 10 | loss: 0.83506 |  0:00:00s\n",
      "epoch 11 | loss: 0.7886  |  0:00:00s\n",
      "epoch 12 | loss: 0.75816 |  0:00:00s\n",
      "epoch 13 | loss: 0.76323 |  0:00:00s\n",
      "epoch 14 | loss: 0.76212 |  0:00:00s\n",
      "epoch 15 | loss: 0.75083 |  0:00:01s\n",
      "epoch 16 | loss: 0.72542 |  0:00:01s\n",
      "epoch 17 | loss: 0.71856 |  0:00:01s\n",
      "epoch 18 | loss: 0.71925 |  0:00:01s\n",
      "epoch 19 | loss: 0.70533 |  0:00:01s\n",
      "epoch 20 | loss: 0.70061 |  0:00:01s\n",
      "epoch 21 | loss: 0.69113 |  0:00:01s\n",
      "epoch 22 | loss: 0.67685 |  0:00:01s\n",
      "epoch 23 | loss: 0.67698 |  0:00:01s\n",
      "epoch 24 | loss: 0.67197 |  0:00:01s\n",
      "epoch 25 | loss: 0.66981 |  0:00:01s\n",
      "epoch 26 | loss: 0.66185 |  0:00:01s\n",
      "epoch 27 | loss: 0.65994 |  0:00:01s\n",
      "epoch 28 | loss: 0.65575 |  0:00:01s\n",
      "epoch 29 | loss: 0.65478 |  0:00:02s\n",
      "epoch 30 | loss: 0.64765 |  0:00:02s\n",
      "epoch 31 | loss: 0.64554 |  0:00:02s\n",
      "epoch 32 | loss: 0.63432 |  0:00:02s\n",
      "epoch 33 | loss: 0.62939 |  0:00:02s\n",
      "epoch 34 | loss: 0.62534 |  0:00:02s\n",
      "epoch 35 | loss: 0.62469 |  0:00:02s\n",
      "epoch 36 | loss: 0.62174 |  0:00:02s\n",
      "epoch 37 | loss: 0.61922 |  0:00:02s\n",
      "epoch 38 | loss: 0.62018 |  0:00:02s\n",
      "epoch 39 | loss: 0.62086 |  0:00:02s\n",
      "epoch 40 | loss: 0.60617 |  0:00:02s\n",
      "epoch 41 | loss: 0.60947 |  0:00:02s\n",
      "epoch 42 | loss: 0.59172 |  0:00:02s\n",
      "epoch 43 | loss: 0.58443 |  0:00:02s\n",
      "epoch 44 | loss: 0.58781 |  0:00:02s\n",
      "epoch 45 | loss: 0.57683 |  0:00:02s\n",
      "epoch 46 | loss: 0.57306 |  0:00:02s\n",
      "epoch 47 | loss: 0.57694 |  0:00:02s\n",
      "epoch 48 | loss: 0.56855 |  0:00:02s\n",
      "epoch 49 | loss: 0.56316 |  0:00:03s\n",
      "epoch 50 | loss: 0.56719 |  0:00:03s\n",
      "epoch 51 | loss: 0.56633 |  0:00:03s\n",
      "epoch 52 | loss: 0.55997 |  0:00:03s\n",
      "epoch 53 | loss: 0.56786 |  0:00:03s\n",
      "epoch 54 | loss: 0.55522 |  0:00:03s\n",
      "epoch 55 | loss: 0.55718 |  0:00:03s\n",
      "epoch 56 | loss: 0.55059 |  0:00:03s\n",
      "epoch 57 | loss: 0.55296 |  0:00:03s\n",
      "epoch 58 | loss: 0.55163 |  0:00:03s\n",
      "epoch 59 | loss: 0.54834 |  0:00:03s\n",
      "epoch 60 | loss: 0.55297 |  0:00:03s\n",
      "epoch 61 | loss: 0.5449  |  0:00:03s\n",
      "epoch 62 | loss: 0.5401  |  0:00:03s\n",
      "epoch 63 | loss: 0.53168 |  0:00:04s\n",
      "epoch 64 | loss: 0.52247 |  0:00:04s\n",
      "epoch 65 | loss: 0.52582 |  0:00:04s\n",
      "epoch 66 | loss: 0.51292 |  0:00:04s\n",
      "epoch 67 | loss: 0.51423 |  0:00:04s\n",
      "epoch 68 | loss: 0.50964 |  0:00:04s\n",
      "epoch 69 | loss: 0.50876 |  0:00:04s\n",
      "epoch 70 | loss: 0.50005 |  0:00:04s\n",
      "epoch 71 | loss: 0.50396 |  0:00:04s\n",
      "epoch 72 | loss: 0.49637 |  0:00:04s\n",
      "epoch 73 | loss: 0.49309 |  0:00:04s\n",
      "epoch 74 | loss: 0.48867 |  0:00:04s\n",
      "epoch 75 | loss: 0.48842 |  0:00:04s\n",
      "epoch 76 | loss: 0.48183 |  0:00:04s\n",
      "epoch 77 | loss: 0.48301 |  0:00:04s\n",
      "epoch 78 | loss: 0.48205 |  0:00:04s\n",
      "epoch 79 | loss: 0.48052 |  0:00:04s\n",
      "epoch 80 | loss: 0.47403 |  0:00:04s\n",
      "epoch 81 | loss: 0.48338 |  0:00:04s\n",
      "epoch 82 | loss: 0.47462 |  0:00:04s\n",
      "epoch 83 | loss: 0.47119 |  0:00:04s\n",
      "epoch 84 | loss: 0.47134 |  0:00:04s\n",
      "epoch 85 | loss: 0.4746  |  0:00:05s\n",
      "epoch 86 | loss: 0.47936 |  0:00:05s\n",
      "epoch 87 | loss: 0.48048 |  0:00:05s\n",
      "epoch 88 | loss: 0.46815 |  0:00:05s\n",
      "epoch 89 | loss: 0.47599 |  0:00:05s\n",
      "epoch 90 | loss: 0.46779 |  0:00:05s\n",
      "epoch 91 | loss: 0.46429 |  0:00:05s\n",
      "epoch 92 | loss: 0.46651 |  0:00:05s\n",
      "epoch 93 | loss: 0.46411 |  0:00:05s\n",
      "epoch 94 | loss: 0.45887 |  0:00:05s\n",
      "epoch 95 | loss: 0.46711 |  0:00:05s\n",
      "epoch 96 | loss: 0.45915 |  0:00:05s\n",
      "epoch 97 | loss: 0.46154 |  0:00:05s\n",
      "epoch 98 | loss: 0.45802 |  0:00:05s\n",
      "epoch 99 | loss: 0.45159 |  0:00:05s\n",
      "epoch 100| loss: 0.45073 |  0:00:06s\n",
      "epoch 101| loss: 0.45322 |  0:00:06s\n",
      "epoch 102| loss: 0.44542 |  0:00:06s\n",
      "epoch 103| loss: 0.44681 |  0:00:06s\n",
      "epoch 104| loss: 0.44443 |  0:00:06s\n",
      "epoch 105| loss: 0.44417 |  0:00:06s\n",
      "epoch 106| loss: 0.44086 |  0:00:06s\n",
      "epoch 107| loss: 0.44396 |  0:00:06s\n",
      "epoch 108| loss: 0.43298 |  0:00:06s\n",
      "epoch 109| loss: 0.44147 |  0:00:06s\n",
      "epoch 110| loss: 0.42825 |  0:00:06s\n",
      "epoch 111| loss: 0.43181 |  0:00:06s\n",
      "epoch 112| loss: 0.43651 |  0:00:06s\n",
      "epoch 113| loss: 0.42791 |  0:00:07s\n",
      "epoch 114| loss: 0.43285 |  0:00:07s\n",
      "epoch 115| loss: 0.43182 |  0:00:07s\n",
      "epoch 116| loss: 0.4306  |  0:00:07s\n",
      "epoch 117| loss: 0.42956 |  0:00:07s\n",
      "epoch 118| loss: 0.42473 |  0:00:07s\n",
      "epoch 119| loss: 0.42655 |  0:00:07s\n",
      "epoch 120| loss: 0.42597 |  0:00:07s\n",
      "epoch 121| loss: 0.41854 |  0:00:07s\n",
      "epoch 122| loss: 0.41561 |  0:00:07s\n",
      "epoch 123| loss: 0.41897 |  0:00:07s\n",
      "epoch 124| loss: 0.41393 |  0:00:07s\n",
      "epoch 125| loss: 0.41506 |  0:00:07s\n",
      "epoch 126| loss: 0.4127  |  0:00:07s\n",
      "epoch 127| loss: 0.41012 |  0:00:07s\n",
      "epoch 128| loss: 0.42201 |  0:00:07s\n",
      "epoch 129| loss: 0.41418 |  0:00:07s\n",
      "epoch 130| loss: 0.4124  |  0:00:07s\n",
      "epoch 131| loss: 0.40676 |  0:00:07s\n",
      "epoch 132| loss: 0.40992 |  0:00:07s\n",
      "epoch 133| loss: 0.41542 |  0:00:08s\n",
      "epoch 134| loss: 0.411   |  0:00:08s\n",
      "epoch 135| loss: 0.40383 |  0:00:08s\n",
      "epoch 136| loss: 0.40702 |  0:00:08s\n",
      "epoch 137| loss: 0.41123 |  0:00:08s\n",
      "epoch 138| loss: 0.40235 |  0:00:08s\n",
      "epoch 139| loss: 0.41131 |  0:00:08s\n",
      "epoch 140| loss: 0.40156 |  0:00:08s\n",
      "epoch 141| loss: 0.40275 |  0:00:08s\n",
      "epoch 142| loss: 0.40435 |  0:00:08s\n",
      "epoch 143| loss: 0.39838 |  0:00:08s\n",
      "epoch 144| loss: 0.39697 |  0:00:08s\n",
      "epoch 145| loss: 0.40627 |  0:00:08s\n",
      "epoch 146| loss: 0.39956 |  0:00:08s\n",
      "epoch 147| loss: 0.39254 |  0:00:08s\n",
      "epoch 148| loss: 0.39673 |  0:00:09s\n",
      "epoch 149| loss: 0.39021 |  0:00:09s\n",
      "epoch 150| loss: 0.38701 |  0:00:09s\n",
      "epoch 151| loss: 0.39155 |  0:00:09s\n",
      "epoch 152| loss: 0.38715 |  0:00:09s\n",
      "epoch 153| loss: 0.38539 |  0:00:09s\n",
      "epoch 154| loss: 0.3805  |  0:00:09s\n",
      "epoch 155| loss: 0.38658 |  0:00:09s\n",
      "epoch 156| loss: 0.38244 |  0:00:09s\n",
      "epoch 157| loss: 0.38939 |  0:00:09s\n",
      "epoch 158| loss: 0.38604 |  0:00:09s\n",
      "epoch 159| loss: 0.38263 |  0:00:09s\n",
      "epoch 160| loss: 0.383   |  0:00:09s\n",
      "epoch 161| loss: 0.38275 |  0:00:09s\n",
      "epoch 162| loss: 0.3747  |  0:00:10s\n",
      "epoch 163| loss: 0.38457 |  0:00:10s\n",
      "epoch 164| loss: 0.38214 |  0:00:10s\n",
      "epoch 165| loss: 0.38842 |  0:00:10s\n",
      "epoch 166| loss: 0.37563 |  0:00:10s\n",
      "epoch 167| loss: 0.38946 |  0:00:10s\n",
      "epoch 168| loss: 0.39004 |  0:00:10s\n",
      "epoch 169| loss: 0.38555 |  0:00:10s\n",
      "epoch 170| loss: 0.38699 |  0:00:10s\n",
      "epoch 171| loss: 0.38251 |  0:00:10s\n",
      "epoch 172| loss: 0.37322 |  0:00:10s\n",
      "epoch 173| loss: 0.37461 |  0:00:11s\n",
      "epoch 174| loss: 0.37934 |  0:00:11s\n",
      "epoch 175| loss: 0.37561 |  0:00:11s\n",
      "epoch 176| loss: 0.37233 |  0:00:11s\n",
      "epoch 177| loss: 0.36703 |  0:00:11s\n",
      "epoch 178| loss: 0.36985 |  0:00:11s\n",
      "epoch 179| loss: 0.37102 |  0:00:11s\n",
      "epoch 180| loss: 0.37611 |  0:00:11s\n",
      "epoch 181| loss: 0.36982 |  0:00:11s\n",
      "epoch 182| loss: 0.37385 |  0:00:11s\n",
      "epoch 183| loss: 0.36204 |  0:00:11s\n",
      "epoch 184| loss: 0.36449 |  0:00:11s\n",
      "epoch 185| loss: 0.36274 |  0:00:11s\n",
      "epoch 186| loss: 0.3675  |  0:00:11s\n",
      "epoch 187| loss: 0.37158 |  0:00:12s\n",
      "epoch 188| loss: 0.36024 |  0:00:12s\n",
      "epoch 189| loss: 0.36222 |  0:00:12s\n",
      "epoch 190| loss: 0.36547 |  0:00:12s\n",
      "epoch 191| loss: 0.35913 |  0:00:12s\n",
      "epoch 192| loss: 0.37019 |  0:00:12s\n",
      "epoch 193| loss: 0.3661  |  0:00:12s\n",
      "epoch 194| loss: 0.36435 |  0:00:12s\n",
      "epoch 195| loss: 0.3665  |  0:00:12s\n",
      "epoch 196| loss: 0.36435 |  0:00:12s\n",
      "epoch 197| loss: 0.36708 |  0:00:12s\n",
      "epoch 198| loss: 0.37635 |  0:00:12s\n",
      "epoch 199| loss: 0.36185 |  0:00:12s\n",
      "epoch 200| loss: 0.372   |  0:00:12s\n",
      "epoch 201| loss: 0.36781 |  0:00:12s\n",
      "epoch 202| loss: 0.37538 |  0:00:12s\n",
      "epoch 203| loss: 0.39584 |  0:00:12s\n",
      "epoch 204| loss: 0.40129 |  0:00:12s\n",
      "epoch 205| loss: 0.39697 |  0:00:12s\n",
      "epoch 206| loss: 0.39629 |  0:00:13s\n",
      "epoch 207| loss: 0.38705 |  0:00:13s\n",
      "epoch 208| loss: 0.38361 |  0:00:13s\n",
      "epoch 209| loss: 0.37977 |  0:00:13s\n",
      "epoch 210| loss: 0.3787  |  0:00:13s\n",
      "epoch 211| loss: 0.37001 |  0:00:13s\n",
      "epoch 212| loss: 0.3723  |  0:00:13s\n",
      "epoch 213| loss: 0.37208 |  0:00:13s\n",
      "epoch 214| loss: 0.36534 |  0:00:13s\n",
      "epoch 215| loss: 0.37599 |  0:00:13s\n",
      "epoch 216| loss: 0.35701 |  0:00:13s\n",
      "epoch 217| loss: 0.36111 |  0:00:13s\n",
      "epoch 218| loss: 0.35919 |  0:00:13s\n",
      "epoch 219| loss: 0.36595 |  0:00:13s\n",
      "epoch 220| loss: 0.35637 |  0:00:13s\n",
      "epoch 221| loss: 0.36044 |  0:00:13s\n",
      "epoch 222| loss: 0.34806 |  0:00:13s\n",
      "epoch 223| loss: 0.35702 |  0:00:13s\n",
      "epoch 224| loss: 0.35781 |  0:00:13s\n",
      "epoch 225| loss: 0.35377 |  0:00:14s\n",
      "epoch 226| loss: 0.35655 |  0:00:14s\n",
      "epoch 227| loss: 0.35704 |  0:00:14s\n",
      "epoch 228| loss: 0.34493 |  0:00:14s\n",
      "epoch 229| loss: 0.35773 |  0:00:14s\n",
      "epoch 230| loss: 0.34637 |  0:00:14s\n",
      "epoch 231| loss: 0.34904 |  0:00:14s\n",
      "epoch 232| loss: 0.34231 |  0:00:14s\n",
      "epoch 233| loss: 0.34362 |  0:00:14s\n",
      "epoch 234| loss: 0.34797 |  0:00:14s\n",
      "epoch 235| loss: 0.34678 |  0:00:15s\n",
      "epoch 236| loss: 0.34557 |  0:00:15s\n",
      "epoch 237| loss: 0.34948 |  0:00:15s\n",
      "epoch 238| loss: 0.34857 |  0:00:15s\n",
      "epoch 239| loss: 0.35335 |  0:00:15s\n",
      "epoch 240| loss: 0.34921 |  0:00:15s\n",
      "epoch 241| loss: 0.34684 |  0:00:15s\n",
      "epoch 242| loss: 0.34874 |  0:00:15s\n",
      "epoch 243| loss: 0.3433  |  0:00:15s\n",
      "epoch 244| loss: 0.34147 |  0:00:15s\n",
      "epoch 245| loss: 0.3383  |  0:00:15s\n",
      "epoch 246| loss: 0.34105 |  0:00:15s\n",
      "epoch 247| loss: 0.34444 |  0:00:15s\n",
      "epoch 248| loss: 0.34859 |  0:00:16s\n",
      "epoch 249| loss: 0.34221 |  0:00:16s\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "epoch 0  | loss: 4.24287 |  0:00:00s\n",
      "epoch 1  | loss: 2.15244 |  0:00:00s\n",
      "epoch 2  | loss: 1.58292 |  0:00:00s\n",
      "epoch 3  | loss: 1.26691 |  0:00:00s\n",
      "epoch 4  | loss: 1.06626 |  0:00:00s\n",
      "epoch 5  | loss: 0.9529  |  0:00:00s\n",
      "epoch 6  | loss: 0.88656 |  0:00:00s\n",
      "epoch 7  | loss: 0.84019 |  0:00:00s\n",
      "epoch 8  | loss: 0.79465 |  0:00:00s\n",
      "epoch 9  | loss: 0.76328 |  0:00:00s\n",
      "epoch 10 | loss: 0.72436 |  0:00:00s\n",
      "epoch 11 | loss: 0.69744 |  0:00:00s\n",
      "epoch 12 | loss: 0.69848 |  0:00:00s\n",
      "epoch 13 | loss: 0.68787 |  0:00:00s\n",
      "epoch 14 | loss: 0.67379 |  0:00:00s\n",
      "epoch 15 | loss: 0.67166 |  0:00:00s\n",
      "epoch 16 | loss: 0.65451 |  0:00:00s\n",
      "epoch 17 | loss: 0.66407 |  0:00:00s\n",
      "epoch 18 | loss: 0.65599 |  0:00:00s\n",
      "epoch 19 | loss: 0.65139 |  0:00:00s\n",
      "epoch 20 | loss: 0.64927 |  0:00:01s\n",
      "epoch 21 | loss: 0.64578 |  0:00:01s\n",
      "epoch 22 | loss: 0.63364 |  0:00:01s\n",
      "epoch 23 | loss: 0.62991 |  0:00:01s\n",
      "epoch 24 | loss: 0.62301 |  0:00:01s\n",
      "epoch 25 | loss: 0.62647 |  0:00:01s\n",
      "epoch 26 | loss: 0.61679 |  0:00:01s\n",
      "epoch 27 | loss: 0.60603 |  0:00:01s\n",
      "epoch 28 | loss: 0.59713 |  0:00:01s\n",
      "epoch 29 | loss: 0.59047 |  0:00:01s\n",
      "epoch 30 | loss: 0.58662 |  0:00:01s\n",
      "epoch 31 | loss: 0.59503 |  0:00:01s\n",
      "epoch 32 | loss: 0.58066 |  0:00:01s\n",
      "epoch 33 | loss: 0.5762  |  0:00:01s\n",
      "epoch 34 | loss: 0.57702 |  0:00:01s\n",
      "epoch 35 | loss: 0.5748  |  0:00:02s\n",
      "epoch 36 | loss: 0.58111 |  0:00:02s\n",
      "epoch 37 | loss: 0.56751 |  0:00:02s\n",
      "epoch 38 | loss: 0.56548 |  0:00:02s\n",
      "epoch 39 | loss: 0.56671 |  0:00:02s\n",
      "epoch 40 | loss: 0.54826 |  0:00:02s\n",
      "epoch 41 | loss: 0.55204 |  0:00:02s\n",
      "epoch 42 | loss: 0.54543 |  0:00:02s\n",
      "epoch 43 | loss: 0.54748 |  0:00:02s\n",
      "epoch 44 | loss: 0.53076 |  0:00:02s\n",
      "epoch 45 | loss: 0.534   |  0:00:02s\n",
      "epoch 46 | loss: 0.52653 |  0:00:02s\n",
      "epoch 47 | loss: 0.51791 |  0:00:02s\n",
      "epoch 48 | loss: 0.52555 |  0:00:02s\n",
      "epoch 49 | loss: 0.51958 |  0:00:02s\n",
      "epoch 50 | loss: 0.51854 |  0:00:02s\n",
      "epoch 51 | loss: 0.52509 |  0:00:02s\n",
      "epoch 52 | loss: 0.53795 |  0:00:02s\n",
      "epoch 53 | loss: 0.51252 |  0:00:02s\n",
      "epoch 54 | loss: 0.52148 |  0:00:02s\n",
      "epoch 55 | loss: 0.50706 |  0:00:03s\n",
      "epoch 56 | loss: 0.50415 |  0:00:03s\n",
      "epoch 57 | loss: 0.50179 |  0:00:03s\n",
      "epoch 58 | loss: 0.5014  |  0:00:03s\n",
      "epoch 59 | loss: 0.496   |  0:00:03s\n",
      "epoch 60 | loss: 0.49581 |  0:00:03s\n",
      "epoch 61 | loss: 0.49195 |  0:00:03s\n",
      "epoch 62 | loss: 0.49182 |  0:00:03s\n",
      "epoch 63 | loss: 0.48621 |  0:00:03s\n",
      "epoch 64 | loss: 0.48535 |  0:00:03s\n",
      "epoch 65 | loss: 0.48092 |  0:00:03s\n",
      "epoch 66 | loss: 0.48223 |  0:00:04s\n",
      "epoch 67 | loss: 0.47486 |  0:00:04s\n",
      "epoch 68 | loss: 0.48263 |  0:00:04s\n",
      "epoch 69 | loss: 0.46807 |  0:00:04s\n",
      "epoch 70 | loss: 0.47951 |  0:00:04s\n",
      "epoch 71 | loss: 0.47439 |  0:00:04s\n",
      "epoch 72 | loss: 0.46664 |  0:00:04s\n",
      "epoch 73 | loss: 0.46357 |  0:00:04s\n",
      "epoch 74 | loss: 0.45955 |  0:00:04s\n",
      "epoch 75 | loss: 0.44495 |  0:00:04s\n",
      "epoch 76 | loss: 0.45515 |  0:00:04s\n",
      "epoch 77 | loss: 0.44442 |  0:00:04s\n",
      "epoch 78 | loss: 0.44651 |  0:00:04s\n",
      "epoch 79 | loss: 0.44756 |  0:00:05s\n",
      "epoch 80 | loss: 0.43945 |  0:00:05s\n",
      "epoch 81 | loss: 0.4455  |  0:00:05s\n",
      "epoch 82 | loss: 0.42914 |  0:00:05s\n",
      "epoch 83 | loss: 0.42907 |  0:00:05s\n",
      "epoch 84 | loss: 0.42916 |  0:00:05s\n",
      "epoch 85 | loss: 0.43479 |  0:00:05s\n",
      "epoch 86 | loss: 0.4282  |  0:00:05s\n",
      "epoch 87 | loss: 0.43356 |  0:00:05s\n",
      "epoch 88 | loss: 0.4317  |  0:00:05s\n",
      "epoch 89 | loss: 0.42938 |  0:00:05s\n",
      "epoch 90 | loss: 0.42696 |  0:00:05s\n",
      "epoch 91 | loss: 0.43679 |  0:00:05s\n",
      "epoch 92 | loss: 0.43223 |  0:00:05s\n",
      "epoch 93 | loss: 0.43293 |  0:00:05s\n",
      "epoch 94 | loss: 0.43471 |  0:00:05s\n",
      "epoch 95 | loss: 0.43117 |  0:00:05s\n",
      "epoch 96 | loss: 0.43198 |  0:00:06s\n",
      "epoch 97 | loss: 0.42767 |  0:00:06s\n",
      "epoch 98 | loss: 0.44682 |  0:00:06s\n",
      "epoch 99 | loss: 0.42731 |  0:00:06s\n",
      "epoch 100| loss: 0.42579 |  0:00:06s\n",
      "epoch 101| loss: 0.42668 |  0:00:06s\n",
      "epoch 102| loss: 0.41374 |  0:00:06s\n",
      "epoch 103| loss: 0.40874 |  0:00:06s\n",
      "epoch 104| loss: 0.41486 |  0:00:06s\n",
      "epoch 105| loss: 0.4021  |  0:00:06s\n",
      "epoch 106| loss: 0.40922 |  0:00:06s\n",
      "epoch 107| loss: 0.40808 |  0:00:06s\n",
      "epoch 108| loss: 0.4061  |  0:00:06s\n",
      "epoch 109| loss: 0.40864 |  0:00:06s\n",
      "epoch 110| loss: 0.40504 |  0:00:06s\n",
      "epoch 111| loss: 0.39976 |  0:00:06s\n",
      "epoch 112| loss: 0.40696 |  0:00:06s\n",
      "epoch 113| loss: 0.38797 |  0:00:06s\n",
      "epoch 114| loss: 0.40204 |  0:00:07s\n",
      "epoch 115| loss: 0.3983  |  0:00:07s\n",
      "epoch 116| loss: 0.4002  |  0:00:07s\n",
      "epoch 117| loss: 0.40514 |  0:00:07s\n",
      "epoch 118| loss: 0.40652 |  0:00:07s\n",
      "epoch 119| loss: 0.40779 |  0:00:07s\n",
      "epoch 120| loss: 0.41209 |  0:00:07s\n",
      "epoch 121| loss: 0.40213 |  0:00:07s\n",
      "epoch 122| loss: 0.38867 |  0:00:07s\n",
      "epoch 123| loss: 0.38918 |  0:00:07s\n",
      "epoch 124| loss: 0.39164 |  0:00:08s\n",
      "epoch 125| loss: 0.37698 |  0:00:08s\n",
      "epoch 126| loss: 0.37028 |  0:00:08s\n",
      "epoch 127| loss: 0.37927 |  0:00:08s\n",
      "epoch 128| loss: 0.36095 |  0:00:08s\n",
      "epoch 129| loss: 0.36817 |  0:00:08s\n",
      "epoch 130| loss: 0.35612 |  0:00:08s\n",
      "epoch 131| loss: 0.35326 |  0:00:08s\n",
      "epoch 132| loss: 0.35904 |  0:00:08s\n",
      "epoch 133| loss: 0.35966 |  0:00:08s\n",
      "epoch 134| loss: 0.34819 |  0:00:08s\n",
      "epoch 135| loss: 0.35239 |  0:00:08s\n",
      "epoch 136| loss: 0.35978 |  0:00:08s\n",
      "epoch 137| loss: 0.35151 |  0:00:08s\n",
      "epoch 138| loss: 0.36372 |  0:00:08s\n",
      "epoch 139| loss: 0.36289 |  0:00:08s\n",
      "epoch 140| loss: 0.36773 |  0:00:08s\n",
      "epoch 141| loss: 0.36356 |  0:00:08s\n",
      "epoch 142| loss: 0.35889 |  0:00:09s\n",
      "epoch 143| loss: 0.36573 |  0:00:09s\n",
      "epoch 144| loss: 0.36685 |  0:00:09s\n",
      "epoch 145| loss: 0.36418 |  0:00:09s\n",
      "epoch 146| loss: 0.37643 |  0:00:09s\n",
      "epoch 147| loss: 0.36169 |  0:00:09s\n",
      "epoch 148| loss: 0.3599  |  0:00:09s\n",
      "epoch 149| loss: 0.36358 |  0:00:09s\n",
      "epoch 150| loss: 0.38092 |  0:00:09s\n",
      "epoch 151| loss: 0.37406 |  0:00:09s\n",
      "epoch 152| loss: 0.36953 |  0:00:09s\n",
      "epoch 153| loss: 0.37239 |  0:00:09s\n",
      "epoch 154| loss: 0.36479 |  0:00:09s\n",
      "epoch 155| loss: 0.36082 |  0:00:10s\n",
      "epoch 156| loss: 0.35538 |  0:00:10s\n",
      "epoch 157| loss: 0.34878 |  0:00:10s\n",
      "epoch 158| loss: 0.34607 |  0:00:10s\n",
      "epoch 159| loss: 0.34139 |  0:00:10s\n",
      "epoch 160| loss: 0.33437 |  0:00:10s\n",
      "epoch 161| loss: 0.33563 |  0:00:10s\n",
      "epoch 162| loss: 0.34112 |  0:00:10s\n",
      "epoch 163| loss: 0.35652 |  0:00:10s\n",
      "epoch 164| loss: 0.35128 |  0:00:10s\n",
      "epoch 165| loss: 0.34045 |  0:00:10s\n",
      "epoch 166| loss: 0.34459 |  0:00:10s\n",
      "epoch 167| loss: 0.34769 |  0:00:10s\n",
      "epoch 168| loss: 0.33172 |  0:00:10s\n",
      "epoch 169| loss: 0.33832 |  0:00:10s\n",
      "epoch 170| loss: 0.32454 |  0:00:10s\n",
      "epoch 171| loss: 0.33092 |  0:00:10s\n",
      "epoch 172| loss: 0.33065 |  0:00:11s\n",
      "epoch 173| loss: 0.31971 |  0:00:11s\n",
      "epoch 174| loss: 0.31975 |  0:00:11s\n",
      "epoch 175| loss: 0.30903 |  0:00:11s\n",
      "epoch 176| loss: 0.31415 |  0:00:11s\n",
      "epoch 177| loss: 0.32472 |  0:00:11s\n",
      "epoch 178| loss: 0.30966 |  0:00:11s\n",
      "epoch 179| loss: 0.31315 |  0:00:11s\n",
      "epoch 180| loss: 0.31162 |  0:00:11s\n",
      "epoch 181| loss: 0.32061 |  0:00:11s\n",
      "epoch 182| loss: 0.31373 |  0:00:11s\n",
      "epoch 183| loss: 0.31775 |  0:00:11s\n",
      "epoch 184| loss: 0.31597 |  0:00:11s\n",
      "epoch 185| loss: 0.3111  |  0:00:11s\n",
      "epoch 186| loss: 0.31505 |  0:00:11s\n",
      "epoch 187| loss: 0.30957 |  0:00:12s\n",
      "epoch 188| loss: 0.31093 |  0:00:12s\n",
      "epoch 189| loss: 0.31486 |  0:00:12s\n",
      "epoch 190| loss: 0.31301 |  0:00:12s\n",
      "epoch 191| loss: 0.3108  |  0:00:12s\n",
      "epoch 192| loss: 0.30916 |  0:00:12s\n",
      "epoch 193| loss: 0.30084 |  0:00:12s\n",
      "epoch 194| loss: 0.30258 |  0:00:12s\n",
      "epoch 195| loss: 0.30658 |  0:00:12s\n",
      "epoch 196| loss: 0.30231 |  0:00:12s\n",
      "epoch 197| loss: 0.29887 |  0:00:12s\n",
      "epoch 198| loss: 0.3017  |  0:00:12s\n",
      "epoch 199| loss: 0.2996  |  0:00:12s\n",
      "epoch 200| loss: 0.29747 |  0:00:13s\n",
      "epoch 201| loss: 0.302   |  0:00:13s\n",
      "epoch 202| loss: 0.29356 |  0:00:13s\n",
      "epoch 203| loss: 0.29971 |  0:00:13s\n",
      "epoch 204| loss: 0.28496 |  0:00:13s\n",
      "epoch 205| loss: 0.28985 |  0:00:13s\n",
      "epoch 206| loss: 0.28443 |  0:00:13s\n",
      "epoch 207| loss: 0.28011 |  0:00:13s\n",
      "epoch 208| loss: 0.28006 |  0:00:13s\n",
      "epoch 209| loss: 0.27741 |  0:00:13s\n",
      "epoch 210| loss: 0.27276 |  0:00:13s\n",
      "epoch 211| loss: 0.27628 |  0:00:13s\n",
      "epoch 212| loss: 0.2841  |  0:00:13s\n",
      "epoch 213| loss: 0.28351 |  0:00:13s\n",
      "epoch 214| loss: 0.28181 |  0:00:13s\n",
      "epoch 215| loss: 0.29372 |  0:00:13s\n",
      "epoch 216| loss: 0.27954 |  0:00:13s\n",
      "epoch 217| loss: 0.28504 |  0:00:14s\n",
      "epoch 218| loss: 0.281   |  0:00:14s\n",
      "epoch 219| loss: 0.28408 |  0:00:14s\n",
      "epoch 220| loss: 0.28229 |  0:00:14s\n",
      "epoch 221| loss: 0.27346 |  0:00:14s\n",
      "epoch 222| loss: 0.26955 |  0:00:14s\n",
      "epoch 223| loss: 0.27341 |  0:00:14s\n",
      "epoch 224| loss: 0.27228 |  0:00:14s\n",
      "epoch 225| loss: 0.26034 |  0:00:14s\n",
      "epoch 226| loss: 0.26504 |  0:00:14s\n",
      "epoch 227| loss: 0.26373 |  0:00:14s\n",
      "epoch 228| loss: 0.25678 |  0:00:14s\n",
      "epoch 229| loss: 0.2667  |  0:00:14s\n",
      "epoch 230| loss: 0.25775 |  0:00:14s\n",
      "epoch 231| loss: 0.26326 |  0:00:14s\n",
      "epoch 232| loss: 0.25435 |  0:00:14s\n",
      "epoch 233| loss: 0.25562 |  0:00:14s\n",
      "epoch 234| loss: 0.26014 |  0:00:15s\n",
      "epoch 235| loss: 0.2552  |  0:00:15s\n",
      "epoch 236| loss: 0.25414 |  0:00:15s\n",
      "epoch 237| loss: 0.25566 |  0:00:15s\n",
      "epoch 238| loss: 0.25705 |  0:00:15s\n",
      "epoch 239| loss: 0.25846 |  0:00:15s\n",
      "epoch 240| loss: 0.25685 |  0:00:15s\n",
      "epoch 241| loss: 0.26753 |  0:00:15s\n",
      "epoch 242| loss: 0.27538 |  0:00:15s\n",
      "epoch 243| loss: 0.27838 |  0:00:15s\n",
      "epoch 244| loss: 0.27072 |  0:00:15s\n",
      "epoch 245| loss: 0.26688 |  0:00:15s\n",
      "epoch 246| loss: 0.26624 |  0:00:15s\n",
      "epoch 247| loss: 0.26438 |  0:00:16s\n",
      "epoch 248| loss: 0.26376 |  0:00:16s\n",
      "epoch 249| loss: 0.26156 |  0:00:16s\n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n",
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">212</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:16\u001b[0m,\u001b[1;36m212\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:16\u001b[0m,\u001b[1;36m224\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">227</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:16\u001b[0m,\u001b[1;36m227\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">244</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model:                        \n",
       "GatedAdditiveTreeEnsembleModel                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:16\u001b[0m,\u001b[1;36m244\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model:                        \n",
       "GatedAdditiveTreeEnsembleModel                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">451</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gate.gate_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">255</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:16\u001b[0m,\u001b[1;36m451\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gate.gate_model:\u001b[1;36m255\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">466</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:16\u001b[0m,\u001b[1;36m466\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">478</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:16\u001b[0m,\u001b[1;36m478\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                       | Params | Mode \n",
      "------------------------------------------------------------------------\n",
      "0 | _backbone        | GatedAdditiveTreesBackbone | 2.1 M  | train\n",
      "1 | _embedding_layer | Embedding1dLayer           | 400    | train\n",
      "2 | _head            | CustomHead                 | 156    | train\n",
      "3 | loss             | MSELoss                    | 0      | train\n",
      "------------------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.417     Total estimated model params size (MB)\n",
      "689       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b737eea438894256a470381366f26132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7fa52bac8f4b229620657782737d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88dec2712dd646909f960e008d5fb0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a70924dfd74cb58de827b8cf4f6655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4988549d82254d5c9f615dbf5841de18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1896bea670f74597a58201c55d85b029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0450f715d62d4e5aac5e01c6f76376d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40df42a75da484f90fd32dc134b870e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b995cb537c6e46ebbf4c3c260d800259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5088b5bb6254c64912a5e8aad2a886c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782f49e0661843f6b153b3208fb66299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ffb36404374437841d3b9c252dc86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">626</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:33\u001b[0m,\u001b[1;36m626\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">627</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:33\u001b[0m,\u001b[1;36m627\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">130</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:34\u001b[0m,\u001b[1;36m130\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">141</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:34\u001b[0m,\u001b[1;36m141\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">145</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:34\u001b[0m,\u001b[1;36m145\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">161</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: DANetModel             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:34\u001b[0m,\u001b[1;36m161\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: DANetModel             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">190</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:34\u001b[0m,\u001b[1;36m190\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:34\u001b[0m,\u001b[1;36m198\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | _backbone        | DANetBackbone    | 1.4 M  | train\n",
      "1 | _embedding_layer | Embedding1dLayer | 400    | train\n",
      "2 | _head            | LinearHead       | 260    | train\n",
      "3 | loss             | MSELoss          | 0      | train\n",
      "--------------------------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.787     Total estimated model params size (MB)\n",
      "156       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe3d07187a341df9acaf09e77c454f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab0ad119804471189a2c28f6529525a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5caa706a904d46b946d2ead82e099e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88dd8e7a7c0c4ff98ce336b6b44f7de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d717a79200403a861acb7096b4888e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ed1d6e06b54c94a33c27005a736132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c34cf7cf5f4693bc9f867302a0a00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d75564f1f845f0870082dc3108df55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">393</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:36\u001b[0m,\u001b[1;36m393\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">395</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:36\u001b[0m,\u001b[1;36m395\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">650</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:36\u001b[0m,\u001b[1;36m650\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">663</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:36\u001b[0m,\u001b[1;36m663\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">666</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:36\u001b[0m,\u001b[1;36m666\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">682</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabTransformerModel    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:36\u001b[0m,\u001b[1;36m682\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabTransformerModel    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">703</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:36\u001b[0m,\u001b[1;36m703\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">711</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:36\u001b[0m,\u001b[1;36m711\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                   | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | _backbone        | TabTransformerBackbone | 271 K  | train\n",
      "1 | _embedding_layer | Embedding2dLayer       | 0      | train\n",
      "2 | _head            | LinearHead             | 804    | train\n",
      "3 | loss             | MSELoss                | 0      | train\n",
      "--------------------------------------------------------------------\n",
      "272 K     Trainable params\n",
      "0         Non-trainable params\n",
      "272 K     Total params\n",
      "1.090     Total estimated model params size (MB)\n",
      "119       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d09f01551b4056a2163d7d7efed8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a74c05d2f1466dbe7a8e8c4ec6d4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084af02ca58a4a87ba0f1a50a647d170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189a138bf3534917a6cfcdf55b97948f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1179105247748188a527ff510a0f02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d8b51db07843b0b4f6049ab8f45ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0cb6ac49374121b58a35f3e8282727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7fe1ad6f6f4e0b9ad34e9e1a40a9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c509356b51e44da6ae3dbe68a418a420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58577de32a8b48008709e7ec9f9c0d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216a7260301d4508b4ec9556c9bb5805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2b73a6f4ff456ba48490062bfae04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">848</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:37\u001b[0m,\u001b[1;36m848\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">849</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:37\u001b[0m,\u001b[1;36m849\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using separate imputers for ordinal and continuous data.\n",
      "No NaN in train data -> Keep as it is. \n",
      "No NaN in test data -> Keep as it is. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">108</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:38\u001b[0m,\u001b[1;36m108\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:38\u001b[0m,\u001b[1;36m119\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:38\u001b[0m,\u001b[1;36m123\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">139</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabNetModel            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:38\u001b[0m,\u001b[1;36m139\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabNetModel            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:38\u001b[0m,\u001b[1;36m160\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">167</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:38\u001b[0m,\u001b[1;36m167\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type           | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | _embedding_layer | Identity       | 0      | train\n",
      "1 | _backbone        | TabNetBackbone | 18.9 K | train\n",
      "2 | _head            | Identity       | 0      | train\n",
      "3 | loss             | MSELoss        | 0      | train\n",
      "------------------------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n",
      "107       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70619eba312f416181a48378d2685109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d3be5caae1472b8dfcb5f08b241f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308caa14130c4a899ced6e0da17fe38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1fc74ee98294905b9081e71e01a2649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9686abf8be3a4d6fa11f98a0e8c24bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6f247d11b3483596c3ba300334a55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419f07bea0dd495f861ff714a9357416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f84305433e4078b7cc62320cffb891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">387</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:39\u001b[0m,\u001b[1;36m387\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:47:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">388</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m09:47:39\u001b[0m,\u001b[1;36m388\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for continuous_imputer, ordinal_imputer, model in combinations:\n",
    "    name_continuous_imputer, continuous_imputer_instance = continuous_imputer\n",
    "    name_ordinal_imputer, ordinal_imputer_instance = ordinal_imputer\n",
    "    name_model, model_instance = model\n",
    "\n",
    "    try: \n",
    "    \n",
    "        # Now you can call your `train_model` function with these components\n",
    "        dict_results = train_imputer_model(\n",
    "            df_X_train, df_X_test, df_y_train, df_y_test,\n",
    "            c_train, c_test,\n",
    "            ordinal_imputer_instance, name_ordinal_imputer,\n",
    "            continuous_imputer_instance, name_continuous_imputer,\n",
    "            model_instance, name_model,\n",
    "            separate_imputers=True  # Or however you want to specify\n",
    "        )\n",
    "\n",
    "    except Exception as e:  \n",
    "\n",
    "        print(e)\n",
    "    \n",
    "        params = {\n",
    "        \"ordinal_imputer\": name_ordinal_imputer, \n",
    "        \"continuous_imputer\": name_continuous_imputer, \n",
    "        \"model\": name_model, \"train_shape\" : df_X_train.shape, \n",
    "        \"test_shape\": df_X_test.shape\n",
    "    }\n",
    "        dict_results = {\n",
    "        \"params\": params, \n",
    "        \"imputation_time\": None,\n",
    "        \"fitting_time\": None, \n",
    "        \"results_adj\": None, \n",
    "        \"results_org\": None\n",
    "    }\n",
    "        \n",
    "    # Optionally keep the all_dict_results list updated\n",
    "    all_dict_results.append(dict_results)\n",
    "\n",
    "    # Save the updated results back to the pickle file\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(all_dict_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open(results_file, 'wb') as handle:\n",
    "    pickle.dump(all_dict_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Table for reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = \"../pickle/training_2_dict_results.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_file, \"rb\") as input_file:\n",
    "    all_dict_results = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>imputation_time</th>\n",
       "      <th>fitting_time</th>\n",
       "      <th>results_adj</th>\n",
       "      <th>results_org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.546680</td>\n",
       "      <td>0.113832</td>\n",
       "      <td>{'mse_score': [0.9049507588960866, 0.497607875...</td>\n",
       "      <td>{'mse_score': [0.9049507510973738, 0.497607869...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.489232</td>\n",
       "      <td>0.018780</td>\n",
       "      <td>{'mse_score': [1.209066965369377, 0.9448829134...</td>\n",
       "      <td>{'mse_score': [1.2090669743425486, 0.944882911...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.492828</td>\n",
       "      <td>1.172759</td>\n",
       "      <td>{'mse_score': [0.9081049470776361, 0.552868544...</td>\n",
       "      <td>{'mse_score': [0.9081049441441496, 0.552868544...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.539802</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>{'mse_score': [1.3936376654364884, 1.040563386...</td>\n",
       "      <td>{'mse_score': [1.39363767778841, 1.04056338628...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.532880</td>\n",
       "      <td>1.073404</td>\n",
       "      <td>{'mse_score': [0.9069250538351172, 0.502013168...</td>\n",
       "      <td>{'mse_score': [0.906925046254779, 0.5020131630...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.543471</td>\n",
       "      <td>39.735521</td>\n",
       "      <td>{'mse_score': [0.8476480766054094, 0.590657743...</td>\n",
       "      <td>{'mse_score': [0.8476480755917476, 0.590657743...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.513994</td>\n",
       "      <td>1.094394</td>\n",
       "      <td>{'mse_score': [0.8644967418117477, 0.474979766...</td>\n",
       "      <td>{'mse_score': [0.8644967402358948, 0.474979767...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.542050</td>\n",
       "      <td>4.451472</td>\n",
       "      <td>{'mse_score': [0.6308271979968313, 0.462175000...</td>\n",
       "      <td>{'mse_score': [0.6308271982625578, 0.462175006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.494494</td>\n",
       "      <td>13.224293</td>\n",
       "      <td>{'mse_score': [0.8216751045368837, 0.840482296...</td>\n",
       "      <td>{'mse_score': [0.8216750921763722, 0.840482310...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.566462</td>\n",
       "      <td>14.135967</td>\n",
       "      <td>{'mse_score': [0.6667009562298352, 0.377261128...</td>\n",
       "      <td>{'mse_score': [0.6667009546426534, 0.377261127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.633561</td>\n",
       "      <td>0.066845</td>\n",
       "      <td>{'mse_score': [0.9904572825274651, 0.657852760...</td>\n",
       "      <td>{'mse_score': [0.9904572854521583, 0.657852758...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.685376</td>\n",
       "      <td>16.588653</td>\n",
       "      <td>{'mse_score': [0.7175119859814013, 0.595379085...</td>\n",
       "      <td>{'mse_score': [0.7175119841624638, 0.595379078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.642462</td>\n",
       "      <td>1.929771</td>\n",
       "      <td>{'mse_score': [1.2015361781903395, 1.033008049...</td>\n",
       "      <td>{'mse_score': [1.2015361913080846, 1.033008050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.876747</td>\n",
       "      <td>1.568611</td>\n",
       "      <td>{'mse_score': [2.042401115199948, 1.4762543317...</td>\n",
       "      <td>{'mse_score': [2.0424011339847667, 1.476254328...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'ordinal_imputer': 'KNNImputer1', 'continuous...</td>\n",
       "      <td>2.774426</td>\n",
       "      <td>2.305695</td>\n",
       "      <td>{'mse_score': [1.4677197539055413, 1.179412714...</td>\n",
       "      <td>{'mse_score': [1.4677197694752766, 1.179412727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102543</td>\n",
       "      <td>{'mse_score': [1.1119234898099377, 0.676686264...</td>\n",
       "      <td>{'mse_score': [1.111923487408025, 0.6766862634...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015766</td>\n",
       "      <td>{'mse_score': [1.1801224687295142, 0.950415342...</td>\n",
       "      <td>{'mse_score': [1.1801224777332378, 0.950415341...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.846519</td>\n",
       "      <td>{'mse_score': [1.0976792354702392, 0.671636024...</td>\n",
       "      <td>{'mse_score': [1.0976792337396566, 0.671636022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007238</td>\n",
       "      <td>{'mse_score': [1.3936376654364884, 1.040563386...</td>\n",
       "      <td>{'mse_score': [1.39363767778841, 1.04056338628...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.028731</td>\n",
       "      <td>{'mse_score': [1.0998622817940762, 0.677003376...</td>\n",
       "      <td>{'mse_score': [1.0998622798698838, 0.677003374...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.523400</td>\n",
       "      <td>{'mse_score': [1.0063871308109065, 0.650126838...</td>\n",
       "      <td>{'mse_score': [1.0063871300392733, 0.650126843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.026638</td>\n",
       "      <td>{'mse_score': [0.9972977744677737, 0.552858876...</td>\n",
       "      <td>{'mse_score': [0.9972977727407778, 0.552858879...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.833591</td>\n",
       "      <td>{'mse_score': [1.0650921982971981, 0.503025863...</td>\n",
       "      <td>{'mse_score': [1.0650921971239258, 0.503025865...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.103587</td>\n",
       "      <td>{'mse_score': [1.0002425052752673, 0.852160951...</td>\n",
       "      <td>{'mse_score': [1.0002425013137521, 0.852160952...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.259788</td>\n",
       "      <td>{'mse_score': [0.9261003635990263, 0.764287381...</td>\n",
       "      <td>{'mse_score': [0.9261003504544436, 0.764287386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077055</td>\n",
       "      <td>{'mse_score': [1.081409082021159, 0.7876511651...</td>\n",
       "      <td>{'mse_score': [1.0814090864925796, 0.787651164...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.633923</td>\n",
       "      <td>{'mse_score': [1.0560083392333595, 0.754741883...</td>\n",
       "      <td>{'mse_score': [1.0560083442605621, 0.754741880...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.330303</td>\n",
       "      <td>{'mse_score': [1.7491323070355045, 0.913167428...</td>\n",
       "      <td>{'mse_score': [1.7491323190951489, 0.913167424...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.216993</td>\n",
       "      <td>{'mse_score': [2.0471137028497073, 1.676544780...</td>\n",
       "      <td>{'mse_score': [2.0471137196295768, 1.676544782...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'ordinal_imputer': 'NoImputer', 'continuous_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.301352</td>\n",
       "      <td>{'mse_score': [1.4796415919230979, 1.039560026...</td>\n",
       "      <td>{'mse_score': [1.4796416050918257, 1.039560032...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  imputation_time  \\\n",
       "0   {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.546680   \n",
       "1   {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.489232   \n",
       "2   {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.492828   \n",
       "3   {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.539802   \n",
       "4   {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.532880   \n",
       "5   {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.543471   \n",
       "6   {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.513994   \n",
       "7   {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.542050   \n",
       "8   {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.494494   \n",
       "9   {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.566462   \n",
       "10  {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.633561   \n",
       "11  {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.685376   \n",
       "12  {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.642462   \n",
       "13  {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.876747   \n",
       "14  {'ordinal_imputer': 'KNNImputer1', 'continuous...         2.774426   \n",
       "15  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "16  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "17  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "18  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "19  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "20  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "21  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "22  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "23  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "24  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "25  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "26  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "27  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "28  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "29  {'ordinal_imputer': 'NoImputer', 'continuous_i...              NaN   \n",
       "\n",
       "    fitting_time                                        results_adj  \\\n",
       "0       0.113832  {'mse_score': [0.9049507588960866, 0.497607875...   \n",
       "1       0.018780  {'mse_score': [1.209066965369377, 0.9448829134...   \n",
       "2       1.172759  {'mse_score': [0.9081049470776361, 0.552868544...   \n",
       "3       0.013393  {'mse_score': [1.3936376654364884, 1.040563386...   \n",
       "4       1.073404  {'mse_score': [0.9069250538351172, 0.502013168...   \n",
       "5      39.735521  {'mse_score': [0.8476480766054094, 0.590657743...   \n",
       "6       1.094394  {'mse_score': [0.8644967418117477, 0.474979766...   \n",
       "7       4.451472  {'mse_score': [0.6308271979968313, 0.462175000...   \n",
       "8      13.224293  {'mse_score': [0.8216751045368837, 0.840482296...   \n",
       "9      14.135967  {'mse_score': [0.6667009562298352, 0.377261128...   \n",
       "10      0.066845  {'mse_score': [0.9904572825274651, 0.657852760...   \n",
       "11     16.588653  {'mse_score': [0.7175119859814013, 0.595379085...   \n",
       "12      1.929771  {'mse_score': [1.2015361781903395, 1.033008049...   \n",
       "13      1.568611  {'mse_score': [2.042401115199948, 1.4762543317...   \n",
       "14      2.305695  {'mse_score': [1.4677197539055413, 1.179412714...   \n",
       "15      0.102543  {'mse_score': [1.1119234898099377, 0.676686264...   \n",
       "16      0.015766  {'mse_score': [1.1801224687295142, 0.950415342...   \n",
       "17      0.846519  {'mse_score': [1.0976792354702392, 0.671636024...   \n",
       "18      0.007238  {'mse_score': [1.3936376654364884, 1.040563386...   \n",
       "19      1.028731  {'mse_score': [1.0998622817940762, 0.677003376...   \n",
       "20     34.523400  {'mse_score': [1.0063871308109065, 0.650126838...   \n",
       "21      1.026638  {'mse_score': [0.9972977744677737, 0.552858876...   \n",
       "22      5.833591  {'mse_score': [1.0650921982971981, 0.503025863...   \n",
       "23     16.103587  {'mse_score': [1.0002425052752673, 0.852160951...   \n",
       "24     16.259788  {'mse_score': [0.9261003635990263, 0.764287381...   \n",
       "25      0.077055  {'mse_score': [1.081409082021159, 0.7876511651...   \n",
       "26     17.633923  {'mse_score': [1.0560083392333595, 0.754741883...   \n",
       "27      2.330303  {'mse_score': [1.7491323070355045, 0.913167428...   \n",
       "28      1.216993  {'mse_score': [2.0471137028497073, 1.676544780...   \n",
       "29      1.301352  {'mse_score': [1.4796415919230979, 1.039560026...   \n",
       "\n",
       "                                          results_org  \n",
       "0   {'mse_score': [0.9049507510973738, 0.497607869...  \n",
       "1   {'mse_score': [1.2090669743425486, 0.944882911...  \n",
       "2   {'mse_score': [0.9081049441441496, 0.552868544...  \n",
       "3   {'mse_score': [1.39363767778841, 1.04056338628...  \n",
       "4   {'mse_score': [0.906925046254779, 0.5020131630...  \n",
       "5   {'mse_score': [0.8476480755917476, 0.590657743...  \n",
       "6   {'mse_score': [0.8644967402358948, 0.474979767...  \n",
       "7   {'mse_score': [0.6308271982625578, 0.462175006...  \n",
       "8   {'mse_score': [0.8216750921763722, 0.840482310...  \n",
       "9   {'mse_score': [0.6667009546426534, 0.377261127...  \n",
       "10  {'mse_score': [0.9904572854521583, 0.657852758...  \n",
       "11  {'mse_score': [0.7175119841624638, 0.595379078...  \n",
       "12  {'mse_score': [1.2015361913080846, 1.033008050...  \n",
       "13  {'mse_score': [2.0424011339847667, 1.476254328...  \n",
       "14  {'mse_score': [1.4677197694752766, 1.179412727...  \n",
       "15  {'mse_score': [1.111923487408025, 0.6766862634...  \n",
       "16  {'mse_score': [1.1801224777332378, 0.950415341...  \n",
       "17  {'mse_score': [1.0976792337396566, 0.671636022...  \n",
       "18  {'mse_score': [1.39363767778841, 1.04056338628...  \n",
       "19  {'mse_score': [1.0998622798698838, 0.677003374...  \n",
       "20  {'mse_score': [1.0063871300392733, 0.650126843...  \n",
       "21  {'mse_score': [0.9972977727407778, 0.552858879...  \n",
       "22  {'mse_score': [1.0650921971239258, 0.503025865...  \n",
       "23  {'mse_score': [1.0002425013137521, 0.852160952...  \n",
       "24  {'mse_score': [0.9261003504544436, 0.764287386...  \n",
       "25  {'mse_score': [1.0814090864925796, 0.787651164...  \n",
       "26  {'mse_score': [1.0560083442605621, 0.754741880...  \n",
       "27  {'mse_score': [1.7491323190951489, 0.913167424...  \n",
       "28  {'mse_score': [2.0471137196295768, 1.676544782...  \n",
       "29  {'mse_score': [1.4796416050918257, 1.039560032...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_dict_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metric_table(\n",
    "    results_list,\n",
    "    targets,\n",
    "    metric_name,\n",
    "    source=\"Adjusted\",\n",
    "    float_format=\"%.3f\",\n",
    "    csv_filename=None,\n",
    "    sort_order=\"ascending\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a LaTeX and CSV table for a single metric across targets, models, and imputers,\n",
    "    including mean  std for performance, imputation time, and fitting time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results_list : list of dict\n",
    "        List of experiment results.\n",
    "    targets : list of str\n",
    "        Target names (e.g., ['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN']).\n",
    "    metric_name : str\n",
    "        Metric to extract (e.g., 'mae_score').\n",
    "    source : str\n",
    "        'Adjusted' or 'Original'.\n",
    "    float_format : str\n",
    "        Format for floats (e.g., '%.3f').\n",
    "    csv_filename : str or None\n",
    "        If provided, saves the table to CSV.\n",
    "    sort_order : str\n",
    "        'ascending' or 'descending' for sorting by mean.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        Final formatted DataFrame.\n",
    "    latex_table : str\n",
    "        LaTeX-formatted table string.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    version_key = \"results_adj\" if source.lower() == \"adjusted\" else \"results_org\"\n",
    "\n",
    "    for res in results_list:\n",
    "        result_block = res.get(version_key)\n",
    "        if result_block is None:\n",
    "            continue\n",
    "\n",
    "        metric_values = result_block.get(metric_name)\n",
    "        if metric_values is None:\n",
    "            continue\n",
    "\n",
    "        if len(metric_values) != len(targets):\n",
    "            continue\n",
    "\n",
    "        ordinal_imputer = res[\"params\"].get(\"ordinal_imputer\")\n",
    "        continuous_imputer = res[\"params\"].get(\"continuous_imputer\")\n",
    "        model = res[\"params\"].get(\"model\")\n",
    "\n",
    "        values = np.array(metric_values, dtype=np.float64)\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "\n",
    "        # Time metrics\n",
    "        imp_times = np.array(res.get(\"imputation_time\", []), dtype=np.float64)\n",
    "        fit_times = np.array(res.get(\"fitting_time\", []), dtype=np.float64)\n",
    "\n",
    "        row = {\n",
    "            \"Ordinal Imputer\": ordinal_imputer,\n",
    "            \"Continuous Imputer\": continuous_imputer,\n",
    "            \"Model\": model,\n",
    "            \"Mean\": mean_val,\n",
    "            \"Mean  SD\": f\"{mean_val:.3f}  {std_val:.3f}\",\n",
    "            \"Imputation Time\": f\"{imp_times.mean():.2f}\" if imp_times.size > 0 else \"N/A\",\n",
    "            \"Fitting Time\": f\"{fit_times.mean():.2f}\" if fit_times.size > 0 else \"N/A\"\n",
    "        }\n",
    "\n",
    "        row.update({target: val for target, val in zip(targets, values)})\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Reorder columns for display\n",
    "    display_cols = (\n",
    "        [\"Ordinal Imputer\", \"Continuous Imputer\", \"Model\"] +\n",
    "        targets +\n",
    "        [\"Mean  SD\", \"Imputation Time\", \"Fitting Time\"]\n",
    "    )\n",
    "    df = df.sort_values(by=\"Mean\", ascending=(sort_order == \"ascending\"))\n",
    "    df = df[display_cols]\n",
    "\n",
    "    df.drop_duplicates(subset=[\"Ordinal Imputer\", \"Continuous Imputer\", \"Model\"] +\n",
    "        targets +\n",
    "        [\"Mean  SD\",], inplace=True)\n",
    "\n",
    "    # Save CSV if requested\n",
    "    if csv_filename:\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    # Generate LaTeX table\n",
    "    latex_table = df.to_latex(\n",
    "        index=False,\n",
    "        escape=False,\n",
    "        float_format=float_format,\n",
    "        caption=f\"{metric_name.replace('_', ' ').upper()} across targets with timing info\",\n",
    "        label=f\"tab:{metric_name}\",\n",
    "        longtable=False\n",
    "    )\n",
    "\n",
    "    return df, latex_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{CORR across targets with timing info}\n",
      "\\label{tab:corr}\n",
      "\\begin{tabular}{lllrrrrlll}\n",
      "\\toprule\n",
      "Ordinal Imputer & Continuous Imputer & Model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & Mean  SD & Imputation Time & Fitting Time \\\\\n",
      "\\midrule\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_custom & 0.745 & 0.795 & 0.659 & 0.594 & 0.698  0.077 & 2.57 & 14.14 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_default & 0.749 & 0.626 & 0.391 & 0.739 & 0.626  0.144 & 2.49 & 13.22 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & RandomForestRegressor & 0.631 & 0.656 & 0.356 & 0.729 & 0.593  0.141 & 2.54 & 39.74 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor_tuned & 0.706 & 0.732 & 0.179 & 0.717 & 0.584  0.234 & 2.54 & 4.45 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor & 0.592 & 0.752 & 0.300 & 0.654 & 0.575  0.168 & 2.51 & 1.09 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & GatedAdditiveTreeEnsembleConfig_tab & 0.684 & 0.574 & 0.147 & 0.767 & 0.543  0.238 & 2.69 & 16.59 \\\\\n",
      "NoImputer & NoImputer & GatedAdditiveTreeEnsembleConfig_tab & 0.638 & 0.525 & 0.274 & 0.593 & 0.507  0.141 & nan & 17.63 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 0.540 & 0.644 & 0.217 & 0.610 & 0.503  0.169 & nan & 34.52 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & 0.522 & 0.698 & 0.212 & 0.566 & 0.500  0.178 & nan & 1.03 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 0.553 & 0.581 & 0.237 & 0.597 & 0.492  0.148 & nan & 16.26 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & 0.629 & 0.471 & 0.067 & 0.730 & 0.474  0.253 & nan & 16.10 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & LinearRegression & 0.483 & 0.707 & 0.194 & 0.446 & 0.457  0.182 & 2.55 & 0.11 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso_tuned & 0.482 & 0.708 & 0.186 & 0.450 & 0.456  0.185 & 2.53 & 1.07 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet_tuned & 0.485 & 0.692 & 0.130 & 0.518 & 0.456  0.204 & 2.49 & 1.17 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & 0.413 & 0.733 & 0.187 & 0.475 & 0.452  0.194 & nan & 5.83 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & PLSRegression_4_components & 0.460 & 0.567 & 0.115 & 0.499 & 0.410  0.174 & 2.63 & 0.07 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & 0.340 & 0.549 & 0.014 & 0.391 & 0.324  0.195 & nan & 1.03 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & 0.338 & 0.551 & 0.010 & 0.392 & 0.323  0.197 & nan & 0.85 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & 0.433 & 0.445 & -0.054 & 0.457 & 0.321  0.216 & nan & 0.08 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & 0.332 & 0.548 & 0.016 & 0.381 & 0.319  0.192 & nan & 0.10 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & 0.422 & 0.179 & -0.163 & 0.446 & 0.221  0.245 & nan & 0.02 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet & 0.369 & 0.212 & -0.123 & 0.425 & 0.221  0.213 & 2.49 & 0.02 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & DANetConfig_tab & 0.084 & 0.275 & 0.309 & 0.178 & 0.211  0.088 & 2.64 & 1.93 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabTransformerConfig_tab & 0.032 & 0.167 & -0.032 & 0.514 & 0.170  0.211 & 2.88 & 1.57 \\\\\n",
      "NoImputer & NoImputer & TabNetModelConfig_tab & 0.266 & 0.269 & 0.099 & -0.197 & 0.109  0.190 & nan & 1.30 \\\\\n",
      "NoImputer & NoImputer & TabTransformerConfig_tab & 0.185 & 0.031 & -0.463 & 0.459 & 0.053  0.335 & nan & 1.22 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetModelConfig_tab & -0.199 & 0.426 & 0.159 & -0.318 & 0.017  0.294 & 2.77 & 2.31 \\\\\n",
      "NoImputer & NoImputer & DANetConfig_tab & -0.397 & 0.229 & -0.593 & -0.180 & -0.235  0.305 & nan & 2.33 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso & NaN & NaN & NaN & NaN & nan  nan & 2.54 & 0.01 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & NaN & NaN & NaN & NaN & nan  nan & nan & 0.01 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='corr',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_corr_adjusted_sorted.csv\",\n",
    "    sort_order=\"descending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{R2 across targets with timing info}\n",
      "\\label{tab:r2}\n",
      "\\begin{tabular}{lllrrrrlll}\n",
      "\\toprule\n",
      "Ordinal Imputer & Continuous Imputer & Model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & Mean  SD & Imputation Time & Fitting Time \\\\\n",
      "\\midrule\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_custom & 0.326 & 0.572 & 0.433 & 0.170 & 0.375  0.147 & 2.57 & 14.14 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor_tuned & 0.362 & 0.476 & -0.098 & 0.376 & 0.279  0.222 & 2.54 & 4.45 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor & 0.126 & 0.461 & 0.030 & 0.175 & 0.198  0.161 & 2.51 & 1.09 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & RandomForestRegressor & 0.143 & 0.330 & 0.111 & 0.184 & 0.192  0.084 & 2.54 & 39.74 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & GatedAdditiveTreeEnsembleConfig_tab & 0.275 & 0.324 & -0.004 & 0.116 & 0.178  0.130 & 2.69 & 16.59 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & -0.008 & 0.373 & -0.040 & 0.092 & 0.104  0.162 & nan & 1.03 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet_tuned & 0.082 & 0.373 & -0.084 & -0.008 & 0.091  0.173 & 2.49 & 1.17 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso_tuned & 0.083 & 0.430 & -0.138 & -0.095 & 0.070  0.224 & 2.53 & 1.07 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & LinearRegression & 0.085 & 0.435 & -0.158 & -0.099 & 0.066  0.232 & 2.55 & 0.11 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & -0.017 & 0.262 & 0.001 & -0.000 & 0.061  0.116 & nan & 34.52 \\\\\n",
      "NoImputer & NoImputer & GatedAdditiveTreeEnsembleConfig_tab & -0.067 & 0.144 & 0.070 & 0.054 & 0.050  0.076 & nan & 17.63 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_default & 0.170 & 0.046 & -0.086 & 0.069 & 0.050  0.091 & 2.49 & 13.22 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & PLSRegression_4_components & -0.001 & 0.254 & -0.046 & -0.043 & 0.041  0.124 & 2.63 & 0.07 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & -0.076 & 0.429 & -0.232 & 0.039 & 0.040  0.244 & nan & 5.83 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 0.064 & 0.133 & -0.277 & -0.064 & -0.036  0.156 & nan & 16.26 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & -0.011 & 0.033 & -0.301 & 0.042 & -0.059  0.141 & nan & 16.10 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & -0.093 & 0.106 & -0.189 & -0.151 & -0.082  0.114 & nan & 0.08 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & -0.109 & 0.238 & -0.289 & -0.168 & -0.082  0.196 & nan & 0.85 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & -0.112 & 0.232 & -0.289 & -0.172 & -0.085  0.194 & nan & 1.03 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & -0.124 & 0.232 & -0.295 & -0.189 & -0.094  0.198 & nan & 0.10 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & DANetConfig_tab & -0.214 & -0.172 & 0.031 & -0.223 & -0.145  0.103 & 2.64 & 1.93 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & -0.193 & -0.078 & -0.059 & -0.252 & -0.146  0.080 & nan & 0.02 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet & -0.222 & -0.072 & -0.047 & -0.273 & -0.154  0.096 & 2.49 & 0.02 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso & -0.409 & -0.181 & -0.020 & -0.508 & -0.279  0.191 & 2.54 & 0.01 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & -0.409 & -0.181 & -0.020 & -0.508 & -0.279  0.191 & nan & 0.01 \\\\\n",
      "NoImputer & NoImputer & TabNetModelConfig_tab & -0.495 & -0.180 & -0.183 & -0.564 & -0.356  0.176 & nan & 1.30 \\\\\n",
      "NoImputer & NoImputer & DANetConfig_tab & -0.768 & -0.036 & -0.193 & -0.537 & -0.384  0.286 & nan & 2.33 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetModelConfig_tab & -0.483 & -0.338 & -0.371 & -0.648 & -0.460  0.121 & 2.77 & 2.31 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabTransformerConfig_tab & -1.064 & -0.675 & -1.883 & 0.079 & -0.886  0.708 & 2.88 & 1.57 \\\\\n",
      "NoImputer & NoImputer & TabTransformerConfig_tab & -1.069 & -0.902 & -2.742 & 0.089 & -1.156  1.017 & nan & 1.22 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='r2',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_r2_adjusted_sorted.csv\",\n",
    "    sort_order=\"descending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{MSE SCORE across targets with timing info}\n",
      "\\label{tab:mse_score}\n",
      "\\begin{tabular}{lllrrrrlll}\n",
      "\\toprule\n",
      "Ordinal Imputer & Continuous Imputer & Model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & Mean  SD & Imputation Time & Fitting Time \\\\\n",
      "\\midrule\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_custom & 0.667 & 0.377 & 0.271 & 0.682 & 0.499  0.179 & 2.57 & 14.14 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor_tuned & 0.631 & 0.462 & 0.526 & 0.513 & 0.533  0.061 & 2.54 & 4.45 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor & 0.864 & 0.475 & 0.465 & 0.678 & 0.621  0.165 & 2.51 & 1.09 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & GatedAdditiveTreeEnsembleConfig_tab & 0.718 & 0.595 & 0.481 & 0.727 & 0.630  0.101 & 2.69 & 16.59 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & RandomForestRegressor & 0.848 & 0.591 & 0.426 & 0.670 & 0.634  0.152 & 2.54 & 39.74 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & 0.997 & 0.553 & 0.498 & 0.746 & 0.699  0.196 & nan & 1.03 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet_tuned & 0.908 & 0.553 & 0.519 & 0.829 & 0.702  0.169 & 2.49 & 1.17 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso_tuned & 0.907 & 0.502 & 0.545 & 0.900 & 0.713  0.191 & 2.53 & 1.07 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & LinearRegression & 0.905 & 0.498 & 0.555 & 0.904 & 0.715  0.190 & 2.55 & 0.11 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_default & 0.822 & 0.840 & 0.520 & 0.765 & 0.737  0.128 & 2.49 & 13.22 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & 1.065 & 0.503 & 0.590 & 0.790 & 0.737  0.216 & nan & 5.83 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 1.006 & 0.650 & 0.479 & 0.822 & 0.739  0.196 & nan & 34.52 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & PLSRegression_4_components & 0.990 & 0.658 & 0.501 & 0.857 & 0.752  0.187 & 2.63 & 0.07 \\\\\n",
      "NoImputer & NoImputer & GatedAdditiveTreeEnsembleConfig_tab & 1.056 & 0.755 & 0.446 & 0.778 & 0.758  0.216 & nan & 17.63 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 0.926 & 0.764 & 0.612 & 0.875 & 0.794  0.121 & nan & 16.26 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & 1.000 & 0.852 & 0.623 & 0.787 & 0.816  0.135 & nan & 16.10 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & 1.098 & 0.672 & 0.617 & 0.960 & 0.837  0.199 & nan & 0.85 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & 1.100 & 0.677 & 0.617 & 0.963 & 0.839  0.199 & nan & 1.03 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & 1.081 & 0.788 & 0.569 & 0.946 & 0.846  0.191 & nan & 0.08 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & 1.112 & 0.677 & 0.620 & 0.978 & 0.847  0.205 & nan & 0.10 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & 1.180 & 0.950 & 0.507 & 1.029 & 0.917  0.250 & nan & 0.02 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet & 1.209 & 0.945 & 0.502 & 1.047 & 0.926  0.262 & 2.49 & 0.02 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & DANetConfig_tab & 1.202 & 1.033 & 0.464 & 1.005 & 0.926  0.277 & 2.64 & 1.93 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso & 1.394 & 1.041 & 0.489 & 1.240 & 1.041  0.342 & 2.54 & 0.01 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & 1.394 & 1.041 & 0.489 & 1.240 & 1.041  0.342 & nan & 0.01 \\\\\n",
      "NoImputer & NoImputer & TabNetModelConfig_tab & 1.480 & 1.040 & 0.566 & 1.286 & 1.093  0.342 & nan & 1.30 \\\\\n",
      "NoImputer & NoImputer & DANetConfig_tab & 1.749 & 0.913 & 0.571 & 1.264 & 1.124  0.436 & nan & 2.33 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetModelConfig_tab & 1.468 & 1.179 & 0.657 & 1.355 & 1.165  0.311 & 2.77 & 2.31 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabTransformerConfig_tab & 2.042 & 1.476 & 1.381 & 0.757 & 1.414  0.456 & 2.88 & 1.57 \\\\\n",
      "NoImputer & NoImputer & TabTransformerConfig_tab & 2.047 & 1.677 & 1.792 & 0.749 & 1.566  0.491 & nan & 1.22 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mse = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='mse_score',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_mse_adjusted_sorted.csv\",\n",
    "    sort_order=\"ascending\"\n",
    ")\n",
    "print(latex_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{MAE SCORE across targets with timing info}\n",
      "\\label{tab:mae_score}\n",
      "\\begin{tabular}{lllrrrrlll}\n",
      "\\toprule\n",
      "Ordinal Imputer & Continuous Imputer & Model & ADNI_MEM & ADNI_EF & ADNI_VS & ADNI_LAN & Mean  SD & Imputation Time & Fitting Time \\\\\n",
      "\\midrule\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_custom & 0.608 & 0.518 & 0.410 & 0.668 & 0.551  0.097 & 2.57 & 14.14 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor_tuned & 0.599 & 0.588 & 0.655 & 0.562 & 0.601  0.034 & 2.54 & 4.45 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & XGBoostRegressor & 0.675 & 0.589 & 0.627 & 0.628 & 0.630  0.031 & 2.51 & 1.09 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & RandomForestRegressor & 0.671 & 0.648 & 0.617 & 0.598 & 0.634  0.028 & 2.54 & 39.74 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor_tuned & 0.801 & 0.516 & 0.658 & 0.626 & 0.650  0.102 & nan & 5.83 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & GatedAdditiveTreeEnsembleConfig_tab & 0.623 & 0.679 & 0.641 & 0.663 & 0.652  0.021 & 2.69 & 16.59 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & LinearRegression & 0.699 & 0.541 & 0.631 & 0.765 & 0.659  0.083 & 2.55 & 0.11 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso_tuned & 0.701 & 0.554 & 0.634 & 0.766 & 0.664  0.078 & 2.53 & 1.07 \\\\\n",
      "NoImputer & NoImputer & XGBoostRegressor & 0.754 & 0.635 & 0.643 & 0.644 & 0.669  0.049 & nan & 1.03 \\\\\n",
      "NoImputer & NoImputer & RandomForestRegressor & 0.755 & 0.684 & 0.635 & 0.632 & 0.677  0.050 & nan & 34.52 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet_tuned & 0.709 & 0.662 & 0.687 & 0.738 & 0.699  0.028 & 2.49 & 1.17 \\\\\n",
      "NoImputer & NoImputer & GatedAdditiveTreeEnsembleConfig_tab & 0.830 & 0.731 & 0.616 & 0.662 & 0.710  0.081 & nan & 17.63 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso_tuned & 0.724 & 0.705 & 0.713 & 0.706 & 0.712  0.008 & nan & 1.03 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet_tuned & 0.727 & 0.703 & 0.714 & 0.708 & 0.713  0.009 & nan & 0.85 \\\\\n",
      "NoImputer & NoImputer & LinearRegression & 0.728 & 0.702 & 0.710 & 0.712 & 0.713  0.010 & nan & 0.10 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_custom & 0.713 & 0.758 & 0.671 & 0.724 & 0.717  0.031 & nan & 16.26 \\\\\n",
      "NoImputer & NoImputer & TabNetRegressor_default & 0.781 & 0.801 & 0.680 & 0.672 & 0.733  0.058 & nan & 16.10 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetRegressor_default & 0.745 & 0.801 & 0.654 & 0.737 & 0.734  0.052 & 2.49 & 13.22 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & PLSRegression_4_components & 0.808 & 0.725 & 0.682 & 0.768 & 0.746  0.047 & 2.63 & 0.07 \\\\\n",
      "NoImputer & NoImputer & PLSRegression_4_components & 0.792 & 0.791 & 0.722 & 0.735 & 0.760  0.032 & nan & 0.08 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & DANetConfig_tab & 0.910 & 0.787 & 0.602 & 0.836 & 0.784  0.114 & 2.64 & 1.93 \\\\\n",
      "NoImputer & NoImputer & MultiTaskElasticNet & 0.884 & 0.787 & 0.654 & 0.827 & 0.788  0.085 & nan & 0.02 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskElasticNet & 0.900 & 0.781 & 0.651 & 0.841 & 0.793  0.092 & 2.49 & 0.02 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & MultiTaskLasso & 0.991 & 0.785 & 0.621 & 0.934 & 0.833  0.144 & 2.54 & 0.01 \\\\\n",
      "NoImputer & NoImputer & MultiTaskLasso & 0.991 & 0.785 & 0.621 & 0.934 & 0.833  0.144 & nan & 0.01 \\\\\n",
      "NoImputer & NoImputer & DANetConfig_tab & 1.124 & 0.732 & 0.656 & 0.944 & 0.864  0.184 & nan & 2.33 \\\\\n",
      "NoImputer & NoImputer & TabNetModelConfig_tab & 1.012 & 0.846 & 0.680 & 0.999 & 0.884  0.135 & nan & 1.30 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabNetModelConfig_tab & 1.113 & 0.921 & 0.747 & 0.984 & 0.941  0.132 & 2.77 & 2.31 \\\\\n",
      "NoImputer & NoImputer & TabTransformerConfig_tab & 1.062 & 1.044 & 0.985 & 0.796 & 0.972  0.105 & nan & 1.22 \\\\\n",
      "KNNImputer1 & KNNImputer_5 & TabTransformerConfig_tab & 1.190 & 1.050 & 0.997 & 0.768 & 1.001  0.152 & 2.88 & 1.57 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_df, latex_mae = generate_metric_table(\n",
    "    results_list=all_dict_results,\n",
    "    targets=['ADNI_MEM', 'ADNI_EF', 'ADNI_VS', 'ADNI_LAN'],\n",
    "    metric_name='mae_score',\n",
    "    source=\"Adjusted\",\n",
    "    csv_filename=\"../tables/2_training_train_test_mae_adjusted_sorted.csv\",\n",
    "    sort_order=\"ascending\"\n",
    ")\n",
    "print(latex_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "TabNetRegressor_custom                 2\n",
       "XGBoostRegressor_tuned                 2\n",
       "XGBoostRegressor                       2\n",
       "RandomForestRegressor                  2\n",
       "GatedAdditiveTreeEnsembleConfig_tab    2\n",
       "LinearRegression                       2\n",
       "MultiTaskLasso_tuned                   2\n",
       "MultiTaskElasticNet_tuned              2\n",
       "TabNetRegressor_default                2\n",
       "PLSRegression_4_components             2\n",
       "DANetConfig_tab                        2\n",
       "MultiTaskElasticNet                    2\n",
       "MultiTaskLasso                         2\n",
       "TabNetModelConfig_tab                  2\n",
       "TabTransformerConfig_tab               2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latex_df.Model.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
